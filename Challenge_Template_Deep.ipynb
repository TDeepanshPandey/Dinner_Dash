{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Challenge_Template_Deep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b939a27f7b0f48e0afb1735eb38f3b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2869b37489ec451eb12cfd5a1150702e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_66fe65523cb0499cb5482b97a7768e7a",
              "IPY_MODEL_1d628e054d904f05a3357c8d708e9713"
            ]
          }
        },
        "2869b37489ec451eb12cfd5a1150702e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66fe65523cb0499cb5482b97a7768e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2a594fac95b34389a9b0a2630704ed24",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e43d0e960044d23b0368f2f21f7a294"
          }
        },
        "1d628e054d904f05a3357c8d708e9713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fe025dbbe637406799effe463f6a6379",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [04:27&lt;00:00,  2.68s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7231adf34a149ca9d27ed6e07d20b09"
          }
        },
        "2a594fac95b34389a9b0a2630704ed24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e43d0e960044d23b0368f2f21f7a294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe025dbbe637406799effe463f6a6379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7231adf34a149ca9d27ed6e07d20b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1uhFSLspLGu",
        "colab_type": "text"
      },
      "source": [
        "# **Diner Dash Challenge**\n",
        "\n",
        "---\n",
        "\n",
        "## Objective:\n",
        "\n",
        "Using Reinforcement Learning(RL) algorithms and a **maximum training timestep of 10 million**, maximise the average rewards from 100 games/episodes of Diner Dash.\n",
        "\n",
        "## Instructions and Expectations:\n",
        "\n",
        "1. Please use Google Colabs for all computing needs (installing of dependencies, training of model, testing of model, generation of submission, etc). This is to ensure fairness in this competition. You can run multiple notebooks but please take note of the contraints of GPU usage.\n",
        "\n",
        "2. You are required to submit **2 files**: \n",
        "  - A fully ran Google Colab notebook \n",
        "  - A Json file which includes action lists for each seeded environment given \n",
        "  \n",
        "  A function \"Testing of policies and verification of submission\" is provided to save your best algo's action list to a json file. For more information about the submission, please refer to the [workshop repo](https://github.com/AISG-Technology-Team/Diner-Dash-Workshop).\n",
        "\n",
        "3. Please update the \"Details of Submission\" section\n",
        "\n",
        "4. We expect to see that the models are learning during training\n",
        "\n",
        "5. If you have any questions, please discuss within your groups first. Otherwise, please check if the issue is existing on the [workshop repo](https://github.com/AISG-Technology-Team/Diner-Dash-Workshop/issues) or raise one if it is not.\n",
        "\n",
        "## Advice on approach to challenge\n",
        "\n",
        "1. Spend some time to read up about the various RL algos, especially easily implementable baselines\n",
        "\n",
        "2. Split the shortlisted algos among the group\n",
        "\n",
        "3. You can choose to train for fewer timesteps and later on further train the model\n",
        "\n",
        "4. Take note of the training duration. Time is tight!\n",
        "\n",
        "5. If necessary, tune the hyperparameters to ensure learning\n",
        "\n",
        "6. Have fun!\n",
        "\n",
        "## Important Resources:\n",
        "\n",
        "1. [Diner Dash repo](https://github.com/AdaCompNUS/diner-dash-simulator)\n",
        "\n",
        "2. [Workshop repo](https://github.com/AISG-Technology-Team/Diner-Dash-Workshop)\n",
        "\n",
        "3. [Stable Baselines](https://github.com/hill-a/stable-baselines)\n",
        "\n",
        "## Things to note:\n",
        "\n",
        "1. Please change the runtime to a GPU when using a GPU. In the above tabs, click Runtime > Change runtime type > GPU in the Hardware accelerator dropdown\n",
        "\n",
        "2. If an \"Error: A module (diner_dash) was specified for the environment but was not found, make sure the package is installed with `pip install` before calling `gym.make()`\" error is raised, please restart the runtime and rerun the installation of the diner dash simulator.\n",
        "\n",
        "2. Please ensure a strong internet connection throughout this challenge to avoid disconnecting from the collab GPUs\n",
        "\n",
        "3. Do not idle your computer as collab automatically disconnects GPUs if the idle time is too long\n",
        "\n",
        "4. GPUs run on CUDA 10.1\n",
        "\n",
        "For other FAQs, refer to this [link](https://research.google.com/colaboratory/faq.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLMQrYZNhc12",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLhRQoYbhGvh",
        "colab_type": "text"
      },
      "source": [
        "# Details of Submission [Please Edit]\n",
        "\n",
        "### Team Name / ID:\n",
        "Team 2\n",
        "\n",
        "### Names of Group Members:\n",
        "Deepansh, Mary, Bryan\n",
        "\n",
        "### Names of Algorithms tested:\n",
        "Random Agent, PPO, PPO2, A2C\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0Sr4eQLrZ3f",
        "colab_type": "text"
      },
      "source": [
        "# Information on Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCjo39oa4Wo_",
        "colab_type": "text"
      },
      "source": [
        "## Python Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwHyupUqn9I0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "597e3794-be39-4667-fdeb-aed58bdee2fc"
      },
      "source": [
        "!python -V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpmpiz2E4ZIi",
        "colab_type": "text"
      },
      "source": [
        "## Cuda Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_YqJEiT4LhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a826aebf-ebc7-4b88-edad-296d0baaaed4"
      },
      "source": [
        "!nvcc -V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGTjEEIFFH5u",
        "colab_type": "text"
      },
      "source": [
        "# Mounting Google Drive\n",
        "\n",
        "To store trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1zPeIVOE2c6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95ba6f69-4c4a-4a4a-d74f-72b455903bdc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb_lw5zhJ6Av",
        "colab_type": "text"
      },
      "source": [
        "## Create Project Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4uwe83-Fo0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fedf182c-3f4f-4b11-a011-71a7746214f0"
      },
      "source": [
        "from os import path, chdir, getcwd, mkdir\n",
        "\n",
        "# Choose a project name\n",
        "projectName = \"DinerDashChallenge\"\n",
        "\n",
        "# Project directory is in My Drive\n",
        "projectDirectory = \"/content/drive/My Drive/\" + projectName\n",
        "\n",
        "# Checks if cwd is in content folder\n",
        "if getcwd() == \"/content\":\n",
        "  # Makes project directory if it does not exist\n",
        "  if not path.isdir(projectDirectory):\n",
        "    mkdir(projectDirectory)\n",
        "    print(f\"Project {projectName} has been created!\")\n",
        "  else:\n",
        "    print(f\"Project {projectName} already exist!\")\n",
        "  # Changes to project directory\n",
        "  chdir(projectDirectory)\n",
        "\n",
        "print(f\"The current working directory is {getcwd()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The current working directory is /content/drive/My Drive/DinerDashChallenge\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhJmt90nhfuz",
        "colab_type": "text"
      },
      "source": [
        "# Installing Dependencies\n",
        "\n",
        "Downloading relevant project dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iYXlsBohnCo",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies for [diner dash simulator](https://github.com/AdaCompNUS/diner-dash-simulator)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h24WNb92iLo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f93cfaa-3c7d-4f1a-f382-5031047e563c"
      },
      "source": [
        "from os import path, getcwd\n",
        "\n",
        "repoName = \"diner-dash-simulator\"\n",
        "\n",
        "# Clones repo if it does not exist\n",
        "if not path.isdir(repoName):\n",
        "  !git clone https://github.com/AdaCompNUS/diner-dash-simulator.git\n",
        "  print(f\"Diner Dash repo has been cloned to {getcwd()}\")\n",
        "else:\n",
        "  print(f\"Diner Dash repo is already available at {path.join(getcwd(), repoName)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diner Dash repo is already available at /content/drive/My Drive/DinerDashChallenge/diner-dash-simulator\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArJDnBT3eq_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "20e44940-0ef5-4568-c71f-e5ad1643805e"
      },
      "source": [
        "!pip install -e diner-dash-simulator/DinerDashEnv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/drive/My%20Drive/DinerDashChallenge/diner-dash-simulator/DinerDashEnv\n",
            "Requirement already satisfied: gym>=0.2.3 in /usr/local/lib/python3.6/dist-packages (from diner-dash==0.0.1) (0.17.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from diner-dash==0.0.1) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from diner-dash==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.2.3->diner-dash==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.2.3->diner-dash==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.2.3->diner-dash==0.0.1) (1.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->diner-dash==0.0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->diner-dash==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->diner-dash==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->diner-dash==0.0.1) (2020.6.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.2.3->diner-dash==0.0.1) (0.16.0)\n",
            "Installing collected packages: diner-dash\n",
            "  Found existing installation: diner-dash 0.0.1\n",
            "    Can't uninstall 'diner-dash'. No files were found to uninstall.\n",
            "  Running setup.py develop for diner-dash\n",
            "Successfully installed diner-dash\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFG_CNITTHDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0bd54e2-5a42-4667-f5be-92743f5ebf97"
      },
      "source": [
        "import gym\n",
        "\n",
        "# Test make environment\n",
        "def testEnv():\n",
        "  env = gym.make('diner_dash:DinerDash-v0').unwrapped\n",
        "  env.flash_sim = False\n",
        "  env.close()\n",
        "  return True\n",
        "\n",
        "if testEnv():\n",
        "  print(\"Installation of diner dash simulator is successful!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installation of diner dash simulator is successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI9AG8cflhV2",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies for Policy [Please Edit]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZQV-Quxmd_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a577aa25-c392-49f0-8963-0bafd747e224"
      },
      "source": [
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.5.1+cu101 in /usr/local/lib/python3.6/dist-packages (1.5.1+cu101)\n",
            "Requirement already satisfied: torchvision==0.6.1+cu101 in /usr/local/lib/python3.6/dist-packages (0.6.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3vS8KYfpIan",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "3a6de6b6-ecf7-4113-bf99-8bca8412675d"
      },
      "source": [
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x\n",
        "!pip install stable-baselines[mpi]==2.10.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stable-baselines[mpi]==2.10.0 in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (0.17.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.0.5)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (4.1.2.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (0.16.0)\n",
            "Requirement already satisfied: mpi4py; extra == \"mpi\" in /tensorflow-1.15.2/python3.6 (from stable-baselines[mpi]==2.10.0) (3.0.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.5.0)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (7.0.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.2.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]==2.10.0) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from atari-py~=0.2.0; extra == \"atari\"->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzdKjy68IIBL",
        "colab_type": "text"
      },
      "source": [
        "# Check GPU usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqvFkTbo69ig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ffddd39-b872-4e50-fc20-fc36c181195a"
      },
      "source": [
        "# Check if runtime uses GPU\n",
        "# Ignore error if you do not wish to use a GPU\n",
        "from tensorflow.test import gpu_device_name\n",
        "\n",
        "device_name = gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "else:\n",
        "  print(\"GPU runtime is in use!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU runtime is in use!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhLb7POHP-Ic",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions\n",
        "\n",
        "For easier debugging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMDW4nVXQA4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getAction(actionID):\n",
        "    actionIDtoName = {\n",
        "        0 : \"None\",\n",
        "        1 : \"Move to Table 1\",\n",
        "        2 : \"Move to Table 2\",\n",
        "        3 : \"Move to Table 3\",\n",
        "        4 : \"Move to Table 4\",\n",
        "        5 : \"Move to Table 5\",\n",
        "        6 : \"Move to Table 6\",\n",
        "        7 : \"Move to Counter\",\n",
        "        8 : \"Pick Food for Table 1\",\n",
        "        9 : \"Pick Food for Table 2\",\n",
        "        10 : \"Pick Food for Table 3\",\n",
        "        11 : \"Pick Food for Table 4\",\n",
        "        12 : \"Pick Food for Table 5\",\n",
        "        13 : \"Pick Food for Table 6\",\n",
        "        14 : \"Move to Food Collection\",\n",
        "        15 : \"Pick Table 1 for Group 1\",\n",
        "        16 : \"Pick Table 2 for Group 1\",\n",
        "        17 : \"Pick Table 3 for Group 1\",\n",
        "        18 : \"Pick Table 4 for Group 1\",\n",
        "        19 : \"Pick Table 5 for Group 1\",\n",
        "        20 : \"Pick Table 6 for Group 1\",\n",
        "        21 : \"Pick Table 1 for Group 2\",\n",
        "        22 : \"Pick Table 2 for Group 2\",\n",
        "        23 : \"Pick Table 3 for Group 2\",\n",
        "        24 : \"Pick Table 4 for Group 2\",\n",
        "        25 : \"Pick Table 5 for Group 2\",\n",
        "        26 : \"Pick Table 6 for Group 2\",\n",
        "        27 : \"Pick Table 1 for Group 3\",\n",
        "        28 : \"Pick Table 2 for Group 3\",\n",
        "        29 : \"Pick Table 3 for Group 3\",\n",
        "        30 : \"Pick Table 4 for Group 3\",\n",
        "        31 : \"Pick Table 5 for Group 3\",\n",
        "        32 : \"Pick Table 6 for Group 3\",\n",
        "        33 : \"Pick Table 1 for Group 4\",\n",
        "        34 : \"Pick Table 2 for Group 4\",\n",
        "        35 : \"Pick Table 3 for Group 4\",\n",
        "        36 : \"Pick Table 4 for Group 4\",\n",
        "        37 : \"Pick Table 5 for Group 4\",\n",
        "        38 : \"Pick Table 6 for Group 4\",\n",
        "        39 : \"Pick Table 1 for Group 5\",\n",
        "        40 : \"Pick Table 2 for Group 5\",\n",
        "        41 : \"Pick Table 3 for Group 5\",\n",
        "        42 : \"Pick Table 4 for Group 5\",\n",
        "        43 : \"Pick Table 5 for Group 5\",\n",
        "        44 : \"Pick Table 6 for Group 5\",\n",
        "        45 : \"Pick Table 1 for Group 6\",\n",
        "        46 : \"Pick Table 2 for Group 6\",\n",
        "        47 : \"Pick Table 3 for Group 6\",\n",
        "        48 : \"Pick Table 4 for Group 6\",\n",
        "        49 : \"Pick Table 5 for Group 6\",\n",
        "        50 : \"Pick Table 6 for Group 6\",\n",
        "        51 : \"Pick Table 1 for Group 7\",\n",
        "        52 : \"Pick Table 2 for Group 7\",\n",
        "        53 : \"Pick Table 3 for Group 7\",\n",
        "        54 : \"Pick Table 4 for Group 7\",\n",
        "        55 : \"Pick Table 5 for Group 7\",\n",
        "        56 : \"Pick Table 6 for Group 7\",\n",
        "    }\n",
        "    return actionIDtoName[actionID]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIfwpn5wnTwk",
        "colab_type": "text"
      },
      "source": [
        "# Policies [Please Edit]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbkVfqVlKED_",
        "colab_type": "text"
      },
      "source": [
        "## Initialise Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN5uGdnlqqmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "# Initialises first env\n",
        "def initEnv(seed=None):\n",
        "  env = gym.make('diner_dash:DinerDash-v0').unwrapped\n",
        "  env.flash_sim = False\n",
        "  \n",
        "  if seed != None:\n",
        "    # sets random seed\n",
        "    env.seed(seed)\n",
        "\n",
        "  obs = env.reset()\n",
        "\n",
        "  return env, obs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47LrGgLLHgzy",
        "colab_type": "text"
      },
      "source": [
        "## Self Implemented/Adapted Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul2Fi9PaPgz7",
        "colab_type": "text"
      },
      "source": [
        "### Random Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StTisAOnPvoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4cYi3VuPjwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Randomly select an action from the action space\n",
        "def testRA(seed):\n",
        "\n",
        "  # init env\n",
        "  env, _ = initEnv(seed=seed)\n",
        "\n",
        "  # init variables\n",
        "  done = False\n",
        "  sumReward = 0\n",
        "  actionList = []\n",
        "\n",
        "  while not done:\n",
        "      action = randint(0, 56)\n",
        "      actionList.append(action)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "      sumReward += reward\n",
        "\n",
        "  return sumReward, actionList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ogJEf9DnYzs",
        "colab_type": "text"
      },
      "source": [
        "### [PPO](https://github.com/nikhilbarhate99/PPO-PyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaLiVAuEnP4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4149966-e8c2-4c53-e394-5c442162f45e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbJ-Mr5ZoCmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory:\n",
        "    def __init__(self):\n",
        "        self.actions = []\n",
        "        self.states = []\n",
        "        self.logprobs = []\n",
        "        self.rewards = []\n",
        "        self.is_terminals = []\n",
        "    \n",
        "    def clear_memory(self):\n",
        "        del self.actions[:]\n",
        "        del self.states[:]\n",
        "        del self.logprobs[:]\n",
        "        del self.rewards[:]\n",
        "        del self.is_terminals[:]\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, n_latent_var):\n",
        "        super(ActorCritic, self).__init__()\n",
        "\n",
        "        # actor\n",
        "        self.action_layer = nn.Sequential(\n",
        "                nn.Linear(state_dim, n_latent_var),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(n_latent_var, n_latent_var),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(n_latent_var, action_dim),\n",
        "                nn.Softmax(dim=-1)\n",
        "                )\n",
        "        \n",
        "        # critic\n",
        "        self.value_layer = nn.Sequential(\n",
        "                nn.Linear(state_dim, n_latent_var),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(n_latent_var, n_latent_var),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(n_latent_var, 1)\n",
        "                )\n",
        "        \n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def act(self, state, memory):\n",
        "        state = torch.from_numpy(state).float().to(device) \n",
        "        action_probs = self.action_layer(state)\n",
        "        dist = Categorical(action_probs)\n",
        "        action = dist.sample()\n",
        "        \n",
        "        memory.states.append(state)\n",
        "        memory.actions.append(action)\n",
        "        memory.logprobs.append(dist.log_prob(action))\n",
        "        \n",
        "        return action.item()\n",
        "    \n",
        "    def evaluate(self, state, action):\n",
        "        action_probs = self.action_layer(state)\n",
        "        dist = Categorical(action_probs)\n",
        "        \n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "        \n",
        "        state_value = self.value_layer(state)\n",
        "        \n",
        "        return action_logprobs, torch.squeeze(state_value), dist_entropy\n",
        "        \n",
        "class PPO:\n",
        "    def __init__(self, state_dim, action_dim, n_latent_var, lr, betas, gamma, K_epochs, eps_clip):\n",
        "        self.lr = lr\n",
        "        self.betas = betas\n",
        "        self.gamma = gamma\n",
        "        self.eps_clip = eps_clip\n",
        "        self.K_epochs = K_epochs\n",
        "        \n",
        "        self.policy = ActorCritic(state_dim, action_dim, n_latent_var).to(device)\n",
        "        self.optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr, betas=betas)\n",
        "        self.policy_old = ActorCritic(state_dim, action_dim, n_latent_var).to(device)\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "        \n",
        "        self.MseLoss = nn.MSELoss()\n",
        "    \n",
        "    def update(self, memory):   \n",
        "        # Monte Carlo estimate of state rewards:\n",
        "        rewards = []\n",
        "        discounted_reward = 0\n",
        "        for reward, is_terminal in zip(reversed(memory.rewards), reversed(memory.is_terminals)):\n",
        "            if is_terminal:\n",
        "                discounted_reward = 0\n",
        "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
        "            rewards.insert(0, discounted_reward)\n",
        "        \n",
        "        # Normalizing the rewards:\n",
        "        rewards = torch.tensor(rewards).to(device)\n",
        "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-5)\n",
        "        \n",
        "        # convert list to tensor\n",
        "        old_states = torch.stack(memory.states).to(device).detach()\n",
        "        old_actions = torch.stack(memory.actions).to(device).detach()\n",
        "        old_logprobs = torch.stack(memory.logprobs).to(device).detach()\n",
        "        \n",
        "        # Optimize policy for K epochs:\n",
        "        for _ in range(self.K_epochs):\n",
        "            # Evaluating old actions and values :\n",
        "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
        "            \n",
        "            # Finding the ratio (pi_theta / pi_theta__old):\n",
        "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
        "                \n",
        "            # Finding Surrogate Loss:\n",
        "            advantages = rewards - state_values.detach()\n",
        "            surr1 = ratios * advantages\n",
        "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
        "            loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
        "            \n",
        "            # take gradient step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.mean().backward()\n",
        "            self.optimizer.step()\n",
        "        \n",
        "        # Copy new weights into old policy:\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eT_jpevGlU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "8fd6f30d-1b9f-487b-ea3d-3fe6bf2ee3aa"
      },
      "source": [
        "def heuristics():\n",
        "  if actionID == 'None':\n",
        "    reward = -10\n",
        "  elif actionID = 'Move To Food Collection':\n",
        "    reward = 100\n",
        "  elif actionID = 'Move To Counter':\n",
        "    reward = 20\n",
        "  elif actionID = 'Move To Table':\n",
        "    reward = 10\n",
        "  elif actionID = 'Pick Up Table':\n",
        "    reward = 10    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-58c5e3352570>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    elif actionID = 'Move To Food Collection':\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb-_zyFloDUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainPPO():\n",
        "    ############## Hyperparameters ##############\n",
        "    # creating environment\n",
        "    env, _ = initEnv()\n",
        "    state_dim = env.observation_space.shape[0]\n",
        "    action_dim = env.action_space.n\n",
        "    log_directory = \"./logs\"     # log directory\n",
        "    log_interval = 500          # print avg reward in the interval\n",
        "    save_interval = int(5e5)    # checkpoints to save model\n",
        "    max_timesteps = int(1e7)    # max training timesteps\n",
        "    n_latent_var = 64           # number of variables in hidden layer\n",
        "    update_timestep = 2000      # update policy every n timesteps\n",
        "    lr = 0.003\n",
        "    betas = (0.9, 0.999)\n",
        "    gamma = 0.99                # discount factor\n",
        "    K_epochs = 4                # update policy for K epochs\n",
        "    eps_clip = 0.2              # clip parameter for PPO\n",
        "    random_seed = None\n",
        "    #############################################\n",
        "    \n",
        "    # Train model\n",
        "    start_time = time.time()\n",
        "\n",
        "    if random_seed:\n",
        "        torch.manual_seed(random_seed)\n",
        "        env.seed(random_seed)\n",
        "    \n",
        "    memory = Memory()\n",
        "    #print(memory)\n",
        "    ppo = PPO(state_dim, action_dim, n_latent_var, lr, betas, gamma, K_epochs, eps_clip)\n",
        "    #print(lr, betas)\n",
        "    #print(state_dim)\n",
        "    #print(action_dim)\n",
        "    #print(n_latent_var)\n",
        "    \n",
        "    # logging variables\n",
        "    running_reward = 0\n",
        "    avg_length = 0\n",
        "    timestep = 0 # train timesteps\n",
        "    t = 0 # timestep within each episode\n",
        "    e = 0 # num of episodes\n",
        "\n",
        "    done = False\n",
        "    \n",
        "    # training loop\n",
        "    while timestep <= max_timesteps:\n",
        "        state = env.reset()\n",
        "        e += 1 # episode number\n",
        "        while not done:\n",
        "            timestep += 1\n",
        "            t += 1 # timestep within each episode\n",
        "\n",
        "            if timestep == max_timesteps:\n",
        "                torch.save(ppo.policy.state_dict(), f'./PPO_diner-dash_{timestep:.0e}.pth')\n",
        "                print(f\"--- Time take to train model = {(time.time() - start_time)//60} minutes ---\")\n",
        "                return\n",
        "            \n",
        "            # Running policy_old:\n",
        "            action = ppo.policy_old.act(state, memory)\n",
        "            #print(action)\n",
        "            state, reward, done, _ = env.step(action)\n",
        "            #print(state)\n",
        "            #print(reward)\n",
        "            #print(done)\n",
        "            # Saving reward and is_terminal:\n",
        "            memory.rewards.append(reward)\n",
        "            memory.is_terminals.append(done)\n",
        "            #print(memory)\n",
        "            # update if its time\n",
        "            if timestep % update_timestep == 0:\n",
        "                ppo.update(memory)\n",
        "                memory.clear_memory()\n",
        "\n",
        "            # save model at checkpoints\n",
        "            if timestep % save_interval == 0:\n",
        "                if not path.isdir(log_directory):\n",
        "                    mkdir(log_directory)\n",
        "                torch.save(ppo.policy.state_dict(), f'{log_directory}/PPO_diner-dash_{timestep:.0e}.pth')\n",
        "            \n",
        "            running_reward += reward\n",
        "                \n",
        "        avg_length += t\n",
        "\n",
        "        # reset timestep t and done since episode ended\n",
        "        t = 0\n",
        "        done = False\n",
        "            \n",
        "        # logging\n",
        "        if e % log_interval == 0:\n",
        "            avg_length = int(avg_length/log_interval)\n",
        "            running_reward = int((running_reward/log_interval))\n",
        "            \n",
        "            print('Episode {} \\t avg length: {} \\t reward: {}'.format(e, avg_length, running_reward))\n",
        "            running_reward = 0\n",
        "            avg_length = 0\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c06KtkyZLHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "1fde8c6e-d9af-45cf-f9dc-1e7494ed5646"
      },
      "source": [
        "trainPPO()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c6945f1b8871>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainPPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-3858fedaf0df>\u001b[0m in \u001b[0;36mtrainPPO\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# Running policy_old:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;31m#print(action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-5521f6d2677a>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state, memory)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUE1qOV9MN3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testPPO(seed):\n",
        "    ############## Hyperparameters ##############\n",
        "    # creating environment\n",
        "    env, obs = initEnv(seed=seed)\n",
        "    state_dim = env.observation_space.shape[0]\n",
        "    action_dim = env.action_space.n\n",
        "    n_latent_var = 64           # number of variables in hidden layer\n",
        "    filename = \"./PPO_diner-dash_1e+07.pth\" # path to saved model\n",
        "    lr = 0.0007\n",
        "    betas = (0.9, 0.999)\n",
        "    gamma = 0.99                # discount factor\n",
        "    K_epochs = 4                # update policy for K epochs\n",
        "    eps_clip = 0.2              # clip parameter for PPO\n",
        "    #############################################\n",
        "    \n",
        "    memory = Memory()\n",
        "    ppo = PPO(state_dim, action_dim, n_latent_var, lr, betas, gamma, K_epochs, eps_clip)\n",
        "    \n",
        "    ppo.policy_old.load_state_dict(torch.load(filename))\n",
        "\n",
        "    ep_reward = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "      action = ppo.policy_old.act(obs, memory)\n",
        "      obs, reward, done, _ = env.step(action)\n",
        "      ep_reward += reward\n",
        "\n",
        "    actionList = [action.item() for action in memory.actions]\n",
        "\n",
        "    return ep_reward, actionList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9AaOurkA68o",
        "colab_type": "text"
      },
      "source": [
        "## [Stable Baselines](https://github.com/hill-a/stable-baselines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhlZv0u3Wyn6",
        "colab_type": "text"
      },
      "source": [
        "### Check Env setup for Stable Baselines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPuA_s1cyeC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5f723c89-4bc3-4322-b3da-002d18e891f6"
      },
      "source": [
        "from stable_baselines.common.env_checker import check_env"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkerSMaSym9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33814b9e-ffdf-4654-a7df-dbb496de3ba9"
      },
      "source": [
        "error = check_env(gym.make('diner_dash:DinerDash-v0').unwrapped)\n",
        "if error == None:\n",
        "  print(\"Diner Dash environment is compatible with Stable-Baselines!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diner Dash environment is compatible with Stable-Baselines!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZN2HqxQXU5j",
        "colab_type": "text"
      },
      "source": [
        "### Saving Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgzEa-0CFK0H",
        "colab_type": "text"
      },
      "source": [
        "#### Using Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJSvrc-hGlz-",
        "colab_type": "text"
      },
      "source": [
        "- Save a checkpoint every 1000 steps\n",
        "- Please change the callback variable name and name_prefix to whatever desire/specific to model\n",
        "- Model saved in ./logs directory\n",
        "\n",
        "  `PPO_callback = CheckpointCallback(save_freq=1000, save_path='./logs/', name_prefix='diner-dash-PPO')`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHqMaCOzFM2X",
        "colab_type": "text"
      },
      "source": [
        "#### Using save function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fagmv0RGGGq",
        "colab_type": "text"
      },
      "source": [
        "- Model saved in current directory\n",
        "\n",
        "  `model.save('name-of-model')`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUaGTTZKHDCV",
        "colab_type": "text"
      },
      "source": [
        "### Loading Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__TWINPkHMMM",
        "colab_type": "text"
      },
      "source": [
        "- If only for evaluation\n",
        "\n",
        "  `PPO_model = PPO2.load('name-of-model')`\n",
        "\n",
        "  `PPO_model.predict(state)`\n",
        "\n",
        "- If loading for further training\n",
        "\n",
        "  `PPO_model = PPO2.load('name-of-model', env)`\n",
        "\n",
        "  `PPO_model.learn(5000)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kITom2RTpWSK",
        "colab_type": "text"
      },
      "source": [
        "### Wrapper for better training performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1WOnn4XpdYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OneHotWrapper(gym.Wrapper):\n",
        "  \"\"\"\n",
        "  :param env: (gym.Env) Gym environment that will be wrapped\n",
        "  \"\"\"\n",
        "  def __init__(self, env):\n",
        "    # Call the parent constructor, so we can access self.env later\n",
        "    super(OneHotWrapper, self).__init__(env)\n",
        "    self.config = [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, \n",
        "                   2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, \n",
        "                   7, 7, 19, 19]\n",
        "    self.low_state = np.array([-20] * sum(self.config), dtype=np.float32)\n",
        "    self.high_state = np.array([20] * sum(self.config), dtype=np.float32)\n",
        "    self.observation_space = gym.spaces.Box(low=self.low_state, high=self.high_state, dtype=np.float32)\n",
        "\n",
        "  def oneHotEncode(self, rawObs):\n",
        "    for i, val in enumerate(rawObs):\n",
        "      tmp = np.zeros(self.config[i])\n",
        "      tmp[val] = 1\n",
        "      if i == 0:\n",
        "        obs = tmp\n",
        "      else:\n",
        "        obs = np.concatenate((obs, tmp))\n",
        "    return obs\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"\n",
        "    Reset the environment \n",
        "    \"\"\"\n",
        "    obs = self.env.reset()\n",
        "    return self.oneHotEncode(obs)\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"\n",
        "    :param action: ([float] or int) Action taken by the agent\n",
        "    :return: (np.ndarray, float, bool, dict) observation, reward, is the episode over?, additional informations\n",
        "    \"\"\"\n",
        "    obs, reward, done, info = self.env.step(action)\n",
        "    return self.oneHotEncode(obs), reward, done, info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWruL1pM4X5H",
        "colab_type": "text"
      },
      "source": [
        "### PPO2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq_Cj8iR0Rqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b7127c6-ceee-4183-a6e7-626a5c28a21f"
      },
      "source": [
        "# Refer to the stable baseline documentation for alternative implementations\n",
        "# of callbacks, baselines and others\n",
        "from stable_baselines.common.callbacks import CheckpointCallback\n",
        "from stable_baselines.common import make_vec_env\n",
        "from stable_baselines import PPO2\n",
        "\n",
        "# fixed params for challenge\n",
        "# Total timesteps for training\n",
        "tts = int(1e7) \n",
        "\n",
        "# custom params\n",
        "n_envs = 24\n",
        "save_freq = int(1e5)\n",
        "log_interval = 500\n",
        "\n",
        "# Vectorize environment\n",
        "env = make_vec_env(env_id=\"diner_dash:DinerDash-v0\", n_envs=n_envs, wrapper_class=OneHotWrapper)\n",
        "\n",
        "# Initialise model\n",
        "model = PPO2('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Initialise callback\n",
        "ppo2_callback = CheckpointCallback(save_freq=save_freq, save_path=f'./logs-PPO2-nenv={n_envs}-tts={tts:.0e}/', name_prefix='diner-dash-PPO')\n",
        "\n",
        "# Train model\n",
        "start_time = time.time()\n",
        "model.learn(total_timesteps=tts, log_interval=log_interval, callback=ppo2_callback)\n",
        "print(f\"--- Time take to train model = {(time.time() - start_time)//60} minutes ---\")\n",
        "\n",
        "# Save model\n",
        "print(\"Saving Final Model...\")\n",
        "modelDirectory = \"./\"\n",
        "modelName = f\"PPO2-nenv={n_envs}-tts={tts:.0e}\"\n",
        "model.save(modelDirectory + modelName)\n",
        "print(f\"Model saved as {modelDirectory + modelName}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:240: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "---------------------------------------\n",
            "| approxkl           | 1.1049222e-05  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 114            |\n",
            "| ep_reward_mean     | -1.47e+03      |\n",
            "| explained_variance | -0.000454      |\n",
            "| fps                | 1084           |\n",
            "| n_updates          | 1              |\n",
            "| policy_entropy     | 4.043029       |\n",
            "| policy_loss        | -0.00075966347 |\n",
            "| serial_timesteps   | 128            |\n",
            "| time_elapsed       | 2.98e-05       |\n",
            "| total_timesteps    | 3072           |\n",
            "| value_loss         | 31449.564      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 6.89558e-05   |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 138           |\n",
            "| ep_reward_mean     | -913          |\n",
            "| explained_variance | 0.261         |\n",
            "| fps                | 3176          |\n",
            "| n_updates          | 500           |\n",
            "| policy_entropy     | 3.603277      |\n",
            "| policy_loss        | -0.0004548415 |\n",
            "| serial_timesteps   | 64000         |\n",
            "| time_elapsed       | 471           |\n",
            "| total_timesteps    | 1536000       |\n",
            "| value_loss         | 17767.914     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 2.3481443e-05  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 143            |\n",
            "| ep_reward_mean     | -468           |\n",
            "| explained_variance | 0.514          |\n",
            "| fps                | 3232           |\n",
            "| n_updates          | 1000           |\n",
            "| policy_entropy     | 3.2395377      |\n",
            "| policy_loss        | -3.6705742e-06 |\n",
            "| serial_timesteps   | 128000         |\n",
            "| time_elapsed       | 942            |\n",
            "| total_timesteps    | 3072000        |\n",
            "| value_loss         | 9482.277       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 4.8635542e-05  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 143            |\n",
            "| ep_reward_mean     | -269           |\n",
            "| explained_variance | 0.679          |\n",
            "| fps                | 3324           |\n",
            "| n_updates          | 1500           |\n",
            "| policy_entropy     | 3.1611025      |\n",
            "| policy_loss        | -1.3781293e-05 |\n",
            "| serial_timesteps   | 192000         |\n",
            "| time_elapsed       | 1.42e+03       |\n",
            "| total_timesteps    | 4608000        |\n",
            "| value_loss         | 6857.4253      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0001274062  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 145           |\n",
            "| ep_reward_mean     | 84            |\n",
            "| explained_variance | 0.736         |\n",
            "| fps                | 3257          |\n",
            "| n_updates          | 2000          |\n",
            "| policy_entropy     | 2.7270665     |\n",
            "| policy_loss        | -0.0004658993 |\n",
            "| serial_timesteps   | 256000        |\n",
            "| time_elapsed       | 1.89e+03      |\n",
            "| total_timesteps    | 6144000       |\n",
            "| value_loss         | 4103.301      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.00018459136  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 150            |\n",
            "| ep_reward_mean     | 462            |\n",
            "| explained_variance | 0.794          |\n",
            "| fps                | 3393           |\n",
            "| n_updates          | 2500           |\n",
            "| policy_entropy     | 2.1806297      |\n",
            "| policy_loss        | -0.00053580396 |\n",
            "| serial_timesteps   | 320000         |\n",
            "| time_elapsed       | 2.35e+03       |\n",
            "| total_timesteps    | 7680000        |\n",
            "| value_loss         | 1253.8744      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0032399874  |\n",
            "| clipfrac           | 0.015055338   |\n",
            "| ep_len_mean        | 152           |\n",
            "| ep_reward_mean     | 581           |\n",
            "| explained_variance | 0.765         |\n",
            "| fps                | 3370          |\n",
            "| n_updates          | 3000          |\n",
            "| policy_entropy     | 2.26905       |\n",
            "| policy_loss        | 0.00036377698 |\n",
            "| serial_timesteps   | 384000        |\n",
            "| time_elapsed       | 2.84e+03      |\n",
            "| total_timesteps    | 9216000       |\n",
            "| value_loss         | 1692.126      |\n",
            "--------------------------------------\n",
            "--- Time take to train model = 51.0 minutes ---\n",
            "Saving Final Model...\n",
            "Model saved as ./PPO2-nenv=24-tts=1e+07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AhDY9hj1rht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testPPO2(seed):\n",
        "  from stable_baselines.common import make_vec_env\n",
        "  from stable_baselines import PPO2\n",
        "\n",
        "  # Vectorize environment with given seed\n",
        "  env = make_vec_env(env_id=\"diner_dash:DinerDash-v0\", wrapper_class=OneHotWrapper, seed=seed)\n",
        "\n",
        "  # Load saved model\n",
        "  PPO_model = PPO2.load(\"PPO2-nenv=24-tts=1e+07\", env=env)\n",
        "\n",
        "  # Reset environment, init obs\n",
        "  obs = env.reset()\n",
        "\n",
        "  done = False\n",
        "  sum_rewards = 0\n",
        "  action_list = []\n",
        "\n",
        "  while not done:\n",
        "    action, _states = PPO_model.predict(obs)\n",
        "    action_list.append(action.item())\n",
        "    obs, rewards, done, info = env.step(action)\n",
        "    sum_rewards += rewards\n",
        "\n",
        "  return sum_rewards, action_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l1xjdpNnfs8",
        "colab_type": "text"
      },
      "source": [
        "### A2C\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCzAniF-nWSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d653b3c1-3ac2-4377-dc68-51c136e580b0"
      },
      "source": [
        "# Refer to the stable baseline documentation for alternative implementations\n",
        "# of callbacks, baselines and others\n",
        "from stable_baselines.common.callbacks import CheckpointCallback\n",
        "from stable_baselines.common import make_vec_env\n",
        "from stable_baselines import A2C\n",
        "\n",
        "# fixed params for challenge\n",
        "# Total timesteps for training\n",
        "tts = int(1e7) \n",
        "\n",
        "# custom params\n",
        "n_envs = 24\n",
        "save_freq = int(1e5)\n",
        "log_interval = 500\n",
        "\n",
        "# Vectorize environment\n",
        "env = make_vec_env(env_id=\"diner_dash:DinerDash-v0\", n_envs=n_envs, wrapper_class=OneHotWrapper)\n",
        "\n",
        "# Initialise model\n",
        "model = A2C('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Initialise callback\n",
        "ppo2_callback = CheckpointCallback(save_freq=save_freq, save_path=f'./logs-A2C-nenv={n_envs}-tts={tts:.0e}/', name_prefix='diner-dash-A2C')\n",
        "\n",
        "# Train model\n",
        "start_time = time.time()\n",
        "model.learn(total_timesteps=tts, log_interval=log_interval, callback=ppo2_callback)\n",
        "print(f\"--- Time take to train model = {(time.time() - start_time)//60} minutes ---\")\n",
        "\n",
        "# Save model\n",
        "print(\"Saving Final Model...\")\n",
        "modelDirectory = \"./\"\n",
        "modelName = f\"A2C-nenv={n_envs}-tts={tts:.0e}\"\n",
        "model.save(modelDirectory + modelName)\n",
        "print(f\"Model saved as {modelDirectory + modelName}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------\n",
            "| explained_variance | -0.000789 |\n",
            "| fps                | 479       |\n",
            "| nupdates           | 1         |\n",
            "| policy_entropy     | 4.04      |\n",
            "| total_timesteps    | 120       |\n",
            "| value_loss         | 8.07      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 135       |\n",
            "| ep_reward_mean     | -1.31e+03 |\n",
            "| explained_variance | -0.00252  |\n",
            "| fps                | 3116      |\n",
            "| nupdates           | 500       |\n",
            "| policy_entropy     | 4.04      |\n",
            "| total_timesteps    | 60000     |\n",
            "| value_loss         | 4.17e+03  |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 139       |\n",
            "| ep_reward_mean     | -1.21e+03 |\n",
            "| explained_variance | 0.00047   |\n",
            "| fps                | 3125      |\n",
            "| nupdates           | 1000      |\n",
            "| policy_entropy     | 4.04      |\n",
            "| total_timesteps    | 120000    |\n",
            "| value_loss         | 2.99e+04  |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 138       |\n",
            "| ep_reward_mean     | -1.16e+03 |\n",
            "| explained_variance | 0.000222  |\n",
            "| fps                | 3135      |\n",
            "| nupdates           | 1500      |\n",
            "| policy_entropy     | 3.95      |\n",
            "| total_timesteps    | 180000    |\n",
            "| value_loss         | 1.82e+04  |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 137      |\n",
            "| ep_reward_mean     | -914     |\n",
            "| explained_variance | 0.0847   |\n",
            "| fps                | 3139     |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 3.32     |\n",
            "| total_timesteps    | 240000   |\n",
            "| value_loss         | 1.02e+04 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 144      |\n",
            "| ep_reward_mean     | -811     |\n",
            "| explained_variance | 0.493    |\n",
            "| fps                | 3141     |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 2.97     |\n",
            "| total_timesteps    | 300000   |\n",
            "| value_loss         | 1.79e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 140      |\n",
            "| ep_reward_mean     | -795     |\n",
            "| explained_variance | 0.261    |\n",
            "| fps                | 3138     |\n",
            "| nupdates           | 3000     |\n",
            "| policy_entropy     | 2.98     |\n",
            "| total_timesteps    | 360000   |\n",
            "| value_loss         | 9.14e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 142      |\n",
            "| ep_reward_mean     | -722     |\n",
            "| explained_variance | 0.36     |\n",
            "| fps                | 3119     |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 2.99     |\n",
            "| total_timesteps    | 420000   |\n",
            "| value_loss         | 7.27e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 144      |\n",
            "| ep_reward_mean     | -688     |\n",
            "| explained_variance | 0.684    |\n",
            "| fps                | 3103     |\n",
            "| nupdates           | 4000     |\n",
            "| policy_entropy     | 3        |\n",
            "| total_timesteps    | 480000   |\n",
            "| value_loss         | 1.62e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 144      |\n",
            "| ep_reward_mean     | -728     |\n",
            "| explained_variance | 0.336    |\n",
            "| fps                | 3089     |\n",
            "| nupdates           | 4500     |\n",
            "| policy_entropy     | 3.05     |\n",
            "| total_timesteps    | 540000   |\n",
            "| value_loss         | 2.12e+04 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 146      |\n",
            "| ep_reward_mean     | -597     |\n",
            "| explained_variance | 0.902    |\n",
            "| fps                | 3080     |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 2.94     |\n",
            "| total_timesteps    | 600000   |\n",
            "| value_loss         | 513      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 143      |\n",
            "| ep_reward_mean     | -453     |\n",
            "| explained_variance | 0.416    |\n",
            "| fps                | 3069     |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 2.81     |\n",
            "| total_timesteps    | 660000   |\n",
            "| value_loss         | 7.31e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 145      |\n",
            "| ep_reward_mean     | -644     |\n",
            "| explained_variance | 0.542    |\n",
            "| fps                | 3064     |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 2.63     |\n",
            "| total_timesteps    | 720000   |\n",
            "| value_loss         | 7.79e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 147      |\n",
            "| ep_reward_mean     | -428     |\n",
            "| explained_variance | 0.554    |\n",
            "| fps                | 3057     |\n",
            "| nupdates           | 6500     |\n",
            "| policy_entropy     | 2.68     |\n",
            "| total_timesteps    | 780000   |\n",
            "| value_loss         | 8.43e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 146      |\n",
            "| ep_reward_mean     | -511     |\n",
            "| explained_variance | 0.768    |\n",
            "| fps                | 3052     |\n",
            "| nupdates           | 7000     |\n",
            "| policy_entropy     | 2.72     |\n",
            "| total_timesteps    | 840000   |\n",
            "| value_loss         | 2.4e+03  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 149      |\n",
            "| ep_reward_mean     | -468     |\n",
            "| explained_variance | 0.438    |\n",
            "| fps                | 3047     |\n",
            "| nupdates           | 7500     |\n",
            "| policy_entropy     | 2.6      |\n",
            "| total_timesteps    | 900000   |\n",
            "| value_loss         | 1.48e+04 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | -307     |\n",
            "| explained_variance | 0.943    |\n",
            "| fps                | 3043     |\n",
            "| nupdates           | 8000     |\n",
            "| policy_entropy     | 2.52     |\n",
            "| total_timesteps    | 960000   |\n",
            "| value_loss         | 584      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 148      |\n",
            "| ep_reward_mean     | -246     |\n",
            "| explained_variance | 0.69     |\n",
            "| fps                | 3039     |\n",
            "| nupdates           | 8500     |\n",
            "| policy_entropy     | 2.55     |\n",
            "| total_timesteps    | 1020000  |\n",
            "| value_loss         | 4.91e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 149      |\n",
            "| ep_reward_mean     | -241     |\n",
            "| explained_variance | 0.672    |\n",
            "| fps                | 3037     |\n",
            "| nupdates           | 9000     |\n",
            "| policy_entropy     | 2.48     |\n",
            "| total_timesteps    | 1080000  |\n",
            "| value_loss         | 5.78e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 152      |\n",
            "| ep_reward_mean     | -209     |\n",
            "| explained_variance | 0.682    |\n",
            "| fps                | 3036     |\n",
            "| nupdates           | 9500     |\n",
            "| policy_entropy     | 2.36     |\n",
            "| total_timesteps    | 1140000  |\n",
            "| value_loss         | 2.29e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 148      |\n",
            "| ep_reward_mean     | -108     |\n",
            "| explained_variance | 0.636    |\n",
            "| fps                | 3034     |\n",
            "| nupdates           | 10000    |\n",
            "| policy_entropy     | 2.32     |\n",
            "| total_timesteps    | 1200000  |\n",
            "| value_loss         | 8.45e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | -73.5    |\n",
            "| explained_variance | 0.673    |\n",
            "| fps                | 3033     |\n",
            "| nupdates           | 10500    |\n",
            "| policy_entropy     | 2.22     |\n",
            "| total_timesteps    | 1260000  |\n",
            "| value_loss         | 3.56e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 36.6     |\n",
            "| explained_variance | 0.964    |\n",
            "| fps                | 3033     |\n",
            "| nupdates           | 11000    |\n",
            "| policy_entropy     | 2.15     |\n",
            "| total_timesteps    | 1320000  |\n",
            "| value_loss         | 526      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 149      |\n",
            "| ep_reward_mean     | 13.5     |\n",
            "| explained_variance | 0.913    |\n",
            "| fps                | 3030     |\n",
            "| nupdates           | 11500    |\n",
            "| policy_entropy     | 2.1      |\n",
            "| total_timesteps    | 1380000  |\n",
            "| value_loss         | 726      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 151      |\n",
            "| ep_reward_mean     | 8.3      |\n",
            "| explained_variance | 0.65     |\n",
            "| fps                | 3029     |\n",
            "| nupdates           | 12000    |\n",
            "| policy_entropy     | 2.04     |\n",
            "| total_timesteps    | 1440000  |\n",
            "| value_loss         | 2.87e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 25       |\n",
            "| explained_variance | 0.853    |\n",
            "| fps                | 3029     |\n",
            "| nupdates           | 12500    |\n",
            "| policy_entropy     | 1.89     |\n",
            "| total_timesteps    | 1500000  |\n",
            "| value_loss         | 2.81e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 147      |\n",
            "| ep_reward_mean     | 87.9     |\n",
            "| explained_variance | 0.889    |\n",
            "| fps                | 3033     |\n",
            "| nupdates           | 13000    |\n",
            "| policy_entropy     | 1.88     |\n",
            "| total_timesteps    | 1560000  |\n",
            "| value_loss         | 2.11e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 146      |\n",
            "| ep_reward_mean     | 53.1     |\n",
            "| explained_variance | 0.883    |\n",
            "| fps                | 3041     |\n",
            "| nupdates           | 13500    |\n",
            "| policy_entropy     | 1.85     |\n",
            "| total_timesteps    | 1620000  |\n",
            "| value_loss         | 1.59e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 156      |\n",
            "| ep_reward_mean     | 85       |\n",
            "| explained_variance | 0.794    |\n",
            "| fps                | 3050     |\n",
            "| nupdates           | 14000    |\n",
            "| policy_entropy     | 1.85     |\n",
            "| total_timesteps    | 1680000  |\n",
            "| value_loss         | 2.27e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 154      |\n",
            "| ep_reward_mean     | 184      |\n",
            "| explained_variance | 0.958    |\n",
            "| fps                | 3060     |\n",
            "| nupdates           | 14500    |\n",
            "| policy_entropy     | 1.78     |\n",
            "| total_timesteps    | 1740000  |\n",
            "| value_loss         | 183      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 152      |\n",
            "| ep_reward_mean     | 157      |\n",
            "| explained_variance | 0.46     |\n",
            "| fps                | 3069     |\n",
            "| nupdates           | 15000    |\n",
            "| policy_entropy     | 1.72     |\n",
            "| total_timesteps    | 1800000  |\n",
            "| value_loss         | 3.2e+03  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 148      |\n",
            "| ep_reward_mean     | 121      |\n",
            "| explained_variance | 0.933    |\n",
            "| fps                | 3076     |\n",
            "| nupdates           | 15500    |\n",
            "| policy_entropy     | 1.81     |\n",
            "| total_timesteps    | 1860000  |\n",
            "| value_loss         | 1.01e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 151      |\n",
            "| ep_reward_mean     | 128      |\n",
            "| explained_variance | 0.85     |\n",
            "| fps                | 3084     |\n",
            "| nupdates           | 16000    |\n",
            "| policy_entropy     | 1.68     |\n",
            "| total_timesteps    | 1920000  |\n",
            "| value_loss         | 1.22e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 153      |\n",
            "| ep_reward_mean     | 141      |\n",
            "| explained_variance | 0.88     |\n",
            "| fps                | 3092     |\n",
            "| nupdates           | 16500    |\n",
            "| policy_entropy     | 1.74     |\n",
            "| total_timesteps    | 1980000  |\n",
            "| value_loss         | 1.86e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 148      |\n",
            "| ep_reward_mean     | 131      |\n",
            "| explained_variance | 0.91     |\n",
            "| fps                | 3099     |\n",
            "| nupdates           | 17000    |\n",
            "| policy_entropy     | 1.61     |\n",
            "| total_timesteps    | 2040000  |\n",
            "| value_loss         | 473      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 126      |\n",
            "| explained_variance | 0.905    |\n",
            "| fps                | 3107     |\n",
            "| nupdates           | 17500    |\n",
            "| policy_entropy     | 1.7      |\n",
            "| total_timesteps    | 2100000  |\n",
            "| value_loss         | 214      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 154      |\n",
            "| ep_reward_mean     | 149      |\n",
            "| explained_variance | 0.865    |\n",
            "| fps                | 3113     |\n",
            "| nupdates           | 18000    |\n",
            "| policy_entropy     | 1.69     |\n",
            "| total_timesteps    | 2160000  |\n",
            "| value_loss         | 1.75e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 190      |\n",
            "| explained_variance | 0.835    |\n",
            "| fps                | 3120     |\n",
            "| nupdates           | 18500    |\n",
            "| policy_entropy     | 1.6      |\n",
            "| total_timesteps    | 2220000  |\n",
            "| value_loss         | 2.07e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 152      |\n",
            "| ep_reward_mean     | 192      |\n",
            "| explained_variance | 0.984    |\n",
            "| fps                | 3126     |\n",
            "| nupdates           | 19000    |\n",
            "| policy_entropy     | 1.61     |\n",
            "| total_timesteps    | 2280000  |\n",
            "| value_loss         | 145      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 148      |\n",
            "| ep_reward_mean     | 208      |\n",
            "| explained_variance | 0.937    |\n",
            "| fps                | 3131     |\n",
            "| nupdates           | 19500    |\n",
            "| policy_entropy     | 1.63     |\n",
            "| total_timesteps    | 2340000  |\n",
            "| value_loss         | 610      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 157      |\n",
            "| ep_reward_mean     | 268      |\n",
            "| explained_variance | 0.941    |\n",
            "| fps                | 3137     |\n",
            "| nupdates           | 20000    |\n",
            "| policy_entropy     | 1.66     |\n",
            "| total_timesteps    | 2400000  |\n",
            "| value_loss         | 663      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 152      |\n",
            "| ep_reward_mean     | 167      |\n",
            "| explained_variance | 0.81     |\n",
            "| fps                | 3147     |\n",
            "| nupdates           | 21000    |\n",
            "| policy_entropy     | 1.58     |\n",
            "| total_timesteps    | 2520000  |\n",
            "| value_loss         | 2.66e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 146      |\n",
            "| ep_reward_mean     | 180      |\n",
            "| explained_variance | 0.976    |\n",
            "| fps                | 3152     |\n",
            "| nupdates           | 21500    |\n",
            "| policy_entropy     | 1.52     |\n",
            "| total_timesteps    | 2580000  |\n",
            "| value_loss         | 283      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 152      |\n",
            "| ep_reward_mean     | 228      |\n",
            "| explained_variance | 0.491    |\n",
            "| fps                | 3157     |\n",
            "| nupdates           | 22000    |\n",
            "| policy_entropy     | 1.58     |\n",
            "| total_timesteps    | 2640000  |\n",
            "| value_loss         | 4.05e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 148      |\n",
            "| ep_reward_mean     | 218      |\n",
            "| explained_variance | 0.783    |\n",
            "| fps                | 3161     |\n",
            "| nupdates           | 22500    |\n",
            "| policy_entropy     | 1.57     |\n",
            "| total_timesteps    | 2700000  |\n",
            "| value_loss         | 3.16e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 153      |\n",
            "| ep_reward_mean     | 237      |\n",
            "| explained_variance | 0.916    |\n",
            "| fps                | 3165     |\n",
            "| nupdates           | 23000    |\n",
            "| policy_entropy     | 1.48     |\n",
            "| total_timesteps    | 2760000  |\n",
            "| value_loss         | 746      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 149      |\n",
            "| ep_reward_mean     | 236      |\n",
            "| explained_variance | 0.891    |\n",
            "| fps                | 3170     |\n",
            "| nupdates           | 23500    |\n",
            "| policy_entropy     | 1.53     |\n",
            "| total_timesteps    | 2820000  |\n",
            "| value_loss         | 2.3e+03  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 146      |\n",
            "| ep_reward_mean     | 229      |\n",
            "| explained_variance | 0.743    |\n",
            "| fps                | 3173     |\n",
            "| nupdates           | 24000    |\n",
            "| policy_entropy     | 1.51     |\n",
            "| total_timesteps    | 2880000  |\n",
            "| value_loss         | 8.16e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 147      |\n",
            "| ep_reward_mean     | 178      |\n",
            "| explained_variance | 0.865    |\n",
            "| fps                | 3175     |\n",
            "| nupdates           | 24500    |\n",
            "| policy_entropy     | 1.54     |\n",
            "| total_timesteps    | 2940000  |\n",
            "| value_loss         | 741      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 151      |\n",
            "| ep_reward_mean     | 302      |\n",
            "| explained_variance | 0.956    |\n",
            "| fps                | 3178     |\n",
            "| nupdates           | 25000    |\n",
            "| policy_entropy     | 1.52     |\n",
            "| total_timesteps    | 3000000  |\n",
            "| value_loss         | 199      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 299      |\n",
            "| explained_variance | 0.62     |\n",
            "| fps                | 3181     |\n",
            "| nupdates           | 25500    |\n",
            "| policy_entropy     | 1.5      |\n",
            "| total_timesteps    | 3060000  |\n",
            "| value_loss         | 1.96e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 153      |\n",
            "| ep_reward_mean     | 276      |\n",
            "| explained_variance | 0.7      |\n",
            "| fps                | 3184     |\n",
            "| nupdates           | 26000    |\n",
            "| policy_entropy     | 1.53     |\n",
            "| total_timesteps    | 3120000  |\n",
            "| value_loss         | 5.12e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 152      |\n",
            "| ep_reward_mean     | 236      |\n",
            "| explained_variance | 0.927    |\n",
            "| fps                | 3187     |\n",
            "| nupdates           | 26500    |\n",
            "| policy_entropy     | 1.54     |\n",
            "| total_timesteps    | 3180000  |\n",
            "| value_loss         | 222      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 151      |\n",
            "| ep_reward_mean     | 236      |\n",
            "| explained_variance | 0.906    |\n",
            "| fps                | 3190     |\n",
            "| nupdates           | 27000    |\n",
            "| policy_entropy     | 1.41     |\n",
            "| total_timesteps    | 3240000  |\n",
            "| value_loss         | 703      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 149      |\n",
            "| ep_reward_mean     | 304      |\n",
            "| explained_variance | 0.969    |\n",
            "| fps                | 3193     |\n",
            "| nupdates           | 27500    |\n",
            "| policy_entropy     | 1.49     |\n",
            "| total_timesteps    | 3300000  |\n",
            "| value_loss         | 135      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 342      |\n",
            "| explained_variance | 0.956    |\n",
            "| fps                | 3195     |\n",
            "| nupdates           | 28000    |\n",
            "| policy_entropy     | 1.39     |\n",
            "| total_timesteps    | 3360000  |\n",
            "| value_loss         | 455      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 148      |\n",
            "| ep_reward_mean     | 240      |\n",
            "| explained_variance | 0.965    |\n",
            "| fps                | 3197     |\n",
            "| nupdates           | 28500    |\n",
            "| policy_entropy     | 1.42     |\n",
            "| total_timesteps    | 3420000  |\n",
            "| value_loss         | 191      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 152      |\n",
            "| ep_reward_mean     | 291      |\n",
            "| explained_variance | 0.945    |\n",
            "| fps                | 3200     |\n",
            "| nupdates           | 29000    |\n",
            "| policy_entropy     | 1.51     |\n",
            "| total_timesteps    | 3480000  |\n",
            "| value_loss         | 348      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 153      |\n",
            "| ep_reward_mean     | 306      |\n",
            "| explained_variance | 0.984    |\n",
            "| fps                | 3202     |\n",
            "| nupdates           | 29500    |\n",
            "| policy_entropy     | 1.44     |\n",
            "| total_timesteps    | 3540000  |\n",
            "| value_loss         | 128      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 348      |\n",
            "| explained_variance | 0.903    |\n",
            "| fps                | 3205     |\n",
            "| nupdates           | 30000    |\n",
            "| policy_entropy     | 1.5      |\n",
            "| total_timesteps    | 3600000  |\n",
            "| value_loss         | 1.17e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 315      |\n",
            "| explained_variance | 0.83     |\n",
            "| fps                | 3207     |\n",
            "| nupdates           | 30500    |\n",
            "| policy_entropy     | 1.34     |\n",
            "| total_timesteps    | 3660000  |\n",
            "| value_loss         | 723      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 329      |\n",
            "| explained_variance | 0.713    |\n",
            "| fps                | 3209     |\n",
            "| nupdates           | 31000    |\n",
            "| policy_entropy     | 1.37     |\n",
            "| total_timesteps    | 3720000  |\n",
            "| value_loss         | 2.2e+03  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 153      |\n",
            "| ep_reward_mean     | 320      |\n",
            "| explained_variance | 0.781    |\n",
            "| fps                | 3211     |\n",
            "| nupdates           | 31500    |\n",
            "| policy_entropy     | 1.39     |\n",
            "| total_timesteps    | 3780000  |\n",
            "| value_loss         | 7.82e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 155      |\n",
            "| ep_reward_mean     | 428      |\n",
            "| explained_variance | 0.927    |\n",
            "| fps                | 3213     |\n",
            "| nupdates           | 32000    |\n",
            "| policy_entropy     | 1.4      |\n",
            "| total_timesteps    | 3840000  |\n",
            "| value_loss         | 656      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 153      |\n",
            "| ep_reward_mean     | 381      |\n",
            "| explained_variance | 0.29     |\n",
            "| fps                | 3215     |\n",
            "| nupdates           | 32500    |\n",
            "| policy_entropy     | 1.31     |\n",
            "| total_timesteps    | 3900000  |\n",
            "| value_loss         | 1.45e+04 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 154      |\n",
            "| ep_reward_mean     | 429      |\n",
            "| explained_variance | 0.913    |\n",
            "| fps                | 3217     |\n",
            "| nupdates           | 33000    |\n",
            "| policy_entropy     | 1.41     |\n",
            "| total_timesteps    | 3960000  |\n",
            "| value_loss         | 269      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 157      |\n",
            "| ep_reward_mean     | 431      |\n",
            "| explained_variance | 0.621    |\n",
            "| fps                | 3219     |\n",
            "| nupdates           | 33500    |\n",
            "| policy_entropy     | 1.36     |\n",
            "| total_timesteps    | 4020000  |\n",
            "| value_loss         | 540      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 155      |\n",
            "| ep_reward_mean     | 506      |\n",
            "| explained_variance | 0.935    |\n",
            "| fps                | 3221     |\n",
            "| nupdates           | 34000    |\n",
            "| policy_entropy     | 1.43     |\n",
            "| total_timesteps    | 4080000  |\n",
            "| value_loss         | 279      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 157      |\n",
            "| ep_reward_mean     | 477      |\n",
            "| explained_variance | 0.717    |\n",
            "| fps                | 3222     |\n",
            "| nupdates           | 34500    |\n",
            "| policy_entropy     | 1.35     |\n",
            "| total_timesteps    | 4140000  |\n",
            "| value_loss         | 1.86e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 502      |\n",
            "| explained_variance | 0.965    |\n",
            "| fps                | 3224     |\n",
            "| nupdates           | 35000    |\n",
            "| policy_entropy     | 1.37     |\n",
            "| total_timesteps    | 4200000  |\n",
            "| value_loss         | 396      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 163      |\n",
            "| ep_reward_mean     | 513      |\n",
            "| explained_variance | 0.853    |\n",
            "| fps                | 3226     |\n",
            "| nupdates           | 35500    |\n",
            "| policy_entropy     | 1.27     |\n",
            "| total_timesteps    | 4260000  |\n",
            "| value_loss         | 938      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 485      |\n",
            "| explained_variance | 0.927    |\n",
            "| fps                | 3228     |\n",
            "| nupdates           | 36000    |\n",
            "| policy_entropy     | 1.34     |\n",
            "| total_timesteps    | 4320000  |\n",
            "| value_loss         | 839      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 159      |\n",
            "| ep_reward_mean     | 520      |\n",
            "| explained_variance | 0.88     |\n",
            "| fps                | 3229     |\n",
            "| nupdates           | 36500    |\n",
            "| policy_entropy     | 1.35     |\n",
            "| total_timesteps    | 4380000  |\n",
            "| value_loss         | 781      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 155      |\n",
            "| ep_reward_mean     | 487      |\n",
            "| explained_variance | 0.892    |\n",
            "| fps                | 3230     |\n",
            "| nupdates           | 37000    |\n",
            "| policy_entropy     | 1.37     |\n",
            "| total_timesteps    | 4440000  |\n",
            "| value_loss         | 755      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 157      |\n",
            "| ep_reward_mean     | 526      |\n",
            "| explained_variance | 0.92     |\n",
            "| fps                | 3232     |\n",
            "| nupdates           | 37500    |\n",
            "| policy_entropy     | 1.16     |\n",
            "| total_timesteps    | 4500000  |\n",
            "| value_loss         | 456      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 155      |\n",
            "| ep_reward_mean     | 562      |\n",
            "| explained_variance | 0.736    |\n",
            "| fps                | 3234     |\n",
            "| nupdates           | 38000    |\n",
            "| policy_entropy     | 1.31     |\n",
            "| total_timesteps    | 4560000  |\n",
            "| value_loss         | 5.17e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 596      |\n",
            "| explained_variance | 0.871    |\n",
            "| fps                | 3236     |\n",
            "| nupdates           | 38500    |\n",
            "| policy_entropy     | 1.19     |\n",
            "| total_timesteps    | 4620000  |\n",
            "| value_loss         | 725      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 157      |\n",
            "| ep_reward_mean     | 593      |\n",
            "| explained_variance | 0.892    |\n",
            "| fps                | 3238     |\n",
            "| nupdates           | 39000    |\n",
            "| policy_entropy     | 1.19     |\n",
            "| total_timesteps    | 4680000  |\n",
            "| value_loss         | 357      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 156      |\n",
            "| ep_reward_mean     | 519      |\n",
            "| explained_variance | 0.856    |\n",
            "| fps                | 3239     |\n",
            "| nupdates           | 39500    |\n",
            "| policy_entropy     | 1.07     |\n",
            "| total_timesteps    | 4740000  |\n",
            "| value_loss         | 1.72e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 585      |\n",
            "| explained_variance | 0.606    |\n",
            "| fps                | 3241     |\n",
            "| nupdates           | 40000    |\n",
            "| policy_entropy     | 1.22     |\n",
            "| total_timesteps    | 4800000  |\n",
            "| value_loss         | 2.22e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 577      |\n",
            "| explained_variance | 0.692    |\n",
            "| fps                | 3242     |\n",
            "| nupdates           | 40500    |\n",
            "| policy_entropy     | 1.2      |\n",
            "| total_timesteps    | 4860000  |\n",
            "| value_loss         | 3.3e+03  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 163      |\n",
            "| ep_reward_mean     | 581      |\n",
            "| explained_variance | 0.727    |\n",
            "| fps                | 3244     |\n",
            "| nupdates           | 41000    |\n",
            "| policy_entropy     | 1.23     |\n",
            "| total_timesteps    | 4920000  |\n",
            "| value_loss         | 4.58e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 605      |\n",
            "| explained_variance | 0.934    |\n",
            "| fps                | 3245     |\n",
            "| nupdates           | 41500    |\n",
            "| policy_entropy     | 1.02     |\n",
            "| total_timesteps    | 4980000  |\n",
            "| value_loss         | 518      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 164      |\n",
            "| ep_reward_mean     | 583      |\n",
            "| explained_variance | 0.942    |\n",
            "| fps                | 3247     |\n",
            "| nupdates           | 42000    |\n",
            "| policy_entropy     | 1.06     |\n",
            "| total_timesteps    | 5040000  |\n",
            "| value_loss         | 217      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 603      |\n",
            "| explained_variance | 0.787    |\n",
            "| fps                | 3248     |\n",
            "| nupdates           | 42500    |\n",
            "| policy_entropy     | 1.13     |\n",
            "| total_timesteps    | 5100000  |\n",
            "| value_loss         | 1.12e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 573      |\n",
            "| explained_variance | 0.704    |\n",
            "| fps                | 3250     |\n",
            "| nupdates           | 43000    |\n",
            "| policy_entropy     | 1.09     |\n",
            "| total_timesteps    | 5160000  |\n",
            "| value_loss         | 4.51e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 156      |\n",
            "| ep_reward_mean     | 601      |\n",
            "| explained_variance | 0.946    |\n",
            "| fps                | 3251     |\n",
            "| nupdates           | 43500    |\n",
            "| policy_entropy     | 0.919    |\n",
            "| total_timesteps    | 5220000  |\n",
            "| value_loss         | 246      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 605      |\n",
            "| explained_variance | 0.968    |\n",
            "| fps                | 3253     |\n",
            "| nupdates           | 44000    |\n",
            "| policy_entropy     | 1.22     |\n",
            "| total_timesteps    | 5280000  |\n",
            "| value_loss         | 239      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 164      |\n",
            "| ep_reward_mean     | 674      |\n",
            "| explained_variance | 0.961    |\n",
            "| fps                | 3254     |\n",
            "| nupdates           | 44500    |\n",
            "| policy_entropy     | 1.13     |\n",
            "| total_timesteps    | 5340000  |\n",
            "| value_loss         | 242      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 163      |\n",
            "| ep_reward_mean     | 628      |\n",
            "| explained_variance | 0.883    |\n",
            "| fps                | 3256     |\n",
            "| nupdates           | 45000    |\n",
            "| policy_entropy     | 1.05     |\n",
            "| total_timesteps    | 5400000  |\n",
            "| value_loss         | 760      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 162      |\n",
            "| ep_reward_mean     | 624      |\n",
            "| explained_variance | 0.955    |\n",
            "| fps                | 3257     |\n",
            "| nupdates           | 45500    |\n",
            "| policy_entropy     | 0.992    |\n",
            "| total_timesteps    | 5460000  |\n",
            "| value_loss         | 556      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 159      |\n",
            "| ep_reward_mean     | 623      |\n",
            "| explained_variance | 0.949    |\n",
            "| fps                | 3259     |\n",
            "| nupdates           | 46000    |\n",
            "| policy_entropy     | 0.966    |\n",
            "| total_timesteps    | 5520000  |\n",
            "| value_loss         | 516      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 602      |\n",
            "| explained_variance | 0.884    |\n",
            "| fps                | 3260     |\n",
            "| nupdates           | 46500    |\n",
            "| policy_entropy     | 1.08     |\n",
            "| total_timesteps    | 5580000  |\n",
            "| value_loss         | 693      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 583      |\n",
            "| explained_variance | 0.965    |\n",
            "| fps                | 3262     |\n",
            "| nupdates           | 47000    |\n",
            "| policy_entropy     | 1.11     |\n",
            "| total_timesteps    | 5640000  |\n",
            "| value_loss         | 294      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 164      |\n",
            "| ep_reward_mean     | 651      |\n",
            "| explained_variance | 0.928    |\n",
            "| fps                | 3263     |\n",
            "| nupdates           | 47500    |\n",
            "| policy_entropy     | 1.1      |\n",
            "| total_timesteps    | 5700000  |\n",
            "| value_loss         | 437      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 163      |\n",
            "| ep_reward_mean     | 642      |\n",
            "| explained_variance | 0.703    |\n",
            "| fps                | 3264     |\n",
            "| nupdates           | 48000    |\n",
            "| policy_entropy     | 0.975    |\n",
            "| total_timesteps    | 5760000  |\n",
            "| value_loss         | 4.78e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 162      |\n",
            "| ep_reward_mean     | 644      |\n",
            "| explained_variance | 0.955    |\n",
            "| fps                | 3265     |\n",
            "| nupdates           | 48500    |\n",
            "| policy_entropy     | 1.08     |\n",
            "| total_timesteps    | 5820000  |\n",
            "| value_loss         | 284      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 164      |\n",
            "| ep_reward_mean     | 696      |\n",
            "| explained_variance | 0.72     |\n",
            "| fps                | 3267     |\n",
            "| nupdates           | 49000    |\n",
            "| policy_entropy     | 0.874    |\n",
            "| total_timesteps    | 5880000  |\n",
            "| value_loss         | 4.16e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 163      |\n",
            "| ep_reward_mean     | 672      |\n",
            "| explained_variance | 0.709    |\n",
            "| fps                | 3268     |\n",
            "| nupdates           | 49500    |\n",
            "| policy_entropy     | 0.85     |\n",
            "| total_timesteps    | 5940000  |\n",
            "| value_loss         | 1.25e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 661      |\n",
            "| explained_variance | 0.872    |\n",
            "| fps                | 3268     |\n",
            "| nupdates           | 50000    |\n",
            "| policy_entropy     | 1.06     |\n",
            "| total_timesteps    | 6000000  |\n",
            "| value_loss         | 991      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 166      |\n",
            "| ep_reward_mean     | 732      |\n",
            "| explained_variance | 0.86     |\n",
            "| fps                | 3269     |\n",
            "| nupdates           | 50500    |\n",
            "| policy_entropy     | 0.878    |\n",
            "| total_timesteps    | 6060000  |\n",
            "| value_loss         | 782      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 162      |\n",
            "| ep_reward_mean     | 643      |\n",
            "| explained_variance | 0.818    |\n",
            "| fps                | 3270     |\n",
            "| nupdates           | 51000    |\n",
            "| policy_entropy     | 0.836    |\n",
            "| total_timesteps    | 6120000  |\n",
            "| value_loss         | 3.17e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 159      |\n",
            "| ep_reward_mean     | 646      |\n",
            "| explained_variance | 0.975    |\n",
            "| fps                | 3271     |\n",
            "| nupdates           | 51500    |\n",
            "| policy_entropy     | 0.871    |\n",
            "| total_timesteps    | 6180000  |\n",
            "| value_loss         | 301      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 161      |\n",
            "| ep_reward_mean     | 693      |\n",
            "| explained_variance | 0.946    |\n",
            "| fps                | 3272     |\n",
            "| nupdates           | 52000    |\n",
            "| policy_entropy     | 0.647    |\n",
            "| total_timesteps    | 6240000  |\n",
            "| value_loss         | 297      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 161      |\n",
            "| ep_reward_mean     | 696      |\n",
            "| explained_variance | 0.975    |\n",
            "| fps                | 3273     |\n",
            "| nupdates           | 52500    |\n",
            "| policy_entropy     | 1        |\n",
            "| total_timesteps    | 6300000  |\n",
            "| value_loss         | 317      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 667      |\n",
            "| explained_variance | 0.965    |\n",
            "| fps                | 3274     |\n",
            "| nupdates           | 53000    |\n",
            "| policy_entropy     | 0.812    |\n",
            "| total_timesteps    | 6360000  |\n",
            "| value_loss         | 260      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 159      |\n",
            "| ep_reward_mean     | 687      |\n",
            "| explained_variance | 0.976    |\n",
            "| fps                | 3275     |\n",
            "| nupdates           | 53500    |\n",
            "| policy_entropy     | 1.03     |\n",
            "| total_timesteps    | 6420000  |\n",
            "| value_loss         | 413      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 157      |\n",
            "| ep_reward_mean     | 671      |\n",
            "| explained_variance | 0.773    |\n",
            "| fps                | 3276     |\n",
            "| nupdates           | 54000    |\n",
            "| policy_entropy     | 0.906    |\n",
            "| total_timesteps    | 6480000  |\n",
            "| value_loss         | 1.93e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 164      |\n",
            "| ep_reward_mean     | 723      |\n",
            "| explained_variance | 0.45     |\n",
            "| fps                | 3277     |\n",
            "| nupdates           | 54500    |\n",
            "| policy_entropy     | 0.781    |\n",
            "| total_timesteps    | 6540000  |\n",
            "| value_loss         | 3.06e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 676      |\n",
            "| explained_variance | 0.942    |\n",
            "| fps                | 3278     |\n",
            "| nupdates           | 55000    |\n",
            "| policy_entropy     | 0.708    |\n",
            "| total_timesteps    | 6600000  |\n",
            "| value_loss         | 273      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 154      |\n",
            "| ep_reward_mean     | 656      |\n",
            "| explained_variance | 0.964    |\n",
            "| fps                | 3279     |\n",
            "| nupdates           | 55500    |\n",
            "| policy_entropy     | 0.827    |\n",
            "| total_timesteps    | 6660000  |\n",
            "| value_loss         | 242      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 696      |\n",
            "| explained_variance | 0.979    |\n",
            "| fps                | 3282     |\n",
            "| nupdates           | 56500    |\n",
            "| policy_entropy     | 0.81     |\n",
            "| total_timesteps    | 6780000  |\n",
            "| value_loss         | 157      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 159      |\n",
            "| ep_reward_mean     | 650      |\n",
            "| explained_variance | 0.678    |\n",
            "| fps                | 3283     |\n",
            "| nupdates           | 57000    |\n",
            "| policy_entropy     | 1.06     |\n",
            "| total_timesteps    | 6840000  |\n",
            "| value_loss         | 4.23e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 653      |\n",
            "| explained_variance | 0.952    |\n",
            "| fps                | 3284     |\n",
            "| nupdates           | 57500    |\n",
            "| policy_entropy     | 0.943    |\n",
            "| total_timesteps    | 6900000  |\n",
            "| value_loss         | 324      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 159      |\n",
            "| ep_reward_mean     | 684      |\n",
            "| explained_variance | 0.917    |\n",
            "| fps                | 3285     |\n",
            "| nupdates           | 58000    |\n",
            "| policy_entropy     | 1.15     |\n",
            "| total_timesteps    | 6960000  |\n",
            "| value_loss         | 689      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 157      |\n",
            "| ep_reward_mean     | 680      |\n",
            "| explained_variance | 0.965    |\n",
            "| fps                | 3286     |\n",
            "| nupdates           | 58500    |\n",
            "| policy_entropy     | 0.94     |\n",
            "| total_timesteps    | 7020000  |\n",
            "| value_loss         | 198      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 165      |\n",
            "| ep_reward_mean     | 714      |\n",
            "| explained_variance | 0.901    |\n",
            "| fps                | 3287     |\n",
            "| nupdates           | 59000    |\n",
            "| policy_entropy     | 0.769    |\n",
            "| total_timesteps    | 7080000  |\n",
            "| value_loss         | 1.26e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 165      |\n",
            "| ep_reward_mean     | 728      |\n",
            "| explained_variance | 0.967    |\n",
            "| fps                | 3288     |\n",
            "| nupdates           | 59500    |\n",
            "| policy_entropy     | 0.583    |\n",
            "| total_timesteps    | 7140000  |\n",
            "| value_loss         | 142      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 678      |\n",
            "| explained_variance | 0.834    |\n",
            "| fps                | 3289     |\n",
            "| nupdates           | 60000    |\n",
            "| policy_entropy     | 0.711    |\n",
            "| total_timesteps    | 7200000  |\n",
            "| value_loss         | 2.9e+03  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 163      |\n",
            "| ep_reward_mean     | 701      |\n",
            "| explained_variance | 0.794    |\n",
            "| fps                | 3290     |\n",
            "| nupdates           | 60500    |\n",
            "| policy_entropy     | 0.864    |\n",
            "| total_timesteps    | 7260000  |\n",
            "| value_loss         | 2.23e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 163      |\n",
            "| ep_reward_mean     | 716      |\n",
            "| explained_variance | 0.965    |\n",
            "| fps                | 3291     |\n",
            "| nupdates           | 61000    |\n",
            "| policy_entropy     | 0.77     |\n",
            "| total_timesteps    | 7320000  |\n",
            "| value_loss         | 229      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 159      |\n",
            "| ep_reward_mean     | 685      |\n",
            "| explained_variance | 0.928    |\n",
            "| fps                | 3292     |\n",
            "| nupdates           | 61500    |\n",
            "| policy_entropy     | 0.764    |\n",
            "| total_timesteps    | 7380000  |\n",
            "| value_loss         | 699      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 159      |\n",
            "| ep_reward_mean     | 710      |\n",
            "| explained_variance | 0.746    |\n",
            "| fps                | 3293     |\n",
            "| nupdates           | 62000    |\n",
            "| policy_entropy     | 0.839    |\n",
            "| total_timesteps    | 7440000  |\n",
            "| value_loss         | 4.48e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 716      |\n",
            "| explained_variance | 0.982    |\n",
            "| fps                | 3294     |\n",
            "| nupdates           | 62500    |\n",
            "| policy_entropy     | 0.855    |\n",
            "| total_timesteps    | 7500000  |\n",
            "| value_loss         | 122      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 165      |\n",
            "| ep_reward_mean     | 765      |\n",
            "| explained_variance | 0.775    |\n",
            "| fps                | 3295     |\n",
            "| nupdates           | 63000    |\n",
            "| policy_entropy     | 0.367    |\n",
            "| total_timesteps    | 7560000  |\n",
            "| value_loss         | 3.34e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 162      |\n",
            "| ep_reward_mean     | 736      |\n",
            "| explained_variance | 0.934    |\n",
            "| fps                | 3296     |\n",
            "| nupdates           | 63500    |\n",
            "| policy_entropy     | 0.722    |\n",
            "| total_timesteps    | 7620000  |\n",
            "| value_loss         | 344      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 698      |\n",
            "| explained_variance | 0.954    |\n",
            "| fps                | 3297     |\n",
            "| nupdates           | 64000    |\n",
            "| policy_entropy     | 0.682    |\n",
            "| total_timesteps    | 7680000  |\n",
            "| value_loss         | 248      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 159      |\n",
            "| ep_reward_mean     | 695      |\n",
            "| explained_variance | 0.905    |\n",
            "| fps                | 3298     |\n",
            "| nupdates           | 64500    |\n",
            "| policy_entropy     | 0.683    |\n",
            "| total_timesteps    | 7740000  |\n",
            "| value_loss         | 988      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 708      |\n",
            "| explained_variance | 0.926    |\n",
            "| fps                | 3299     |\n",
            "| nupdates           | 65000    |\n",
            "| policy_entropy     | 0.495    |\n",
            "| total_timesteps    | 7800000  |\n",
            "| value_loss         | 829      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 163      |\n",
            "| ep_reward_mean     | 722      |\n",
            "| explained_variance | 0.529    |\n",
            "| fps                | 3301     |\n",
            "| nupdates           | 65500    |\n",
            "| policy_entropy     | 0.508    |\n",
            "| total_timesteps    | 7860000  |\n",
            "| value_loss         | 7.94e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 163      |\n",
            "| ep_reward_mean     | 722      |\n",
            "| explained_variance | 0.855    |\n",
            "| fps                | 3302     |\n",
            "| nupdates           | 66000    |\n",
            "| policy_entropy     | 0.567    |\n",
            "| total_timesteps    | 7920000  |\n",
            "| value_loss         | 1.07e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 161      |\n",
            "| ep_reward_mean     | 726      |\n",
            "| explained_variance | 0.962    |\n",
            "| fps                | 3303     |\n",
            "| nupdates           | 66500    |\n",
            "| policy_entropy     | 0.513    |\n",
            "| total_timesteps    | 7980000  |\n",
            "| value_loss         | 254      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 170      |\n",
            "| ep_reward_mean     | 776      |\n",
            "| explained_variance | 0.973    |\n",
            "| fps                | 3303     |\n",
            "| nupdates           | 67000    |\n",
            "| policy_entropy     | 0.42     |\n",
            "| total_timesteps    | 8040000  |\n",
            "| value_loss         | 250      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 713      |\n",
            "| explained_variance | 0.963    |\n",
            "| fps                | 3303     |\n",
            "| nupdates           | 67500    |\n",
            "| policy_entropy     | 0.7      |\n",
            "| total_timesteps    | 8100000  |\n",
            "| value_loss         | 354      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 729      |\n",
            "| explained_variance | 0.923    |\n",
            "| fps                | 3302     |\n",
            "| nupdates           | 68000    |\n",
            "| policy_entropy     | 0.541    |\n",
            "| total_timesteps    | 8160000  |\n",
            "| value_loss         | 606      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 165      |\n",
            "| ep_reward_mean     | 728      |\n",
            "| explained_variance | 0.772    |\n",
            "| fps                | 3302     |\n",
            "| nupdates           | 68500    |\n",
            "| policy_entropy     | 0.811    |\n",
            "| total_timesteps    | 8220000  |\n",
            "| value_loss         | 1.68e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 165      |\n",
            "| ep_reward_mean     | 759      |\n",
            "| explained_variance | 0.934    |\n",
            "| fps                | 3303     |\n",
            "| nupdates           | 69000    |\n",
            "| policy_entropy     | 0.653    |\n",
            "| total_timesteps    | 8280000  |\n",
            "| value_loss         | 408      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 162      |\n",
            "| ep_reward_mean     | 722      |\n",
            "| explained_variance | 0.87     |\n",
            "| fps                | 3303     |\n",
            "| nupdates           | 69500    |\n",
            "| policy_entropy     | 0.835    |\n",
            "| total_timesteps    | 8340000  |\n",
            "| value_loss         | 1.38e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 162      |\n",
            "| ep_reward_mean     | 750      |\n",
            "| explained_variance | 0.891    |\n",
            "| fps                | 3304     |\n",
            "| nupdates           | 70000    |\n",
            "| policy_entropy     | 0.661    |\n",
            "| total_timesteps    | 8400000  |\n",
            "| value_loss         | 1.02e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 161      |\n",
            "| ep_reward_mean     | 744      |\n",
            "| explained_variance | 0.986    |\n",
            "| fps                | 3304     |\n",
            "| nupdates           | 70500    |\n",
            "| policy_entropy     | 0.449    |\n",
            "| total_timesteps    | 8460000  |\n",
            "| value_loss         | 146      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 165      |\n",
            "| ep_reward_mean     | 744      |\n",
            "| explained_variance | 0.943    |\n",
            "| fps                | 3305     |\n",
            "| nupdates           | 71000    |\n",
            "| policy_entropy     | 0.874    |\n",
            "| total_timesteps    | 8520000  |\n",
            "| value_loss         | 288      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 164      |\n",
            "| ep_reward_mean     | 751      |\n",
            "| explained_variance | 0.806    |\n",
            "| fps                | 3306     |\n",
            "| nupdates           | 71500    |\n",
            "| policy_entropy     | 0.813    |\n",
            "| total_timesteps    | 8580000  |\n",
            "| value_loss         | 3.56e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 708      |\n",
            "| explained_variance | 0.964    |\n",
            "| fps                | 3306     |\n",
            "| nupdates           | 72000    |\n",
            "| policy_entropy     | 0.626    |\n",
            "| total_timesteps    | 8640000  |\n",
            "| value_loss         | 507      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 162      |\n",
            "| ep_reward_mean     | 761      |\n",
            "| explained_variance | 0.953    |\n",
            "| fps                | 3306     |\n",
            "| nupdates           | 72500    |\n",
            "| policy_entropy     | 0.512    |\n",
            "| total_timesteps    | 8700000  |\n",
            "| value_loss         | 839      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 159      |\n",
            "| ep_reward_mean     | 720      |\n",
            "| explained_variance | 0.861    |\n",
            "| fps                | 3306     |\n",
            "| nupdates           | 73000    |\n",
            "| policy_entropy     | 0.622    |\n",
            "| total_timesteps    | 8760000  |\n",
            "| value_loss         | 1.41e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 704      |\n",
            "| explained_variance | 0.95     |\n",
            "| fps                | 3307     |\n",
            "| nupdates           | 73500    |\n",
            "| policy_entropy     | 0.751    |\n",
            "| total_timesteps    | 8820000  |\n",
            "| value_loss         | 487      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 163      |\n",
            "| ep_reward_mean     | 749      |\n",
            "| explained_variance | 0.973    |\n",
            "| fps                | 3307     |\n",
            "| nupdates           | 74000    |\n",
            "| policy_entropy     | 0.56     |\n",
            "| total_timesteps    | 8880000  |\n",
            "| value_loss         | 128      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 161      |\n",
            "| ep_reward_mean     | 730      |\n",
            "| explained_variance | 0.9      |\n",
            "| fps                | 3307     |\n",
            "| nupdates           | 74500    |\n",
            "| policy_entropy     | 0.724    |\n",
            "| total_timesteps    | 8940000  |\n",
            "| value_loss         | 760      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 725      |\n",
            "| explained_variance | 0.933    |\n",
            "| fps                | 3307     |\n",
            "| nupdates           | 75000    |\n",
            "| policy_entropy     | 0.361    |\n",
            "| total_timesteps    | 9000000  |\n",
            "| value_loss         | 527      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 162      |\n",
            "| ep_reward_mean     | 738      |\n",
            "| explained_variance | 0.982    |\n",
            "| fps                | 3307     |\n",
            "| nupdates           | 75500    |\n",
            "| policy_entropy     | 0.9      |\n",
            "| total_timesteps    | 9060000  |\n",
            "| value_loss         | 253      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 161      |\n",
            "| ep_reward_mean     | 741      |\n",
            "| explained_variance | 0.884    |\n",
            "| fps                | 3307     |\n",
            "| nupdates           | 76000    |\n",
            "| policy_entropy     | 0.356    |\n",
            "| total_timesteps    | 9120000  |\n",
            "| value_loss         | 811      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 154      |\n",
            "| ep_reward_mean     | 699      |\n",
            "| explained_variance | 0.983    |\n",
            "| fps                | 3307     |\n",
            "| nupdates           | 76500    |\n",
            "| policy_entropy     | 0.386    |\n",
            "| total_timesteps    | 9180000  |\n",
            "| value_loss         | 145      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 164      |\n",
            "| ep_reward_mean     | 760      |\n",
            "| explained_variance | 0.933    |\n",
            "| fps                | 3307     |\n",
            "| nupdates           | 77000    |\n",
            "| policy_entropy     | 0.519    |\n",
            "| total_timesteps    | 9240000  |\n",
            "| value_loss         | 576      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 161      |\n",
            "| ep_reward_mean     | 715      |\n",
            "| explained_variance | 0.762    |\n",
            "| fps                | 3307     |\n",
            "| nupdates           | 77500    |\n",
            "| policy_entropy     | 0.83     |\n",
            "| total_timesteps    | 9300000  |\n",
            "| value_loss         | 2.21e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 161      |\n",
            "| ep_reward_mean     | 760      |\n",
            "| explained_variance | 0.912    |\n",
            "| fps                | 3307     |\n",
            "| nupdates           | 78000    |\n",
            "| policy_entropy     | 0.516    |\n",
            "| total_timesteps    | 9360000  |\n",
            "| value_loss         | 1.39e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 159      |\n",
            "| ep_reward_mean     | 720      |\n",
            "| explained_variance | 0.892    |\n",
            "| fps                | 3307     |\n",
            "| nupdates           | 78500    |\n",
            "| policy_entropy     | 0.562    |\n",
            "| total_timesteps    | 9420000  |\n",
            "| value_loss         | 851      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 701      |\n",
            "| explained_variance | 0.954    |\n",
            "| fps                | 3308     |\n",
            "| nupdates           | 79000    |\n",
            "| policy_entropy     | 0.488    |\n",
            "| total_timesteps    | 9480000  |\n",
            "| value_loss         | 397      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 761      |\n",
            "| explained_variance | 0.873    |\n",
            "| fps                | 3308     |\n",
            "| nupdates           | 79500    |\n",
            "| policy_entropy     | 0.572    |\n",
            "| total_timesteps    | 9540000  |\n",
            "| value_loss         | 1.57e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 164      |\n",
            "| ep_reward_mean     | 761      |\n",
            "| explained_variance | 0.963    |\n",
            "| fps                | 3308     |\n",
            "| nupdates           | 80000    |\n",
            "| policy_entropy     | 0.592    |\n",
            "| total_timesteps    | 9600000  |\n",
            "| value_loss         | 284      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 165      |\n",
            "| ep_reward_mean     | 754      |\n",
            "| explained_variance | 0.958    |\n",
            "| fps                | 3308     |\n",
            "| nupdates           | 80500    |\n",
            "| policy_entropy     | 0.321    |\n",
            "| total_timesteps    | 9660000  |\n",
            "| value_loss         | 538      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 165      |\n",
            "| ep_reward_mean     | 774      |\n",
            "| explained_variance | 0.983    |\n",
            "| fps                | 3308     |\n",
            "| nupdates           | 81000    |\n",
            "| policy_entropy     | 0.32     |\n",
            "| total_timesteps    | 9720000  |\n",
            "| value_loss         | 119      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 161      |\n",
            "| ep_reward_mean     | 742      |\n",
            "| explained_variance | 0.968    |\n",
            "| fps                | 3308     |\n",
            "| nupdates           | 81500    |\n",
            "| policy_entropy     | 0.425    |\n",
            "| total_timesteps    | 9780000  |\n",
            "| value_loss         | 179      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 745      |\n",
            "| explained_variance | 0.823    |\n",
            "| fps                | 3308     |\n",
            "| nupdates           | 82000    |\n",
            "| policy_entropy     | 0.405    |\n",
            "| total_timesteps    | 9840000  |\n",
            "| value_loss         | 2.53e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 160      |\n",
            "| ep_reward_mean     | 718      |\n",
            "| explained_variance | 0.871    |\n",
            "| fps                | 3308     |\n",
            "| nupdates           | 82500    |\n",
            "| policy_entropy     | 0.292    |\n",
            "| total_timesteps    | 9900000  |\n",
            "| value_loss         | 1.13e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 157      |\n",
            "| ep_reward_mean     | 714      |\n",
            "| explained_variance | 0.916    |\n",
            "| fps                | 3308     |\n",
            "| nupdates           | 83000    |\n",
            "| policy_entropy     | 0.321    |\n",
            "| total_timesteps    | 9960000  |\n",
            "| value_loss         | 489      |\n",
            "---------------------------------\n",
            "--- Time take to train model = 50.0 minutes ---\n",
            "Saving Final Model...\n",
            "Model saved as ./A2C-nenv=24-tts=1e+07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3qP_CTooo-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testA2C(seed):\n",
        "  from stable_baselines.common import make_vec_env\n",
        "  from stable_baselines import A2C\n",
        "\n",
        "  # Vectorize environment with given seed\n",
        "  env = make_vec_env(env_id=\"diner_dash:DinerDash-v0\", wrapper_class=OneHotWrapper, seed=seed)\n",
        "\n",
        "  # Load saved model\n",
        "  PPO_model = A2C.load(\"A2C-nenv=24-tts=1e+07\", env=env)\n",
        "\n",
        "  # Reset environment, init obs\n",
        "  obs = env.reset()\n",
        "\n",
        "  done = False\n",
        "  sum_rewards = 0\n",
        "  action_list = []\n",
        "\n",
        "  while not done:\n",
        "    action, _states = PPO_model.predict(obs)\n",
        "    action_list.append(action.item())\n",
        "    obs, rewards, done, info = env.step(action)\n",
        "    sum_rewards += rewards\n",
        "\n",
        "  return sum_rewards, action_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SolGR2yNPGCQ",
        "colab_type": "text"
      },
      "source": [
        "# Testing of Policies and Verification of Submission [Please Edit]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6rxjZmnBceL",
        "colab_type": "text"
      },
      "source": [
        "Creates a json file of action lists from the best scoring algo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWh2kSf9OGv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randint\n",
        "import json\n",
        "from os import getcwd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Sample test\n",
        "def test():\n",
        "  ############################ CHANGEABLE AREA ##############################\n",
        "  # Changeable parameters\n",
        "  numEpisodes = 100                             # num of test episodes\n",
        "  algos = [testPPO2, testA2C]           # Add or remove algos (must have unique names)\n",
        "  saveJson = True                              # Whether to save actions_dict\n",
        "  fileDirectory = \"./\"                          # Path of saved json file\n",
        "  fileName = \"submission.json\"                  # Name of json file\n",
        "\n",
        "  ### Replace the list of randomSeeds with that given for submission\n",
        "  # e.g. randomSeeds = [1, 2, 3]\n",
        "  randomSeeds = randomSeeds = [45990181, 42859851, 88292417, 17986451, 4310124, 28416871, 21378509, 28987250, 49793653, 81705172, 90381554, 13393105, 90402290, 69802779, 87378977, 7338848, 74942140, 86896376, 60192513, 90268611, 12193092, 45037492, 32444344, 60276470, 81720257, 48114169, 2745186, 39780027, 68039546, 63661496, 89673369, 54490252, 9508183, 78690722, 41872036, 40729179, 71091571, 52945376, 49602567, 11079941, 35506423, 32863705, 98722501, 95078645, 2050683, 30225876, 12983163, 5244339, 28278496, 80180211, 63902897, 46843366, 74357835, 90376940, 98407071, 48007796, 96438018, 54730109, 40955186, 60494091, 76878283, 24175421, 91447265, 36570693, 3334869, 14057265, 53946219, 30908957, 86325356, 90558192, 24759335, 51591742, 38364662, 1189567, 536631, 16559969, 68687507, 24406829, 9720389, 23088515, 34242387, 74268255, 23615670, 68613237, 7166219, 27203162, 29343492, 75431707, 39683866, 87146964, 78351462, 23184439, 9088138, 34637812, 25889305, 95479264, 55637910, 26835621, 37209126, 47123382]\n",
        "\n",
        "  ############################################################################\n",
        "\n",
        "  # uses function name as key\n",
        "  # hence, name function with algo name (e.g. testPPO or just PPO)\n",
        "  rewards_dict = {algo.__name__ : [] for algo in algos}\n",
        "  actions_dict = {algo.__name__ : [] for algo in algos}\n",
        "\n",
        "  # Test begins\n",
        "  for seed in tqdm(randomSeeds):\n",
        "    for algo in algos:\n",
        "      # Given a random seed\n",
        "      # Returns the sum of rewards for that episode and the actions list\n",
        "      rewards, actions = algo(seed)\n",
        "\n",
        "      rewards_dict[algo.__name__].append(rewards)\n",
        "      actions_dict[algo.__name__].append(actions)\n",
        "\n",
        "  # Print average rewards from n episodes for each algo\n",
        "  avgReward_dict = {algo : int(sum(rewards)/len(rewards)) for algo, rewards in rewards_dict.items()}\n",
        "  print(f\"Average Rewards for each algo: {avgReward_dict}\")\n",
        "\n",
        "  # Prints best algo\n",
        "  best_algo = max(avgReward_dict.keys(), key=(lambda k: avgReward_dict[k]))\n",
        "  best_reward = avgReward_dict[best_algo]\n",
        "  print(f\"The best algo is {best_algo} with the highest rewards of {best_reward}\")\n",
        "\n",
        "  # Print an action dict containing actions list for each random seed env for each algo\n",
        "  print(f\"Actions list for each env for each algo: {actions_dict}\")\n",
        "\n",
        "  submission_dict = {best_algo: actions_dict[best_algo]}\n",
        "\n",
        "  if saveJson:\n",
        "    print(\"Saving best algo to json file...\")\n",
        "    with open(fileDirectory + fileName, \"w\") as write_file:\n",
        "      json.dump(submission_dict, write_file)\n",
        "      print(f\"{fileName} was saved in {getcwd()}\")\n",
        "    \n",
        "    print(\"-\" * 100)\n",
        "    \n",
        "    print(f\"Verifying {fileName}...\")\n",
        "    (best_algo, best_action_list), = submission_dict.items()\n",
        "    print(f\"Name of best algo: {best_algo}\")\n",
        "    submissionEpisodes = len(best_action_list)\n",
        "    if submissionEpisodes != len(randomSeeds):\n",
        "      raise ValueError(\"Number of episodes in submission does not match the number of random seeds!\")\n",
        "    print(f\"Number of episodes(random seeds): {submissionEpisodes}\")\n",
        "    print(\"Number of episodes in submission matches the number of random seeds\")\n",
        "    print(\"Verification Complete! Please double check the verification results\")\n",
        "  \n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9BwcjYfmyfI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "b939a27f7b0f48e0afb1735eb38f3b59",
            "2869b37489ec451eb12cfd5a1150702e",
            "66fe65523cb0499cb5482b97a7768e7a",
            "1d628e054d904f05a3357c8d708e9713",
            "2a594fac95b34389a9b0a2630704ed24",
            "8e43d0e960044d23b0368f2f21f7a294",
            "fe025dbbe637406799effe463f6a6379",
            "d7231adf34a149ca9d27ed6e07d20b09"
          ]
        },
        "outputId": "c10a85c8-3d8d-4243-edc3-61f703a2fa30"
      },
      "source": [
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b939a27f7b0f48e0afb1735eb38f3b59",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average Rewards for each algo: {'testPPO2': 660, 'testA2C': 745}\n",
            "The best algo is testA2C with the highest rewards of 745\n",
            "Actions list for each env for each algo: {'testPPO2': [[18, 18, 18, 18, 1, 30, 6, 24, 11, 12, 18, 4, 3, 7, 42, 42, 4, 1, 4, 36, 18, 4, 14, 7, 11, 4, 14, 48, 5, 11, 4, 11, 4, 14, 45, 6, 11, 4, 4, 42, 14, 42, 4, 42, 45, 18, 4, 6, 4, 14, 42, 1, 2, 56, 42, 39, 4, 7, 7, 51, 7, 6, 4, 48, 6, 42, 4, 51, 5, 11, 4, 14, 7, 7, 1, 6, 42, 45, 14, 1, 4, 45, 4, 4, 56, 1, 3, 5, 8, 7, 42, 42, 8, 7, 42, 1, 1, 7, 8, 14, 1, 7, 13, 51, 4, 8, 4, 7, 14, 14, 7, 2, 7, 7, 1, 14, 1, 13, 1, 14, 4, 42, 4, 1, 11, 47, 1, 4, 7, 9, 1, 8, 8, 7, 42, 4, 1, 1, 4, 4, 14, 6, 1, 6, 1, 42, 1, 7, 42, 1, 8, 14, 8, 42, 1, 8, 3, 4, 7, 7, 7, 6, 1, 7, 14, 4], [18, 24, 14, 45, 4, 56, 56, 14, 18, 18, 18, 4, 7, 7, 53, 8, 48, 7, 18, 11, 11, 54, 11, 11, 4, 42, 8, 14, 7, 13, 9, 14, 45, 46, 4, 4, 4, 7, 42, 42, 6, 6, 42, 42, 6, 14, 42, 7, 7, 5, 1, 42, 14, 7, 1, 14, 13, 4, 14, 7, 2, 1, 7, 4, 14, 4, 6, 11, 1, 1, 14, 11, 4, 11, 42, 7, 14, 7, 4, 56, 1, 4, 42, 4, 4, 45, 6, 42, 1, 7, 7, 8, 42, 45, 13, 42, 1, 14, 4, 7, 7, 14, 14, 8, 4, 4, 4, 14, 4, 14, 5, 11, 4], [18, 5, 6, 8, 18, 42, 42, 8, 7, 12, 6, 4, 7, 18, 13, 7, 14, 28, 4, 56, 11, 3, 4, 14, 15, 56, 11, 37, 4, 56, 1, 42, 10, 36, 1, 56, 1, 1, 7, 4, 4, 54, 8, 7, 8, 48, 42, 4, 51, 7, 42, 42, 1, 42, 14, 14, 8, 8, 42, 6, 3, 1, 14, 14, 42, 8, 8, 54, 14, 8, 4, 7, 6, 4, 1, 4, 14, 1, 14, 3, 5, 11, 11, 4, 51, 14, 7, 8, 1, 53, 4, 13, 8, 14, 42, 4, 14, 4, 1, 5, 14, 56, 56, 8, 42, 14, 14, 7, 4, 8, 14, 42, 42, 8, 45, 8, 6, 6, 13, 4, 1, 8, 14, 4, 14, 7, 6, 8, 13, 7, 6, 6, 14, 13, 8, 56, 6, 1, 13, 4, 7, 11, 14, 6, 6, 14, 4, 45, 56, 4, 14, 8, 7, 7, 42, 7, 14], [18, 54, 45, 18, 33, 6, 10, 18, 3, 24, 6, 4, 7, 4, 18, 13, 4, 18, 0, 56, 8, 5, 18, 11, 4, 51, 45, 5, 56, 11, 4, 0, 48, 18, 8, 7, 45, 4, 13, 4, 48, 33, 6, 5, 42, 42, 14, 54, 42, 7, 1, 13, 50, 1, 13, 14, 14, 14, 42, 4, 4, 7, 4, 6, 7, 4, 7, 5, 54, 14, 1, 14, 11, 4, 3, 45, 1, 42, 4, 45, 1, 14, 14, 5, 4, 13, 4, 1, 42, 14, 13, 7, 7, 8, 14, 14, 7, 14, 5, 4, 7, 1, 7, 42, 8, 14, 1, 56, 45, 4, 42, 11, 4, 14, 14, 14, 42, 4, 7, 4, 13, 6, 1, 4, 4, 1, 42, 45, 1, 14, 6, 4, 42, 56, 14, 4, 7, 4, 7, 1, 6, 13, 4, 7, 6, 14, 6, 6, 7, 11, 14, 14, 6, 1, 4, 7, 51, 4], [54, 18, 3, 2, 54, 42, 39, 14, 18, 13, 7, 50, 4, 7, 42, 14, 9, 4, 10, 12, 13, 4, 6, 4, 11, 7, 45, 1, 4, 5, 56, 7, 4, 42, 4, 45, 14, 56, 1, 54, 4, 4, 42, 45, 14, 53, 8, 42, 56, 42, 42, 13, 4, 55, 4, 4, 14, 13, 4, 7, 7, 7, 6, 4, 4, 4, 1, 54, 11, 1, 2, 48, 45, 11, 4, 4, 6, 42, 4, 4, 11, 4, 4, 3, 42, 3, 14, 4, 54, 42, 4, 42, 13, 13, 14, 56, 14, 4, 1, 7, 14, 42, 4, 4, 7, 6, 56, 14, 7, 1, 2, 42, 4, 54, 45, 11, 4, 4, 13, 7, 1, 8, 1, 14, 1, 8, 8, 4, 4, 14, 42, 8, 42, 6, 1, 7, 1, 51, 7, 42], [48, 6, 18, 38, 5, 18, 18, 12, 45, 18, 48, 18, 18, 7, 46, 4, 7, 56, 7, 7, 7, 7, 4, 4, 6, 45, 42, 54, 18, 11, 1, 4, 8, 7, 10, 14, 4, 6, 6, 7, 6, 11, 4, 4, 6, 42, 14, 42, 14, 9, 13, 3, 14, 4, 4, 1, 53, 13, 4, 7, 4, 4, 14, 13, 4, 13, 14, 4, 6, 8, 5, 11, 4, 42, 1, 1, 42, 1, 42, 6, 7, 4, 6, 4, 4, 3, 42, 1, 45, 42, 13, 6, 56, 4, 14, 42, 42, 4, 7, 4, 7, 1, 7, 6, 7, 7, 1, 4, 54, 11, 4, 6, 8, 1, 42, 6, 6, 2, 42, 4, 7, 12, 6, 4, 50, 13, 1, 48, 6, 42, 42, 13, 54, 56, 54, 6, 13, 6, 7, 13], [18, 18, 6, 48, 18, 45, 56, 18, 46, 14, 43, 4, 7, 7, 18, 48, 42, 18, 18, 5, 56, 4, 18, 5, 2, 13, 11, 4, 3, 42, 4, 14, 48, 4, 48, 5, 7, 4, 42, 4, 4, 36, 42, 3, 13, 13, 7, 6, 42, 14, 14, 11, 4, 7, 50, 6, 4, 11, 4, 4, 4, 42, 14, 4, 11, 4, 4, 4, 8, 1, 14, 42, 11, 6, 14, 7, 6, 4, 4, 42, 6, 4, 42, 4, 7, 45, 42, 14, 8, 2, 4, 7, 9, 4, 7, 8, 1, 7, 7, 11, 11, 7, 11, 4, 8, 8, 14, 6, 1, 2, 14, 6, 9, 3, 4, 4, 14, 14, 14, 14, 14, 8, 4, 1, 6, 4, 4, 8, 42, 14, 1, 8, 9, 1, 42, 14, 1, 1, 56, 4, 7, 7, 4, 7, 7, 14, 7, 1, 8], [18, 18, 8, 7, 18, 18, 18, 8, 1, 10, 42, 4, 7, 8, 7, 18, 14, 48, 29, 14, 8, 36, 14, 11, 7, 7, 4, 18, 52, 2, 54, 39, 43, 5, 14, 13, 7, 4, 4, 42, 45, 1, 2, 8, 25, 5, 1, 42, 7, 14, 42, 31, 51, 4, 14, 13, 42, 13, 42, 8, 13, 10, 5, 7, 11, 1, 12, 4, 7, 13, 14, 7, 7, 14, 4, 7, 8, 7, 6, 11, 42, 4, 6, 8, 11, 6, 13, 14, 4, 42, 6, 8, 4, 42, 4, 8, 20, 42, 5, 56, 14, 42, 6, 14, 42, 6, 4, 45, 1, 48, 4, 7, 14, 4, 6, 1, 7, 6, 7, 6, 4, 13, 11, 7, 7, 13, 6, 14, 7, 45, 1, 14, 8, 7, 4, 8, 42, 6, 4, 4, 14, 6, 11, 8, 54, 13, 6, 1, 7, 6, 8, 44, 4, 4, 50, 54, 3, 14, 42, 51, 1, 14, 1, 6, 14, 8, 2, 1, 1, 1, 4, 1, 7, 45, 7], [18, 54, 14, 18, 18, 18, 14, 2, 30, 50, 50, 4, 7, 7, 4, 7, 49, 14, 7, 12, 8, 2, 9, 18, 42, 9, 13, 11, 7, 3, 4, 48, 13, 7, 1, 6, 50, 1, 1, 14, 6, 4, 42, 4, 6, 24, 48, 7, 1, 45, 14, 6, 24, 45, 14, 6, 4, 7, 4, 4, 42, 42, 42, 8, 7, 8, 9, 7, 4, 14, 11, 13, 4, 14, 42, 7, 6, 42, 42, 6, 42, 13, 13, 8, 4, 2, 4, 14, 1, 6, 51, 1, 42, 11, 42, 52, 4, 1, 4, 7, 4, 8, 4, 42, 4, 6, 7, 11, 14, 4, 4, 11, 1, 7, 7, 45, 4, 11, 4, 7, 1, 14, 8, 1, 8, 1, 2, 3, 1, 4, 4, 7, 42, 1, 1, 14, 56, 42, 14], [18, 18, 56, 45, 13, 13, 4, 56, 45, 14, 8, 4, 7, 18, 53, 9, 18, 4, 7, 4, 11, 11, 7, 14, 11, 4, 50, 7, 54, 3, 11, 6, 4, 14, 18, 4, 54, 4, 4, 14, 42, 56, 56, 42, 4, 42, 14, 42, 14, 42, 10, 1, 4, 1, 4, 14, 14, 54, 52, 4, 7, 11, 9, 4, 6, 13, 42, 4, 8, 7, 7, 11, 4, 39, 51, 1, 8, 1, 8, 45, 56, 7, 8, 11, 6, 1, 7, 4, 4, 42, 14, 14, 42, 5, 1, 7, 42, 1, 42, 1, 4, 14, 7, 8, 4, 14, 7, 7, 14, 7, 1, 4, 13, 11, 4, 14, 3, 14, 7, 51, 1, 14, 42, 14, 14, 4, 56, 13, 7, 7, 45, 11, 42, 4, 1, 1, 3, 42, 14, 1, 6, 6, 1, 1, 4, 7, 8, 4, 6, 4, 8, 7, 4, 45, 7, 13, 14, 6, 5, 11, 6, 4, 11, 4, 3, 6], [18, 9, 18, 42, 14, 18, 18, 42, 28, 7, 56, 56, 6, 4, 14, 7, 8, 48, 7, 1, 45, 6, 7, 13, 2, 24, 11, 4, 11, 53, 4, 9, 6, 8, 18, 4, 6, 18, 4, 1, 7, 7, 8, 4, 42, 7, 48, 13, 14, 6, 14, 14, 13, 45, 54, 13, 42, 7, 3, 12, 42, 2, 6, 42, 14, 45, 42, 4, 7, 7, 4, 1, 7, 4, 4, 1, 11, 7, 4, 11, 4, 6, 8, 14, 4, 1, 6, 56, 14, 7, 6, 4, 56, 42, 4, 7, 42, 7, 13, 14, 5, 7, 2, 42, 6, 6, 6, 4, 7, 7, 42, 1, 4, 4, 8, 4, 1, 1, 42, 5, 8, 1, 11, 7, 4, 4, 6, 4, 1, 6, 4, 11, 4, 1, 11, 6, 6, 6, 4, 6, 13, 4, 6, 6, 4, 14, 1, 6, 8, 45, 14, 4, 14, 6, 1, 3, 2, 6, 14, 42, 6, 48, 42, 1, 45, 11, 3], [18, 6, 6, 2, 3, 51, 1, 18, 4, 42, 9, 4, 7, 42, 7, 13, 14, 18, 13, 4, 6, 7, 7, 14, 11, 4, 18, 4, 30, 6, 52, 42, 4, 42, 13, 42, 14, 4, 4, 6, 42, 6, 1, 14, 4, 42, 56, 14, 42, 7, 14, 6, 14, 7, 14, 8, 56, 14, 11, 51, 4, 4, 7, 4, 54, 14, 4, 13, 42, 14, 45, 11, 13, 11, 4, 14, 14, 1, 2, 7, 3, 1, 42, 6, 14, 42, 4, 4, 14, 42, 42, 4, 1, 42, 2, 14, 4, 48, 48, 1, 4, 7, 4, 11, 11, 7, 7, 1, 7, 1, 14, 42, 1], [48, 18, 8, 1, 12, 5, 7, 5, 42, 54, 18, 7, 42, 4, 7, 18, 18, 52, 3, 3, 7, 45, 4, 56, 8, 11, 1, 4, 56, 10, 42, 6, 3, 56, 10, 14, 8, 7, 4, 4, 14, 42, 23, 6, 42, 42, 3, 6, 14, 3, 7, 42, 12, 51, 11, 12, 3, 6, 42, 4, 14, 4, 42, 4, 14, 4, 14, 7, 50, 13, 4, 4, 6, 3, 20, 4, 6, 7, 11, 4, 7, 14, 42, 14, 6, 6, 56, 3, 7, 1, 4, 11, 6, 42, 56, 4, 6, 14, 14, 8, 14, 18, 6, 6, 42, 6, 42, 42, 13, 14, 6, 6, 4, 56, 7, 6, 6, 13, 4, 11, 11, 3, 6, 14, 4, 11, 4, 18, 42, 56, 4, 4, 42, 6, 5, 14, 6, 4, 4, 42, 1, 9, 14, 5, 7, 42, 7, 1, 1, 5, 13, 26, 4, 7, 4, 7, 4, 45, 7, 1, 7, 8, 7, 11, 7, 8], [18, 7, 18, 7, 18, 5, 18, 4, 30, 3, 56, 4, 7, 49, 18, 54, 7, 45, 7, 18, 54, 13, 5, 5, 4, 11, 7, 4, 39, 12, 1, 8, 4, 6, 42, 14, 10, 45, 11, 4, 4, 42, 4, 14, 42, 56, 7, 3, 13, 42, 3, 9, 42, 14, 11, 1, 14, 7, 14, 14, 4, 4, 14, 7, 14, 8, 4, 1, 14, 51, 8, 11, 14, 3, 13, 11, 7, 6, 4, 42, 6, 14, 1, 4, 8, 4, 14, 6, 14, 7, 4, 4, 13, 14, 13, 14, 2, 42, 7, 33, 56, 1, 14, 1, 7, 14, 2, 14, 4, 2, 7, 1, 7, 8, 1, 6, 4, 14, 7, 1, 3, 8, 3, 11, 1, 42, 4, 1, 45, 7, 1, 1, 1, 8, 1, 7, 1, 11, 4, 4, 14, 1, 1, 14, 14, 42, 54, 1, 4, 13, 1, 5, 14, 14, 4, 56, 4, 2, 7, 14, 13, 6, 8, 42, 6, 4, 4, 4, 24, 11, 4, 1, 54, 6, 13, 4, 11, 42, 14, 7, 14, 42, 11, 1, 6, 1, 14, 8, 8, 11, 13, 1, 7], [18, 8, 6, 48, 45, 6, 2, 11, 10, 46, 18, 25, 4, 7, 42, 54, 56, 7, 56, 4, 42, 4, 1, 18, 7, 4, 7, 11, 7, 7, 42, 4, 14, 11, 34, 14, 7, 11, 14, 11, 4, 3, 4, 2, 4, 42, 42, 56, 1, 14, 1, 42, 1, 5, 54, 56, 4, 4, 7, 4, 1, 4, 8, 5, 8, 3, 14, 4, 8, 11, 8, 4, 11, 1, 11, 14, 7, 4, 14, 6, 4, 8, 4, 4, 48, 42, 42, 4, 14, 13, 7, 4, 14, 14, 1, 4, 1, 7, 14, 4, 1, 6, 4, 6, 11, 41, 7, 14, 11, 1, 7, 7, 14, 7, 1, 4, 7, 4, 4, 42, 1, 1, 1, 4, 13, 50, 4, 1, 4, 1, 7, 14, 8, 42, 7, 11, 14, 6, 33, 50, 14, 14, 14, 56, 4, 7, 36, 11, 7, 7, 7, 8, 7, 4, 6, 7, 11, 56, 4, 6, 7, 1, 6, 7, 4, 6], [18, 24, 18, 51, 2, 7, 45, 7, 54, 7, 8, 4, 4, 7, 18, 8, 18, 4, 4, 7, 13, 45, 18, 3, 11, 7, 7, 4, 11, 4, 13, 4, 42, 7, 4, 7, 13, 14, 4, 7, 27, 42, 42, 6, 4, 42, 45, 14, 11, 42, 42, 42, 42, 14, 7, 42, 4, 14, 42, 7, 4, 7, 4, 4, 7, 1, 4, 2, 11, 13, 42, 6, 11, 5, 4, 1, 14, 45, 14, 14, 42, 12, 6, 8, 42, 7, 4, 4, 42, 45, 14, 42, 13, 4, 27, 8, 42, 1, 7, 56, 4, 7, 1, 1, 4, 7, 4, 1, 4, 8, 1, 14, 7, 14, 11, 7, 14, 7, 14, 4, 7, 1, 1, 1, 1, 14, 14, 14, 8, 1, 1, 4, 14, 4, 42, 8, 14, 45, 1, 8, 14, 8, 8, 8, 2, 1, 4, 7], [18, 54, 42, 36, 14, 7, 48, 48, 8, 18, 18, 4, 7, 48, 53, 42, 7, 9, 3, 3, 7, 3, 8, 11, 4, 3, 54, 42, 7, 48, 3, 6, 4, 4, 4, 4, 18, 7, 42, 4, 42, 8, 45, 42, 7, 13, 42, 6, 7, 8, 14, 54, 7, 14, 48, 5, 14, 4, 14, 14, 7, 4, 42, 7, 8, 13, 13, 11, 7, 4, 4, 11, 4, 5, 48, 14, 42, 4, 6, 4, 8, 7, 14, 1, 4, 3, 42, 4, 42, 42, 12, 14, 1, 1, 13, 1, 1, 14, 7, 4, 14, 6, 7, 14, 14, 1, 6, 14, 1, 4, 11, 11, 7, 11, 11, 1, 11, 4, 6, 14, 1, 8, 6, 6, 6, 42, 14, 14, 4, 1, 42, 4, 14, 42, 56, 7, 8, 14, 13, 4, 4, 4, 7, 14, 4, 7, 13, 7, 6, 7, 6, 14, 14, 6, 13, 6, 48, 11, 4, 4, 13, 8, 42, 6, 13, 4, 6, 14, 6, 4, 4, 6, 7, 42, 6, 1, 1, 42, 50, 1, 1, 4, 14, 13, 6, 4, 7, 7, 4, 7, 7, 7, 14], [18, 14, 42, 18, 1, 7, 1, 6, 18, 1, 54, 4, 7, 12, 6, 18, 51, 30, 18, 7, 14, 6, 9, 20, 11, 46, 4, 6, 7, 48, 6, 18, 8, 9, 45, 42, 8, 42, 4, 56, 11, 4, 6, 14, 4, 14, 42, 2, 1, 8, 7, 48, 14, 13, 6, 6, 42, 6, 13, 6, 7, 1, 13, 4, 6, 9, 42, 4, 7, 13, 14, 4, 6, 48, 7, 2, 6, 13, 51, 11, 4, 14, 14, 56, 42, 5, 13, 1, 6, 8, 12, 4, 14, 14, 1, 4, 8, 42, 14, 11, 42, 42, 9, 4, 14, 56, 11, 6, 4, 13, 7, 7, 2, 6, 11, 14, 9, 4, 8, 1, 6, 11, 4, 1, 4, 1, 6, 7, 1, 4, 14, 47, 4, 4, 4, 42, 42, 14, 14, 0, 1, 7, 9, 4, 5, 6, 42, 13, 4, 8, 6, 7, 7, 13, 6, 54, 3], [18, 27, 14, 1, 8, 5, 2, 18, 18, 14, 18, 4, 7, 1, 15, 14, 18, 11, 3, 7, 18, 4, 1, 54, 23, 11, 7, 4, 42, 48, 3, 7, 3, 5, 4, 45, 18, 54, 24, 4, 4, 42, 14, 42, 51, 14, 14, 18, 7, 1, 7, 7, 42, 14, 6, 11, 11, 8, 4, 7, 14, 7, 7, 7, 14, 56, 7, 3, 4, 7, 7, 44, 11, 7, 4, 7, 14, 1, 1, 4, 14, 4, 14, 8, 8, 4, 14, 42, 6, 42, 4, 42, 7, 6, 6, 8, 14, 4, 14, 56, 42, 13, 4, 1, 7, 56, 13, 8, 14, 6, 5, 4, 6, 4, 4, 11, 11, 8, 7, 4, 1, 6, 7, 6, 14, 13, 7, 7, 14, 45, 4, 42, 56, 4, 42, 1, 14, 14, 54, 50, 2, 4, 14, 3, 5, 2, 2, 8, 4, 7, 42, 14, 4, 13, 4, 54, 11, 6, 7, 6, 11, 4, 11, 6, 6, 13], [18, 7, 7, 51, 18, 7, 8, 7, 7, 14, 18, 4, 7, 1, 6, 53, 2, 7, 48, 11, 7, 18, 15, 11, 3, 4, 48, 4, 18, 14, 49, 42, 40, 3, 7, 18, 4, 4, 14, 1, 1, 13, 1, 7, 7, 1, 40, 56, 4, 42, 48, 8, 14, 42, 45, 42, 14, 45, 4, 42, 8, 14, 7, 8, 14, 7, 7, 4, 1, 1, 7, 53, 14, 11, 14, 13, 1, 45, 8, 7, 3, 1, 11, 4, 14, 14, 14, 1, 6, 14, 6, 8, 52, 3, 4, 42, 1, 4, 42, 14, 42, 13, 7, 13, 11, 1, 1, 3, 11, 11, 4, 14, 7, 7, 4, 4, 4, 56, 4, 3, 11, 11, 14, 11, 14, 4, 8, 13, 8, 1, 6, 1, 9, 14, 6, 56, 4, 4, 42, 6, 1, 7, 6, 48, 1, 7, 14, 8, 13, 4, 7, 1, 1, 14, 42, 2, 4, 4, 11, 7, 1, 6, 14, 52, 11, 6, 11, 7, 13, 7, 56, 4, 6, 8, 3], [9, 18, 18, 7, 48, 51, 18, 42, 18, 12, 2, 18, 4, 11, 7, 18, 23, 54, 18, 12, 4, 6, 5, 50, 4, 42, 11, 14, 8, 4, 7, 7, 42, 4, 30, 8, 6, 4, 3, 14, 4, 18, 7, 4, 45, 14, 42, 6, 48, 8, 14, 7, 6, 12, 50, 7, 14, 48, 4, 7, 14, 7, 6, 42, 8, 14, 50, 1, 56, 42, 11, 32, 6, 8, 14, 4, 11, 14, 42, 42, 4, 6, 14, 14, 54, 4, 4, 13, 13, 6, 36, 24, 14, 4, 3, 42, 42, 7, 42, 13, 6, 6, 14, 7, 14, 42, 4, 1, 56, 14, 6, 7, 7, 6, 3, 4, 42, 7, 4, 7, 11, 42, 45, 8, 13, 11, 4, 8, 7, 6, 14, 8, 7, 7, 11, 14, 5, 4, 14, 1, 4, 42, 13, 14, 56, 14, 6, 14, 12, 14, 7, 3, 4, 7, 4, 11, 9, 1, 4, 6, 7, 1, 42, 11, 11, 7, 1, 7, 11, 6, 14, 54, 4, 14, 8, 8], [18, 8, 4, 5, 12, 13, 4, 4, 42, 4, 18, 4, 14, 7, 1, 4, 14, 18, 14, 4, 4, 18, 11, 4, 56, 11, 7, 4, 18, 18, 11, 11, 14, 54, 14, 14, 52, 9, 4, 4, 14, 2, 42, 18, 14, 2, 1, 8, 45, 8, 13, 13, 6, 13, 4, 4, 7, 45, 14, 8, 4, 14, 54, 2, 6, 13, 8, 7, 11, 7, 4, 14, 6, 14, 7, 2, 1, 6, 6, 42, 42, 4, 45, 6, 7, 44, 42, 14, 4, 42, 8, 14, 1, 4, 11, 14, 14, 1, 14, 42, 7, 53, 4, 7, 14, 1, 11, 13, 4, 7, 7, 7, 42, 13, 14, 1, 8, 4, 6, 4, 7, 1, 42, 4, 14, 13, 2, 6, 11, 6, 6, 13, 56, 4, 7, 7, 6, 8, 6, 13, 14, 6, 14, 6, 4, 1], [42, 44, 18, 3, 18, 8, 42, 1, 13, 45, 4, 14, 54, 4, 7, 4, 7, 7, 1, 50, 1, 6, 7, 13, 18, 8, 11, 4, 3, 1, 5, 7, 3, 41, 41, 8, 4, 7, 1, 4, 0, 39, 3, 11, 4, 42, 42, 7, 7, 14, 7, 4, 14, 14, 8, 13, 6, 2, 4, 7, 4, 4, 7, 4, 14, 7, 8, 45, 11, 4, 11, 6, 4, 6, 9, 1, 42, 56, 1, 7, 14, 14, 0, 54, 1, 4, 42, 4, 14, 42, 1, 14, 1, 14, 14, 1, 8, 7, 4, 42, 4, 7, 4, 7, 1, 7, 7, 4, 4, 7, 7, 55, 50, 7, 11, 4, 1, 4, 42, 14, 6, 7, 56, 13, 6, 42, 4, 13, 11, 8, 4, 45, 42, 14, 56, 42, 6, 7, 4, 4, 4, 6, 6, 4, 7, 6, 48, 42, 1, 11, 42, 12, 7, 7, 35, 6, 11, 7, 6, 4, 7, 14, 4, 7, 6, 44, 6, 8, 4, 42, 4, 54, 6, 13], [18, 7, 14, 1, 14, 18, 14, 14, 18, 18, 18, 14, 3, 4, 7, 4, 50, 6, 9, 30, 7, 1, 18, 6, 7, 11, 3, 54, 45, 4, 11, 14, 7, 12, 14, 14, 54, 6, 14, 1, 54, 4, 4, 42, 42, 18, 14, 14, 4, 4, 56, 42, 11, 14, 6, 42, 3, 4, 13, 7, 5, 42, 1, 7, 14, 6, 14, 4, 11, 6, 11, 4, 14, 42, 8, 7, 56, 6, 6, 42, 6, 42, 6, 14, 6, 4, 14, 7, 13, 4, 56, 48, 45, 42, 11, 3, 14, 7, 1, 6, 7, 14, 4, 7, 48, 6, 7, 7, 14, 7, 8, 7, 2, 14, 11, 4, 14, 30, 42, 45, 1, 1, 51, 1, 7, 56, 4, 5, 6, 14, 14, 13, 1, 8, 42, 4, 45, 7, 6, 8, 1, 42, 11, 14, 42, 7, 48, 14], [18, 42, 3, 45, 18, 9, 42, 1, 1, 54, 4, 42, 4, 7, 9, 32, 18, 24, 4, 7, 31, 18, 45, 21, 1, 11, 48, 4, 8, 14, 18, 7, 7, 13, 1, 14, 49, 45, 4, 4, 56, 3, 50, 1, 51, 3, 14, 5, 18, 14, 4, 7, 14, 8, 8, 11, 42, 4, 48, 4, 7, 1, 12, 7, 1, 1, 8, 14, 13, 14, 13, 1, 14, 11, 1, 7, 4, 1, 1, 4, 50, 5, 11, 8, 14, 1, 42, 4, 4, 52, 3, 42, 1, 5, 42, 2, 42, 1, 7, 7, 7, 6, 14, 4, 7, 6, 4, 4, 7, 7, 6, 4, 42, 4, 8, 11, 6, 4, 13, 1, 6, 8], [1, 18, 14, 42, 56, 18, 11, 48, 14, 18, 13, 45, 56, 18, 4, 7, 18, 12, 45, 1, 55, 14, 4, 13, 56, 4, 11, 4, 10, 7, 7, 1, 7, 18, 5, 56, 1, 6, 14, 4, 11, 11, 14, 11, 4, 14, 42, 6, 14, 2, 42, 4, 4, 6, 42, 42, 14, 4, 7, 4, 42, 45, 8, 11, 14, 54, 4, 14, 50, 11, 1, 4, 14, 14, 4, 42, 13, 56, 42, 7, 14, 42, 4, 14, 54, 4, 42, 45, 42, 31, 56, 13, 14, 13, 14, 42, 42, 4, 7, 7, 42, 7, 45, 7, 4, 11, 11, 4, 1, 11, 7, 4, 1, 13, 7, 1, 6, 36, 14, 1, 8, 11, 4, 56, 8, 1, 14, 8, 1, 4, 6, 6, 7, 13, 6, 14, 6, 7, 14, 10, 6, 4, 48, 6, 13, 14, 54, 56, 6, 1, 13, 56, 14, 8, 8, 4, 1, 14], [37, 18, 18, 18, 14, 42, 48, 18, 6, 29, 6, 14, 10, 40, 4, 30, 7, 12, 50, 7, 54, 7, 42, 4, 12, 56, 7, 11, 4, 30, 6, 4, 12, 18, 5, 14, 4, 14, 5, 4, 4, 42, 42, 14, 13, 14, 14, 42, 13, 7, 13, 8, 14, 4, 6, 1, 11, 14, 4, 7, 6, 7, 1, 4, 7, 8, 5, 1, 14, 4, 11, 4, 14, 4, 7, 7, 8, 1, 6, 6, 14, 42, 4, 4, 42, 14, 6, 56, 42, 14, 12, 3, 42, 14, 6, 14, 6, 4, 7, 1, 7, 4, 1, 8, 4, 1, 4, 14, 5, 11, 4, 1, 6, 56, 8, 42, 14, 18, 6, 42, 7, 8, 4, 7, 4, 42, 6, 1, 54, 2, 3, 42, 31, 14, 13, 7, 4, 7, 56, 8, 6, 14, 11, 54, 11, 8, 1, 42], [18, 18, 4, 56, 7, 48, 18, 8, 18, 42, 18, 45, 4, 4, 7, 14, 13, 48, 45, 7, 11, 7, 7, 11, 42, 11, 4, 6, 14, 1, 42, 4, 7, 4, 11, 7, 42, 11, 4, 4, 7, 42, 6, 42, 45, 8, 42, 5, 14, 42, 10, 51, 4, 4, 7, 14, 1, 4, 6, 7, 1, 7, 14, 4, 4, 4, 45, 8, 8, 4, 11, 4, 14, 14, 1, 9, 7, 45, 42, 42, 1, 1, 13, 4, 4, 42, 7, 14, 1, 1, 3, 42, 14, 14, 42, 7, 7, 4, 14, 4, 7, 7, 8, 4, 8, 7, 8, 6, 4, 4, 56, 11, 14, 45, 4, 8, 14, 7, 14, 1, 6, 42, 6, 8, 11, 6, 13, 4, 5, 14, 6, 7, 4, 6, 42, 6, 6, 7, 1, 42, 14, 7, 8, 1, 56, 42, 14, 42, 42, 7, 14, 45], [18, 42, 7, 9, 18, 13, 42, 14, 45, 42, 12, 48, 4, 36, 7, 7, 7, 50, 7, 4, 42, 14, 6, 1, 11, 18, 11, 13, 4, 13, 4, 4, 2, 3, 42, 42, 6, 6, 4, 4, 4, 18, 42, 4, 14, 56, 50, 2, 4, 14, 14, 1, 4, 7, 52, 4, 14, 56, 51, 14, 7, 4, 14, 42, 7, 11, 4, 1, 14, 6, 4, 6, 3, 56, 42, 8, 4, 4, 4, 14, 48, 45, 4, 5, 14, 42, 3, 42, 2, 4, 13, 45, 52, 8, 4, 13, 4, 42, 4, 1, 14, 7, 11, 4, 4, 6, 13, 4, 14, 6, 14, 6, 11, 7, 14, 4, 6, 6, 4, 45, 8, 7, 7, 6, 13, 42, 6, 4, 4, 54, 14, 4, 7, 6, 13, 6, 1, 14, 45, 1, 4, 7, 13, 3, 7, 7, 8, 36, 1, 54, 14, 3, 45, 11, 6, 4, 51, 1, 6, 13, 1, 14, 14, 1, 1, 30, 8, 4, 6, 13, 8, 14, 14, 1, 4, 14, 6, 45, 56, 12, 42, 4], [42, 18, 42, 9, 7, 45, 18, 14, 42, 14, 24, 38, 4, 7, 7, 7, 11, 4, 18, 7, 4, 1, 46, 6, 11, 14, 4, 51, 43, 45, 3, 14, 1, 7, 42, 54, 56, 4, 4, 42, 8, 42, 18, 14, 13, 4, 1, 7, 14, 4, 4, 45, 6, 4, 7, 13, 7, 6, 13, 4, 7, 11, 14, 3, 54, 11, 48, 45, 13, 4, 42, 14, 1, 1, 4, 8, 8, 4, 14, 42, 4, 7, 42, 4, 6, 45, 42, 1, 42, 42, 1, 7, 6, 8, 1, 7, 7, 7, 4, 8, 1, 7, 4, 14, 1, 56, 7, 4, 4, 7, 4, 7, 6, 11, 4, 3, 42, 8, 13, 2, 8, 1, 42, 2, 36, 4, 42, 4, 42, 42, 4, 1, 8, 1, 1, 1, 2, 4, 48, 7, 56, 42, 4, 42, 7, 1, 7, 6, 7, 13, 1, 1, 56, 7, 6, 11, 7], [18, 14, 2, 18, 51, 13, 18, 48, 14, 18, 18, 4, 6, 7, 4, 7, 45, 7, 56, 42, 27, 50, 18, 7, 11, 7, 4, 4, 5, 52, 50, 7, 45, 53, 7, 1, 8, 7, 4, 42, 5, 4, 14, 42, 42, 3, 14, 13, 2, 42, 4, 6, 5, 4, 42, 8, 14, 11, 56, 1, 4, 7, 1, 7, 7, 1, 4, 14, 14, 4, 6, 13, 3, 8, 14, 11, 50, 7, 7, 6, 6, 4, 42, 14, 56, 9, 6, 42, 6, 4, 48, 7, 7, 4, 4, 42, 50, 45, 42, 42, 1, 14, 48, 4, 14, 14, 4, 11, 8, 7, 3, 6, 6, 6, 13, 7, 7, 1, 14, 13, 56, 11, 7, 7, 7, 14, 7, 7, 7, 6, 56, 4, 1, 6, 13, 14, 13, 4, 14, 14, 1, 8, 4, 13, 6, 42, 4, 4, 4], [18, 5, 42, 8, 4, 13, 13, 4, 7, 1, 14, 12, 7, 4, 7, 7, 4, 11, 54, 7, 11, 4, 4, 7, 51, 2, 11, 7, 3, 56, 4, 30, 14, 7, 53, 4, 56, 4, 14, 42, 6, 4, 6, 4, 14, 48, 42, 7, 48, 6, 14, 11, 42, 18, 14, 6, 1, 4, 7, 1, 30, 14, 11, 6, 3, 56, 6, 45, 4, 11, 4, 1, 14, 8, 56, 4, 42, 42, 4, 56, 41, 4, 13, 13, 4, 42, 42, 3, 51, 48, 7, 8, 4, 8, 1, 1, 7, 1, 7, 7, 1, 7, 1, 14, 4, 14, 7, 42, 1, 1, 1, 1, 1, 1, 1, 4, 8, 11, 1, 14, 7, 1, 42, 7, 7, 7, 4, 9, 14, 42, 1, 4, 42, 8, 4, 42, 56, 4, 42, 4, 14, 6, 42, 42, 42, 56, 6, 13, 6, 4, 6, 54, 14, 4, 7, 4, 6], [18, 11, 18, 14, 7, 45, 18, 18, 6, 48, 30, 14, 4, 7, 15, 4, 11, 14, 4, 4, 7, 41, 4, 18, 11, 4, 18, 8, 54, 7, 6, 7, 45, 1, 54, 1, 13, 4, 4, 42, 42, 4, 14, 8, 7, 14, 54, 14, 3, 56, 14, 42, 4, 14, 56, 45, 6, 42, 14, 42, 1, 13, 1, 14, 42, 13, 5, 56, 3, 8, 14, 1, 42, 4, 42, 1, 7, 7, 4, 7, 7, 1, 5, 45, 4, 13, 14, 11, 1, 8, 45, 7, 4, 1, 48, 45, 8, 8, 7, 42, 1, 13, 4, 4, 1, 54, 4, 42, 7, 14, 2, 14, 2, 3, 14, 53, 14, 8, 8, 4, 7, 8, 4, 7, 7, 4, 24, 45, 14, 7, 11, 6, 11, 4, 4, 33, 14, 42, 1, 1, 7, 1, 36, 1, 4, 4, 8, 7, 42, 54, 11, 8, 42, 2, 13, 7, 14, 6, 7, 2, 4, 1, 6, 6, 14, 7, 6, 1, 4, 8, 8, 14, 56, 7, 6, 7, 11, 6, 7, 4, 7, 14, 7, 7, 8, 3], [54, 18, 54, 6, 54, 7, 7, 6, 18, 50, 5, 56, 4, 23, 7, 7, 38, 18, 18, 13, 39, 7, 4, 4, 48, 18, 11, 4, 4, 14, 6, 5, 2, 5, 51, 8, 13, 7, 8, 4, 4, 9, 18, 42, 6, 14, 3, 2, 7, 6, 42, 2, 6, 4, 7, 13, 4, 4, 14, 56, 3, 4, 4, 11, 13, 13, 11, 14, 4, 7, 7, 1, 9, 13, 51, 11, 42, 7, 56, 14, 4, 4, 42, 6, 14, 14, 6, 51, 6, 5, 4, 48, 42, 4, 7, 6, 14, 8, 42, 42, 42, 8, 45, 1, 4, 11, 4, 7, 14, 54, 14, 8, 4, 42, 8, 6, 14, 4, 4, 6, 42, 42, 1, 4, 1, 14, 1, 7, 42, 4, 14], [18, 4, 38, 45, 6, 14, 56, 6, 48, 8, 18, 4, 7, 14, 11, 18, 7, 18, 48, 14, 6, 2, 5, 18, 7, 11, 5, 4, 4, 6, 8, 4, 48, 14, 4, 18, 7, 3, 4, 42, 6, 4, 7, 6, 42, 6, 14, 7, 42, 14, 6, 45, 1, 6, 6, 53, 7, 7, 6, 4, 4, 7, 4, 7, 11, 56, 7, 13, 13, 7, 4, 8, 50, 11, 4, 6, 6, 3, 1, 8, 56, 42, 6, 6, 42, 7, 4, 4, 42, 6, 13, 14, 12, 1, 42, 42, 6, 6, 13, 4, 48, 7, 14, 12, 1, 13, 7, 4, 6, 6, 45, 3, 11, 1, 4, 45, 13, 14, 12, 6, 54, 1, 49, 56, 9, 13, 45, 4, 6, 4, 42, 14, 14, 14, 4, 14, 13, 7, 42, 7, 48, 2, 4, 6, 7, 1, 14, 42, 13, 7, 7, 1, 6, 11, 4, 11, 4, 9, 44, 13, 30, 8, 6, 6, 56, 3, 6, 6, 4, 4, 56, 14, 42, 6, 13, 7, 14, 8, 45, 18, 56, 14, 6, 4], [18, 18, 56, 11, 18, 1, 12, 18, 18, 18, 18, 4, 7, 18, 56, 4, 14, 56, 13, 13, 11, 45, 4, 11, 7, 1, 4, 18, 7, 14, 6, 7, 6, 14, 5, 4, 6, 4, 54, 4, 8, 14, 4, 12, 42, 42, 42, 7, 4, 6, 6, 4, 7, 13, 56, 4, 13, 4, 7, 45, 13, 4, 4, 4, 7, 8, 4, 6, 11, 1, 11, 4, 8, 6, 42, 14, 8, 5, 14, 42, 14, 14, 42, 7, 4, 4, 42, 42, 7, 50, 14, 14, 14, 42, 42, 14, 6, 7, 12, 4, 7, 11, 42, 7, 4, 7, 4, 7, 6, 8, 2, 11, 45, 4, 8, 29, 45, 8, 45, 5, 7, 14, 14, 42, 5, 4, 1, 2, 14, 4, 50, 54, 42, 42, 42, 14, 8, 4, 7, 8], [18, 13, 1, 42, 7, 1, 8, 4, 27, 16, 18, 18, 7, 18, 18, 4, 7, 11, 11, 56, 42, 3, 8, 13, 18, 14, 42, 20, 41, 11, 7, 7, 4, 1, 6, 14, 4, 18, 6, 3, 1, 6, 13, 4, 4, 5, 42, 56, 42, 33, 6, 56, 50, 6, 5, 13, 7, 8, 42, 6, 6, 14, 6, 7, 14, 1, 42, 42, 13, 4, 7, 4, 14, 14, 45, 13, 13, 6, 13, 1, 42, 4, 4, 42, 42, 14, 42, 11, 6, 6, 4, 7, 11, 1, 6, 14, 14, 7, 11, 7, 14, 4, 7, 4, 48, 14, 56, 6, 1, 14, 14, 3, 8, 2, 13, 7, 4, 14, 7, 11, 8, 56, 3, 3, 7, 4, 6, 1, 42, 11, 4, 11, 11, 4, 8, 56, 7, 54, 8, 6, 7, 4, 4, 14, 42, 6, 8, 4, 8, 6, 8, 1, 42, 4, 42, 4, 7, 1, 8, 6, 14, 4, 6, 42, 4, 7, 4], [45, 42, 18, 9, 19, 18, 42, 42, 27, 4, 7, 42, 18, 4, 12, 7, 7, 24, 7, 43, 14, 42, 6, 54, 7, 4, 11, 18, 25, 4, 56, 42, 6, 18, 18, 8, 14, 1, 4, 1, 11, 4, 4, 6, 1, 14, 56, 54, 14, 42, 14, 42, 6, 4, 4, 8, 2, 14, 14, 8, 6, 4, 7, 6, 5, 11, 14, 7, 7, 8, 7, 4, 1, 4, 11, 4, 2, 7, 50, 13, 8, 11, 14, 7, 14, 6, 4, 4, 7, 42, 6, 14, 8, 13, 14, 7, 1, 42, 6, 14, 4, 1, 7, 1, 1, 56, 6, 7, 8, 3, 7, 13, 7, 11, 1, 2, 14, 56, 7, 14, 45, 4, 13, 14, 14, 8, 7, 6, 14, 1, 8, 45, 4, 11, 4, 8, 42, 3, 8, 6, 8, 1, 14, 4, 6, 8, 6, 4, 8, 4, 1, 7, 4, 7, 13, 11, 7, 7, 6, 4, 11, 1, 1, 7, 9], [18, 4, 42, 1, 45, 1, 14, 42, 39, 37, 12, 4, 7, 1, 1, 5, 1, 1, 14, 56, 14, 45, 48, 2, 11, 14, 4, 14, 45, 7, 51, 42, 6, 42, 4, 7, 4, 4, 42, 11, 33, 4, 1, 42, 14, 37, 14, 3, 8, 14, 46, 5, 10, 3, 4, 44, 6, 14, 7, 14, 42, 1, 7, 6, 14, 42, 6, 1, 5, 4, 7, 8, 6, 14, 6, 1, 1, 6, 6, 4, 6, 14, 7, 14, 13, 6, 6, 4, 2, 4, 42, 14, 6, 6, 4, 42, 6, 7, 50, 11, 1, 4, 1, 11, 8, 14, 11, 4, 4, 7, 6, 1, 7, 1, 7, 4, 42, 4, 14, 13, 1, 4, 4, 42, 1, 8, 8, 6, 14, 6, 6, 7, 7, 42, 4, 7, 6, 4, 6, 4], [18, 42, 45, 18, 48, 12, 48, 7, 3, 4, 13, 4, 7, 43, 24, 18, 7, 11, 4, 33, 21, 13, 51, 7, 11, 4, 42, 14, 4, 14, 42, 8, 7, 48, 1, 8, 4, 4, 14, 9, 4, 8, 1, 56, 9, 9, 30, 7, 1, 1, 4, 14, 6, 2, 6, 8, 14, 4, 7, 42, 3, 14, 2, 4, 1, 1, 11, 7, 1, 13, 4, 11, 4, 4, 6, 7, 7, 45, 7, 4, 14, 8, 1, 13, 6, 3, 4, 4, 2, 13, 25, 14, 42, 1, 8, 7, 51, 6, 42, 4, 14, 1, 8, 4, 7, 5, 7, 8, 7, 3, 7, 1, 14, 6, 3, 11, 4, 54, 4, 14, 2, 11, 29, 9, 14, 42, 1, 11, 4, 4, 4, 42, 14, 6, 13, 14, 1, 4, 14], [18, 18, 18, 42, 18, 18, 7, 18, 4, 11, 18, 54, 18, 18, 4, 14, 7, 42, 9, 7, 14, 4, 18, 6, 7, 53, 56, 11, 4, 1, 54, 42, 4, 1, 42, 3, 7, 14, 14, 4, 48, 4, 42, 54, 42, 7, 42, 7, 6, 14, 30, 5, 56, 5, 13, 4, 56, 4, 7, 7, 4, 14, 4, 4, 4, 11, 1, 42, 4, 11, 42, 4, 56, 6, 13, 56, 42, 14, 45, 8, 14, 6, 4, 4, 8, 14, 42, 1, 7, 11, 4, 8, 1, 14, 7, 11, 6, 11, 4, 7, 4, 42, 7, 8, 14, 7, 14, 7, 56, 4, 7, 7, 7, 11, 1, 7, 36, 1, 1, 1, 1, 4, 1, 14, 8, 1, 6, 6, 6, 5, 2, 13, 11, 14, 14, 4, 54, 1, 4, 42, 1, 42, 14, 42, 1, 42, 14, 13], [18, 18, 1, 2, 42, 9, 14, 45, 7, 14, 45, 3, 4, 7, 4, 13, 42, 4, 18, 24, 45, 18, 4, 13, 54, 11, 4, 11, 42, 7, 42, 14, 14, 18, 42, 45, 7, 4, 8, 13, 4, 8, 42, 7, 14, 50, 42, 13, 42, 14, 14, 54, 13, 8, 30, 5, 14, 7, 14, 4, 7, 11, 6, 4, 7, 13, 14, 6, 4, 1, 54, 11, 14, 4, 1, 14, 48, 56, 4, 7, 14, 8, 14, 7, 4, 11, 4, 56, 42, 14, 11, 11, 1, 3, 6, 13, 11, 4, 14, 4, 7, 6, 1, 11, 4, 11, 11, 1, 4, 14, 4, 11, 4, 8, 1, 7, 8, 4, 42, 13, 14, 7, 8, 4, 42, 6, 7, 4, 14, 4, 14, 42, 14, 13, 7, 7, 4, 45, 6, 6, 45, 42, 4, 14, 7, 30, 1, 42, 2, 14, 45, 1, 7, 1, 7, 11], [18, 14, 56, 7, 6, 6, 41, 7, 18, 13, 18, 8, 7, 4, 7, 7, 18, 14, 3, 42, 7, 7, 1, 4, 5, 18, 11, 4, 3, 50, 2, 2, 7, 8, 14, 45, 3, 14, 4, 4, 50, 14, 14, 18, 11, 18, 5, 8, 42, 54, 2, 13, 45, 11, 4, 7, 11, 6, 3, 5, 14, 7, 56, 1, 14, 6, 11, 4, 6, 7, 54, 4, 45, 56, 4, 6, 56, 14, 14, 7, 14, 4, 8, 13, 1, 42, 4, 6, 6, 8, 42, 42, 7, 6, 8, 6, 1, 42, 8, 13, 1, 4, 7, 7, 7, 1, 42, 7, 7, 42, 51, 1, 8, 4, 11, 7, 7, 8, 14, 4, 7, 14, 56, 7, 11, 7, 7, 6, 5, 7, 7, 8, 8, 1, 6, 1, 14, 7, 4, 13, 14, 1, 7, 1, 7, 6, 14, 14, 42, 42, 3, 13, 6, 3, 14, 4, 4, 2, 50, 42, 42, 13, 8, 42, 50, 6], [54, 18, 18, 14, 42, 3, 42, 14, 4, 18, 56, 18, 4, 7, 1, 51, 40, 37, 14, 56, 48, 4, 4, 4, 11, 4, 48, 3, 48, 18, 3, 5, 14, 53, 6, 11, 9, 1, 14, 4, 4, 18, 45, 8, 14, 56, 13, 1, 42, 2, 7, 14, 4, 7, 8, 4, 4, 11, 7, 4, 42, 8, 1, 7, 14, 48, 11, 14, 4, 42, 6, 4, 1, 4, 13, 6, 48, 7, 3, 4, 3, 14, 3, 4, 2, 42, 7, 14, 8, 7, 14, 1, 42, 42, 6, 1, 4, 7, 2, 1, 4, 7, 4, 11, 4, 4, 4, 6, 11, 4, 14, 14, 4, 1, 42, 6, 11, 14, 8, 14, 4, 6, 4, 8, 1, 42, 42, 54, 4, 42, 1, 13, 7, 8, 1, 14, 4, 7, 4, 4, 4, 51, 11, 4, 1, 4, 4, 6, 4, 8, 4, 42, 7, 1, 7, 14, 1, 13, 1, 14, 8, 9, 14, 24, 4, 14, 7, 1, 1, 7, 13, 11, 1, 4, 1], [45, 18, 18, 14, 24, 1, 51, 45, 1, 56, 18, 10, 2, 6, 4, 7, 11, 4, 7, 7, 56, 54, 7, 20, 4, 7, 7, 6, 4, 11, 45, 56, 6, 6, 14, 4, 52, 8, 8, 42, 42, 6, 42, 6, 6, 14, 7, 8, 6, 4, 4, 13, 8, 14, 6, 6, 42, 11, 8, 14, 14, 4, 6, 42, 6, 6, 6, 6, 4, 56, 4, 1, 7, 14, 13, 14, 7, 4, 4, 6, 4, 48, 4, 1, 11, 4, 6, 42, 42, 6, 6, 1, 13, 1, 18, 7, 14, 4, 4, 6, 14, 1, 54, 56, 42, 6, 6, 4, 42, 14, 56, 4, 1, 56, 4, 7, 6, 4, 45, 4, 14, 14, 6, 7, 7, 14, 11, 1, 14, 4, 6, 1, 14, 12, 1, 4, 13, 1, 7, 14, 4, 4, 6, 1, 6, 14, 14, 13, 42, 36, 45, 42, 9, 1, 1, 1, 8, 8, 1, 4, 7, 14, 6, 4, 42, 7], [56, 26, 18, 9, 18, 12, 6, 4, 56, 48, 27, 18, 18, 42, 45, 4, 7, 48, 18, 18, 1, 2, 18, 7, 18, 18, 13, 26, 44, 6, 11, 13, 7, 4, 51, 54, 8, 45, 7, 6, 6, 3, 7, 6, 18, 4, 4, 6, 14, 42, 6, 42, 42, 12, 42, 8, 6, 42, 8, 6, 6, 14, 14, 6, 6, 4, 6, 42, 4, 45, 7, 7, 13, 14, 14, 4, 8, 6, 6, 4, 6, 11, 4, 6, 13, 14, 4, 56, 42, 42, 14, 6, 14, 5, 51, 4, 4, 42, 13, 8, 6, 1, 14, 1, 14, 7, 11, 3, 11, 4, 7, 4, 11, 14, 6, 7, 6, 6, 14, 13, 14, 11, 2, 4, 14, 7, 6, 6, 13, 42, 13, 2, 4, 45, 14, 4, 4, 14, 42, 1, 14, 18, 8, 1, 4, 14, 54, 11, 4, 4, 7, 27, 42, 7, 4, 1, 48, 5, 4, 8, 7, 11, 7, 1, 7, 4], [18, 7, 8, 7, 14, 56, 9, 50, 12, 8, 18, 18, 4, 7, 14, 7, 24, 7, 6, 1, 18, 52, 56, 3, 11, 7, 7, 13, 42, 42, 4, 14, 11, 21, 4, 42, 42, 42, 29, 18, 4, 4, 56, 4, 14, 9, 4, 14, 13, 12, 4, 42, 8, 42, 11, 42, 4, 6, 7, 4, 7, 4, 4, 6, 14, 6, 7, 6, 56, 4, 42, 14, 7, 7, 45, 11, 8, 54, 7, 50, 7, 7, 4, 10, 4, 11, 4, 13, 7, 42, 8, 42, 42, 42, 14, 42, 42, 8, 4, 4, 7, 7, 42, 14, 8, 2, 42, 13, 14, 1, 54, 7, 8, 8, 4, 7, 8, 14, 14, 1, 7, 1, 45, 4, 4, 42, 2, 11, 56, 8, 56, 4, 1, 6, 4, 3, 6, 1, 14], [10, 12, 18, 55, 42, 56, 4, 51, 18, 39, 30, 6, 45, 6, 4, 7, 56, 1, 4, 7, 7, 4, 14, 18, 4, 4, 2, 51, 14, 11, 4, 2, 2, 56, 45, 36, 14, 6, 7, 4, 7, 4, 45, 4, 7, 7, 42, 21, 42, 4, 1, 7, 42, 7, 42, 45, 5, 13, 4, 7, 14, 1, 7, 1, 1, 7, 1, 1, 9, 1, 13, 1, 7, 11, 4, 13, 14, 1, 14, 8, 1, 7, 14, 11, 4, 4, 4, 4, 14, 42, 14, 14, 42, 42, 1, 54, 9, 1, 14, 56, 4, 1, 1, 7, 7, 4, 4, 7, 56, 1, 4, 4, 1, 8, 11, 4, 3, 13, 14, 48, 13, 14, 56, 13, 56, 50, 14, 4, 14, 14, 4, 4, 48, 50, 7, 48, 45, 13, 4, 14, 13, 4, 14, 4, 7, 6, 7, 4, 6, 6, 13, 6, 14, 6, 4, 11, 6, 56, 6, 4, 6, 42, 13, 6, 13, 24, 13, 42, 14, 4, 4, 1, 4], [21, 18, 42, 42, 9, 5, 18, 42, 18, 10, 18, 42, 45, 6, 56, 45, 4, 7, 4, 7, 53, 7, 18, 14, 11, 14, 54, 6, 11, 4, 2, 1, 42, 4, 18, 42, 56, 13, 13, 42, 4, 9, 4, 6, 7, 42, 42, 14, 8, 4, 42, 6, 56, 14, 42, 11, 6, 54, 4, 14, 7, 7, 42, 7, 54, 4, 14, 45, 6, 1, 4, 11, 4, 42, 7, 14, 56, 1, 56, 42, 14, 14, 56, 4, 4, 42, 42, 1, 42, 1, 42, 45, 1, 8, 1, 42, 4, 8, 4, 1, 14, 7, 2, 1, 14, 1, 7, 14, 11, 11, 1, 42, 4, 11, 4, 1, 56, 6, 8, 14, 1, 42, 1, 1, 7, 4, 4, 14, 0, 42, 8, 1, 4, 48, 4, 13, 17, 4, 1, 6], [18, 18, 42, 3, 42, 42, 1, 42, 7, 14, 33, 18, 4, 1, 7, 4, 18, 5, 7, 18, 7, 18, 1, 24, 18, 11, 45, 4, 15, 18, 18, 3, 5, 8, 18, 42, 14, 8, 14, 4, 3, 2, 7, 4, 18, 54, 45, 46, 14, 7, 14, 42, 14, 7, 3, 11, 7, 7, 4, 7, 1, 7, 14, 27, 14, 14, 7, 4, 7, 1, 11, 2, 4, 9, 42, 1, 4, 1, 42, 1, 8, 8, 3, 8, 4, 4, 8, 1, 1, 42, 7, 3, 14, 42, 14, 42, 42, 14, 8, 42, 4, 7, 11, 56, 1, 4, 45, 7, 7, 11, 8, 1, 4, 7, 4, 6, 11, 7, 7, 3, 7, 14, 7, 4, 45, 6, 42, 6, 6, 42, 1, 8, 14, 7, 4, 4, 42, 1, 1, 43, 7, 1, 11, 1, 7, 14, 6, 4, 11, 7, 6, 4, 4, 4, 6, 4, 4, 4, 4, 7, 11, 7, 4, 7, 42, 4, 14, 4, 1, 42, 6, 42, 42, 14, 42], [18, 12, 18, 50, 14, 18, 18, 42, 39, 18, 18, 4, 6, 4, 7, 13, 14, 50, 54, 14, 18, 51, 4, 4, 43, 11, 4, 8, 6, 3, 48, 33, 3, 18, 6, 4, 18, 4, 4, 14, 42, 42, 11, 4, 3, 54, 42, 4, 3, 14, 14, 7, 4, 51, 14, 13, 33, 4, 7, 42, 4, 1, 4, 11, 1, 4, 4, 6, 1, 11, 6, 7, 4, 1, 42, 42, 42, 1, 14, 2, 11, 2, 8, 1, 4, 4, 42, 1, 39, 42, 1, 1, 7, 14, 4, 6, 1, 4, 46, 1, 7, 14, 11, 4, 4, 42, 7, 45, 4, 7, 4, 11, 4, 56, 6, 14, 42, 56, 7, 30, 7, 8, 1, 14, 4, 1, 4, 14, 4, 4, 7], [42, 4, 46, 18, 2, 7, 8, 53, 18, 18, 18, 4, 18, 14, 3, 45, 4, 7, 18, 18, 52, 7, 18, 7, 18, 12, 14, 8, 6, 11, 7, 4, 7, 13, 14, 7, 4, 4, 30, 48, 4, 4, 4, 4, 42, 42, 6, 14, 4, 14, 4, 42, 48, 7, 8, 8, 7, 42, 54, 14, 7, 14, 36, 4, 1, 7, 14, 4, 6, 14, 4, 48, 5, 8, 42, 4, 7, 42, 11, 14, 6, 4, 14, 42, 30, 11, 4, 4, 42, 18, 4, 14, 4, 4, 52, 42, 6, 14, 13, 13, 4, 4, 7, 6, 6, 7, 4, 7, 4, 7, 4, 6, 4, 11, 14, 42, 11, 4, 11, 42, 4, 2, 7, 14, 42, 56, 4, 1, 8, 4, 1, 4, 2, 4, 13, 42, 11, 14, 6, 4, 14, 14, 6, 14, 14, 7, 4, 7, 7, 6, 7, 7, 14, 5, 6, 4], [46, 18, 4, 8, 4, 4, 14, 56, 8, 1, 10, 1, 6, 18, 30, 5, 4, 7, 56, 14, 9, 18, 51, 18, 18, 3, 7, 4, 11, 18, 4, 2, 7, 7, 4, 13, 12, 6, 6, 7, 7, 4, 56, 7, 4, 42, 14, 14, 42, 3, 8, 8, 14, 5, 14, 2, 4, 8, 1, 4, 7, 8, 4, 7, 14, 6, 6, 6, 14, 18, 42, 6, 11, 4, 4, 42, 14, 5, 51, 8, 56, 14, 4, 14, 4, 13, 4, 8, 2, 14, 42, 1, 4, 42, 1, 14, 4, 1, 1, 7, 7, 4, 7, 14, 7, 4, 4, 7, 11, 42, 7, 1, 14, 11, 5, 4, 1, 4, 1, 4, 48, 42, 42, 1, 36, 10, 4, 42, 42, 4, 48, 1, 8, 7, 1, 14, 13, 14, 1, 14], [18, 18, 18, 54, 8, 6, 13, 18, 18, 0, 18, 4, 12, 7, 45, 14, 18, 50, 7, 48, 18, 56, 4, 30, 18, 11, 4, 6, 18, 42, 7, 14, 21, 42, 18, 18, 42, 4, 4, 6, 6, 6, 11, 14, 6, 18, 51, 6, 8, 7, 8, 56, 51, 14, 8, 1, 4, 7, 14, 4, 1, 7, 4, 8, 14, 1, 6, 3, 11, 7, 8, 7, 1, 1, 11, 4, 14, 7, 7, 12, 42, 42, 8, 42, 1, 1, 7, 14, 4, 1, 4, 3, 14, 32, 6, 20, 14, 5, 42, 5, 6, 14, 7, 6, 4, 14, 5, 42, 6, 4, 4, 4, 6, 7, 7, 6, 45, 11, 3, 7, 6, 42, 6, 8, 1, 7, 54, 11, 13, 14, 10, 4, 8, 1, 1, 56, 14, 14, 1, 1, 7, 4, 42, 14, 7, 7, 4, 4, 13, 6, 42, 7, 48, 6, 2, 1, 8, 6, 42, 14, 1, 4, 7, 4, 6, 1], [11, 18, 11, 30, 14, 8, 14, 6, 18, 5, 53, 42, 42, 4, 4, 7, 18, 14, 7, 6, 4, 4, 56, 54, 18, 4, 11, 14, 4, 6, 4, 4, 42, 18, 42, 2, 4, 6, 42, 4, 6, 4, 52, 6, 5, 51, 56, 6, 5, 42, 7, 1, 14, 1, 4, 4, 42, 14, 14, 53, 4, 7, 6, 42, 4, 4, 4, 42, 42, 42, 1, 14, 11, 7, 7, 7, 13, 4, 14, 14, 1, 14, 4, 5, 42, 13, 42, 4, 4, 4, 14, 42, 1, 1, 42, 13, 6, 10, 4, 6, 6, 56, 4, 7, 5, 48, 42, 6, 7, 9, 6, 4, 56, 4, 11, 1, 4, 1, 18, 13, 11, 8], [18, 8, 0, 18, 6, 14, 11, 5, 8, 18, 42, 4, 7, 9, 4, 1, 51, 18, 18, 12, 42, 18, 14, 11, 4, 46, 54, 18, 6, 18, 4, 10, 50, 13, 56, 11, 54, 4, 4, 14, 3, 53, 18, 6, 54, 45, 42, 2, 8, 14, 18, 7, 18, 4, 4, 14, 7, 3, 12, 48, 6, 4, 6, 45, 14, 4, 11, 11, 14, 4, 7, 7, 42, 13, 14, 13, 7, 1, 6, 14, 14, 4, 4, 42, 6, 56, 4, 13, 7, 7, 45, 7, 42, 14, 4, 1, 1, 7, 56, 14, 4, 6, 6, 7, 4, 7, 11, 42, 8, 7, 11, 6, 4, 45, 5, 7, 7, 14, 14, 6, 14, 6, 1, 14, 7, 4, 2, 14, 14, 56, 1, 13, 6, 6, 6, 4, 1, 12, 6, 42, 6, 8, 8, 56, 14, 14, 1, 8, 42, 6, 4, 7, 51, 11, 7, 7, 7, 3, 14, 6, 6, 8, 11, 7, 4, 42, 1, 48, 14, 14, 42, 42, 6, 6, 14], [18, 4, 18, 18, 13, 56, 6, 42, 42, 7, 2, 4, 7, 8, 8, 14, 18, 12, 46, 45, 18, 42, 7, 11, 7, 9, 7, 4, 6, 9, 7, 5, 5, 11, 1, 45, 6, 1, 5, 9, 4, 5, 8, 6, 4, 54, 1, 42, 42, 8, 14, 3, 7, 30, 0, 3, 4, 12, 4, 7, 4, 4, 42, 6, 7, 7, 54, 14, 4, 56, 11, 7, 13, 7, 7, 56, 4, 6, 42, 8, 6, 8, 6, 4, 45, 7, 13, 6, 13, 7, 13, 4, 4, 42, 1, 2, 7, 42, 42, 1, 1, 1, 14, 7, 6, 45, 4, 14, 7, 1, 13, 14, 56, 7, 7, 42, 7, 8, 14, 7, 11, 7, 48, 13, 7, 7, 7, 14, 7, 1, 1, 6, 11, 7, 6, 11, 1, 6, 4], [48, 42, 18, 5, 14, 18, 42, 18, 56, 5, 13, 42, 7, 4, 7, 7, 4, 6, 3, 7, 13, 7, 4, 54, 45, 18, 11, 7, 4, 56, 8, 42, 14, 6, 42, 6, 44, 4, 4, 4, 56, 45, 4, 42, 12, 14, 14, 42, 13, 13, 14, 14, 4, 6, 6, 8, 14, 6, 4, 4, 7, 4, 4, 11, 6, 6, 8, 6, 56, 8, 1, 11, 4, 4, 1, 14, 12, 14, 42, 6, 7, 5, 42, 4, 4, 42, 48, 3, 56, 42, 14, 48, 11, 6, 4, 8, 4, 4, 7, 42, 4, 7, 7, 7, 4, 4, 5, 4, 7, 11, 56, 7, 6, 14, 6, 14, 4, 7, 6, 14, 54, 6], [42, 18, 1, 4, 45, 14, 18, 1, 6, 42, 19, 9, 4, 6, 7, 4, 7, 56, 18, 45, 6, 18, 9, 18, 38, 4, 11, 4, 26, 7, 15, 18, 42, 7, 18, 2, 2, 56, 7, 4, 18, 12, 18, 4, 3, 42, 18, 8, 14, 3, 42, 14, 23, 56, 7, 7, 14, 4, 7, 56, 4, 51, 7, 5, 4, 4, 7, 7, 53, 7, 14, 8, 4, 11, 1, 7, 4, 6, 4, 14, 56, 14, 13, 8, 6, 1, 8, 4, 7, 42, 11, 4, 4, 14, 7, 42, 1, 1, 42, 13, 6, 8, 1, 8, 6, 42, 4, 7, 1, 7, 6, 14, 14, 6, 13, 11, 1, 1, 4, 45, 3, 7, 14, 11, 7, 7, 7, 4, 1, 8, 14, 42, 7, 8, 56, 4, 7, 48, 1, 56, 4, 7, 7, 6, 1, 14, 8, 4, 13, 3, 3, 42, 14, 2, 1, 6, 14, 17, 4, 14, 7, 6, 7, 4, 6, 7, 7], [18, 14, 7, 4, 56, 6, 9, 18, 42, 4, 18, 4, 1, 7, 54, 43, 7, 51, 7, 4, 7, 4, 36, 18, 56, 11, 14, 11, 4, 51, 8, 7, 4, 42, 3, 11, 14, 6, 45, 4, 4, 8, 54, 42, 5, 7, 14, 6, 42, 14, 14, 14, 42, 4, 48, 8, 42, 4, 14, 4, 7, 1, 7, 4, 1, 6, 54, 11, 4, 14, 4, 11, 4, 42, 1, 54, 11, 6, 6, 4, 45, 14, 42, 14, 4, 4, 42, 14, 14, 14, 1, 7, 42, 56, 42, 6, 1, 4, 7, 4, 8, 4, 11, 6, 14, 7, 1, 4, 4, 8, 11, 1, 1], [18, 7, 1, 33, 13, 8, 4, 6, 7, 51, 49, 4, 7, 18, 11, 21, 4, 52, 38, 4, 11, 7, 7, 4, 11, 4, 41, 45, 1, 13, 28, 12, 30, 14, 18, 8, 4, 11, 4, 42, 8, 54, 54, 42, 42, 42, 42, 14, 42, 18, 5, 4, 56, 2, 1, 8, 8, 6, 7, 11, 4, 2, 6, 1, 7, 4, 56, 11, 11, 1, 7, 7, 8, 1, 4, 1, 3, 7, 4, 8, 11, 4, 45, 1, 13, 1, 42, 14, 6, 4, 42, 48, 14, 42, 18, 4, 7, 4, 42, 7, 1, 24, 8, 14, 7, 14, 45, 14, 11, 4, 7, 4, 6, 4, 7, 42, 4, 7, 6, 48, 7, 8, 1, 11, 4, 4, 13, 14, 6, 4, 8], [27, 39, 18, 1, 1, 2, 12, 44, 18, 8, 36, 42, 7, 4, 7, 36, 8, 4, 52, 4, 4, 4, 9, 18, 36, 18, 7, 11, 4, 1, 42, 3, 3, 9, 46, 4, 9, 1, 14, 8, 5, 4, 4, 14, 42, 1, 42, 7, 6, 2, 48, 42, 1, 36, 14, 6, 1, 1, 45, 4, 7, 12, 42, 4, 6, 7, 1, 56, 4, 4, 14, 11, 1, 4, 9, 2, 2, 1, 6, 4, 1, 1, 4, 4, 11, 4, 4, 42, 14, 6, 14, 4, 45, 8, 1, 44, 42, 42, 11, 4, 7, 14, 42, 4, 1, 1, 42, 13, 8, 1, 56, 11, 7, 1, 4, 42, 6, 13, 42, 13, 13, 42, 8, 13, 14, 6, 7, 4, 8, 6, 1, 4, 14, 6, 1, 13, 42, 3, 13, 6, 6, 54, 42, 42, 7, 6, 14, 4, 6, 4, 13, 7, 13, 13, 8, 54, 4, 8], [2, 26, 18, 2, 48, 1, 54, 8, 56, 8, 45, 38, 14, 4, 7, 7, 14, 52, 4, 14, 1, 8, 7, 7, 13, 18, 11, 4, 14, 7, 45, 4, 3, 8, 4, 30, 18, 8, 7, 4, 4, 56, 14, 14, 18, 39, 9, 13, 7, 20, 18, 39, 6, 5, 14, 6, 4, 7, 3, 3, 7, 45, 14, 3, 14, 3, 6, 7, 4, 11, 6, 4, 45, 6, 45, 6, 45, 7, 6, 6, 14, 13, 7, 4, 4, 42, 6, 14, 41, 3, 1, 14, 6, 6, 3, 14, 4, 7, 14, 6, 6, 1, 42, 55, 7, 8, 8, 7, 11, 7, 7, 7, 7, 4, 13, 56, 6, 56, 3, 6, 8, 14, 1, 45, 4, 6, 8, 4, 42, 42, 1, 14, 42, 42, 48, 44, 8, 45, 1, 14, 4, 7, 7, 4, 1, 4, 4, 4, 53, 7, 2, 14, 7, 11, 4, 4, 6, 1, 14, 50, 13, 1, 10, 4, 1, 1], [46, 42, 6, 18, 56, 11, 42, 14, 56, 42, 42, 18, 18, 14, 14, 4, 18, 14, 6, 4, 45, 1, 7, 3, 50, 42, 18, 5, 7, 6, 47, 7, 2, 48, 11, 7, 4, 8, 7, 5, 1, 9, 18, 45, 42, 6, 1, 4, 48, 4, 14, 42, 51, 11, 8, 1, 7, 8, 14, 14, 13, 42, 4, 7, 1, 4, 1, 35, 7, 7, 56, 50, 6, 8, 13, 4, 4, 4, 4, 7, 11, 4, 42, 14, 1, 50, 48, 4, 4, 3, 14, 14, 7, 4, 4, 42, 42, 1, 42, 8, 1, 1, 42, 14, 48, 14, 42, 7, 1, 4, 7, 1, 14, 11, 4, 11, 14, 14, 7, 7, 45, 11], [42, 18, 5, 24, 8, 56, 39, 18, 48, 48, 7, 56, 14, 4, 7, 26, 42, 9, 4, 18, 7, 6, 7, 18, 4, 11, 4, 6, 3, 50, 4, 7, 4, 45, 18, 48, 1, 4, 6, 4, 45, 54, 42, 14, 6, 42, 35, 5, 42, 7, 54, 14, 4, 14, 3, 4, 1, 8, 45, 4, 7, 7, 7, 7, 7, 3, 4, 7, 4, 8, 8, 11, 4, 14, 4, 14, 1, 1, 8, 1, 12, 14, 7, 1, 4, 4, 6, 1, 6, 56, 1, 8, 42, 7, 14, 42, 11, 8, 14, 13, 14, 14, 4, 11, 4, 7, 13, 14, 14, 13, 7, 14, 7, 7, 7, 42, 11, 6, 4, 7, 1, 1, 14, 1, 4, 1, 11, 4, 14, 4, 1, 11, 4, 6, 8, 42, 14, 56, 56, 42, 8, 14, 13, 13, 8, 7, 4, 7, 7, 6, 45, 54, 7, 6, 13, 6, 6, 14, 11, 8, 11, 1, 14, 1, 4, 13, 14, 50, 14, 6, 3, 6, 6, 42, 4, 4, 13, 3, 4, 14, 42, 7, 7, 14, 6, 8, 14, 4, 6, 5, 14, 56, 4, 7, 9, 6, 6, 1, 11, 4, 11, 9], [18, 55, 14, 8, 14, 48, 42, 5, 18, 30, 42, 18, 4, 7, 50, 7, 9, 18, 7, 11, 6, 6, 54, 45, 5, 11, 11, 10, 4, 47, 4, 6, 8, 1, 6, 4, 7, 1, 56, 4, 14, 42, 4, 42, 13, 42, 42, 14, 13, 4, 4, 4, 42, 42, 42, 14, 6, 4, 14, 7, 11, 7, 42, 54, 1, 13, 4, 1, 7, 7, 11, 4, 8, 1, 13, 42, 8, 45, 50, 5, 4, 4, 4, 4, 48, 1, 14, 7, 6, 7, 4, 42, 56, 6, 13, 4, 7, 11, 4, 8, 5, 7, 1, 4, 50, 4, 39, 11, 3, 7, 4, 42, 14, 14, 13, 3, 14, 1, 42, 6, 6, 1, 1, 7, 4, 4, 1, 42, 7, 14, 1, 6, 7, 14, 1, 42, 13, 14, 42, 1, 56, 14, 4, 13, 3, 7, 7, 6, 10, 6, 4, 11, 6, 56, 11, 42, 1], [18, 45, 56, 42, 4, 30, 18, 14, 7, 14, 7, 4, 7, 42, 2, 7, 43, 4, 46, 5, 3, 45, 45, 7, 11, 4, 6, 42, 42, 50, 14, 14, 14, 4, 7, 7, 4, 4, 4, 7, 11, 5, 14, 14, 42, 1, 42, 7, 8, 3, 42, 14, 13, 7, 4, 6, 14, 6, 4, 7, 8, 3, 4, 11, 7, 4, 7, 4, 14, 54, 11, 7, 4, 11, 8, 42, 6, 11, 14, 14, 56, 6, 4, 4, 14, 42, 1, 4, 42, 42, 4, 14, 42, 14, 7, 8, 14, 8, 1, 4, 1, 7, 4, 11, 54, 4, 42, 42, 4, 4, 4, 6, 11, 14, 4, 14, 13, 1, 14, 3, 2, 7, 7, 14, 6, 4, 4, 14, 42, 8, 14, 13, 14, 11, 7, 3, 14, 14, 6, 4, 1, 7, 13, 13, 1, 11, 1, 11, 7, 4, 7, 8, 11, 7, 4, 13, 6, 7, 35, 13, 14, 36, 11, 2, 42, 4], [18, 7, 14, 11, 45, 42, 7, 14, 6, 14, 42, 18, 45, 45, 4, 7, 54, 4, 18, 42, 7, 7, 56, 42, 7, 4, 4, 6, 11, 4, 45, 49, 14, 7, 14, 4, 4, 42, 8, 14, 4, 6, 1, 4, 42, 14, 42, 42, 6, 12, 6, 42, 7, 1, 11, 14, 6, 7, 4, 7, 4, 42, 3, 13, 6, 4, 11, 4, 14, 7, 2, 11, 4, 13, 14, 42, 14, 3, 6, 9, 13, 42, 4, 4, 4, 54, 42, 42, 56, 42, 42, 6, 42, 42, 1, 42, 14, 4, 7, 4, 11, 7, 7, 7, 1, 4, 4, 4, 7, 11, 11, 7, 4, 1, 4, 4, 11, 8, 42, 42, 4, 4, 14, 4, 4, 42, 14, 11, 11, 14, 13, 6, 14, 8, 1, 1, 4, 7, 4, 6, 4, 14, 14, 4, 4, 13, 4, 11, 11], [18, 18, 18, 1, 7, 42, 48, 1, 42, 7, 33, 56, 4, 7, 11, 45, 18, 4, 18, 4, 50, 4, 14, 7, 11, 48, 7, 4, 42, 8, 4, 6, 50, 1, 3, 56, 36, 14, 51, 4, 4, 2, 1, 6, 42, 7, 42, 11, 42, 51, 14, 1, 10, 6, 11, 42, 11, 1, 4, 7, 4, 54, 6, 4, 4, 52, 5, 4, 13, 42, 1, 1, 11, 4, 14, 14, 4, 42, 9, 45, 3, 14, 4, 42, 3, 4, 4, 14, 4, 42, 10, 6, 7, 14, 4, 7, 14, 4, 2, 14, 10, 56, 11, 4, 7, 4, 8, 1, 45, 6, 54, 51, 42, 7, 14, 11, 4, 42, 14, 14, 8, 1], [18, 14, 6, 0, 47, 2, 4, 14, 8, 18, 14, 4, 7, 15, 7, 7, 9, 1, 1, 9, 7, 7, 14, 11, 2, 7, 4, 7, 7, 7, 42, 1, 54, 7, 8, 7, 6, 4, 4, 7, 45, 4, 42, 42, 7, 42, 42, 42, 8, 42, 2, 42, 6, 42, 7, 4, 13, 42, 7, 56, 3, 7, 1, 42, 8, 1, 6, 13, 4, 7, 8, 1, 1, 1, 1, 7, 14, 14, 1, 8, 11, 4, 5, 14, 14, 13, 6, 6, 1, 13, 1, 14, 4, 4, 42, 45, 7, 14, 50, 14, 4, 2, 45, 8, 8, 4, 4, 7, 42, 11, 6, 7, 50, 45, 4, 13, 4, 14, 11, 14, 4, 1, 42, 4, 54, 7, 6, 7, 14, 4, 56], [18, 14, 7, 7, 5, 8, 14, 54, 45, 50, 42, 4, 42, 7, 48, 50, 9, 1, 18, 18, 48, 7, 6, 1, 14, 54, 2, 11, 7, 4, 8, 2, 43, 42, 14, 30, 4, 14, 42, 42, 4, 1, 4, 8, 42, 13, 14, 4, 42, 42, 42, 6, 6, 9, 1, 42, 4, 7, 5, 6, 4, 14, 7, 4, 4, 45, 4, 6, 7, 6, 4, 11, 4, 11, 7, 4, 9, 8, 42, 45, 11, 14, 11, 42, 14, 1, 4, 8, 6, 4, 14, 8, 14, 4, 14, 42, 54, 6, 1, 4, 1, 1, 42, 5, 8, 1, 4, 1, 8, 7, 11, 1, 14, 1, 14, 6, 1, 8, 7, 11, 11, 2, 4, 18, 8, 14, 18, 1, 1, 8, 39, 42, 1, 4, 14, 4, 42, 54, 1, 1, 3, 14, 54, 7, 42, 42, 2, 4, 4, 7, 1, 48, 4, 1, 1, 1, 14, 1], [18, 14, 45, 45, 14, 24, 1, 2, 18, 14, 14, 42, 4, 7, 11, 18, 2, 18, 18, 6, 7, 42, 14, 18, 7, 11, 4, 8, 42, 13, 27, 56, 4, 1, 1, 3, 2, 4, 45, 4, 53, 6, 14, 36, 42, 3, 14, 14, 14, 54, 1, 37, 8, 5, 4, 1, 42, 8, 7, 7, 14, 56, 14, 56, 4, 1, 1, 7, 56, 4, 8, 7, 1, 45, 1, 8, 7, 14, 13, 4, 4, 11, 3, 1, 6, 11, 4, 4, 56, 7, 7, 6, 4, 56, 1, 8, 4, 4, 56, 7, 4, 7, 1, 6, 1, 14, 1, 42, 42, 14, 6, 7, 14, 6, 6, 42, 4, 14, 4, 7, 4, 54, 4, 6, 7, 42, 4, 6, 6, 6, 8, 11, 4, 6, 13, 14, 42, 13, 14, 48, 42, 6, 1, 4, 13, 42, 4, 8, 6, 14, 6, 13, 42, 6, 8, 42, 13, 6, 7, 3, 6, 50, 1, 4, 7, 9, 13, 3, 7, 7, 13, 1, 7, 7, 4, 11, 4, 14, 42, 1, 56, 7, 7, 6, 6, 7, 42, 4, 14, 8, 4, 6, 54], [18, 5, 5, 7, 48, 42, 42, 6, 7, 13, 18, 42, 4, 7, 18, 0, 2, 12, 18, 4, 4, 9, 14, 54, 11, 44, 45, 4, 6, 6, 8, 56, 18, 18, 42, 56, 7, 1, 4, 6, 7, 45, 4, 42, 42, 42, 6, 14, 42, 8, 14, 4, 42, 14, 7, 54, 14, 42, 4, 4, 14, 7, 14, 11, 14, 4, 54, 14, 14, 4, 1, 42, 11, 4, 8, 1, 12, 7, 1, 14, 13, 13, 8, 42, 4, 14, 4, 42, 14, 7, 42, 14, 8, 42, 13, 7, 14, 11, 4, 7, 14, 45, 4, 6, 42, 42, 4, 12, 14, 4, 11, 4, 8], [54, 18, 18, 1, 1, 38, 7, 18, 11, 6, 7, 5, 4, 7, 8, 18, 14, 33, 4, 52, 13, 1, 18, 18, 14, 11, 8, 7, 4, 36, 42, 8, 6, 42, 42, 7, 4, 7, 4, 4, 4, 7, 4, 14, 14, 4, 42, 6, 14, 50, 2, 48, 56, 1, 48, 45, 42, 4, 1, 7, 13, 4, 13, 14, 6, 13, 7, 13, 4, 42, 11, 4, 1, 42, 14, 56, 1, 42, 14, 7, 14, 6, 4, 6, 12, 8, 4, 14, 4, 14, 1, 42, 14, 51, 8, 42, 42, 14, 8, 14, 7, 1, 4, 7, 6, 45, 7, 8, 7, 7, 6, 14, 4, 4, 7, 11, 8, 4, 4, 6, 1, 7, 1, 14, 11, 3, 7, 1, 4, 4, 8, 1, 56, 36, 1, 42, 1, 14, 14, 56, 47, 6, 8, 7, 42, 14, 7, 4, 7, 1, 4, 14, 6, 7, 6, 1, 14], [21, 18, 30, 46, 34, 14, 14, 14, 2, 54, 48, 56, 50, 4, 7, 24, 18, 8, 18, 1, 8, 11, 13, 18, 4, 13, 11, 4, 4, 8, 13, 7, 14, 22, 11, 24, 18, 11, 4, 54, 4, 14, 42, 45, 14, 1, 13, 42, 18, 5, 9, 42, 14, 5, 42, 42, 14, 45, 14, 7, 4, 1, 7, 13, 1, 13, 1, 11, 14, 7, 6, 4, 4, 11, 4, 4, 7, 42, 4, 14, 4, 2, 14, 7, 4, 4, 14, 4, 42, 6, 42, 14, 2, 1, 14, 4, 13, 42, 14, 13, 4, 7, 4, 4, 13, 4, 4, 45, 4, 1, 7, 1, 11, 4, 6, 2, 4, 14, 39, 1, 8, 2, 3, 8, 4, 7, 6, 7, 4, 14, 55, 1, 4, 42, 1, 14, 0, 8, 14, 42, 8, 1, 1, 14, 1, 11, 1, 4, 7, 1, 4, 4, 13, 1, 4, 4, 42, 14, 1, 42, 4, 14, 14, 42, 14, 2], [18, 13, 51, 18, 45, 36, 12, 12, 42, 1, 4, 4, 7, 42, 7, 7, 18, 4, 4, 8, 7, 7, 4, 11, 4, 18, 6, 42, 1, 1, 4, 1, 1, 4, 11, 4, 4, 42, 42, 42, 3, 30, 4, 8, 14, 4, 4, 56, 14, 14, 45, 4, 4, 7, 2, 14, 4, 13, 42, 14, 14, 14, 1, 14, 13, 11, 1, 4, 42, 7, 54, 48, 14, 42, 42, 14, 8, 4, 4, 3, 54, 42, 4, 42, 1, 42, 6, 6, 56, 14, 42, 48, 13, 14, 4, 7, 14, 10, 7, 4, 56, 4, 1, 4, 4, 11, 11, 4, 8, 1, 45, 4, 18, 6, 4, 45, 4, 8, 4, 1, 4, 6], [18, 6, 8, 7, 42, 48, 10, 3, 51, 3, 42, 18, 4, 7, 12, 26, 36, 4, 52, 18, 6, 4, 7, 8, 11, 4, 6, 51, 54, 6, 3, 56, 5, 33, 7, 46, 4, 4, 42, 42, 6, 36, 14, 13, 1, 2, 1, 8, 6, 6, 42, 7, 56, 4, 7, 1, 6, 4, 14, 6, 13, 48, 7, 8, 4, 11, 4, 14, 6, 1, 42, 18, 8, 7, 4, 30, 4, 56, 4, 4, 14, 1, 42, 4, 4, 56, 1, 48, 42, 8, 14, 4, 4, 56, 4, 1, 7, 7, 6, 11, 1, 7, 7, 8, 7, 51, 11, 56, 11, 7, 4, 4, 4, 8, 14, 6, 8, 42, 5, 3, 14, 8, 56, 1, 4, 56, 7, 42, 4, 8, 48, 4, 14, 13, 14, 48, 14, 8, 6, 14, 14, 13, 8, 4, 55, 14, 7, 8, 6], [4, 18, 14, 49, 8, 50, 56, 14, 4, 14, 5, 56, 8, 4, 7, 6, 18, 45, 18, 18, 18, 3, 14, 8, 42, 11, 30, 54, 4, 8, 54, 42, 14, 4, 14, 1, 4, 1, 42, 4, 45, 4, 9, 42, 6, 14, 50, 42, 6, 4, 3, 42, 2, 4, 42, 14, 1, 14, 4, 3, 7, 7, 11, 2, 7, 8, 6, 56, 13, 53, 42, 11, 4, 48, 7, 8, 7, 24, 56, 1, 51, 42, 42, 13, 4, 14, 4, 12, 13, 42, 14, 6, 1, 7, 6, 6, 9, 45, 6, 4, 14, 1, 4, 7, 6, 14, 13, 8, 42, 7, 7, 7, 14, 11, 11, 7, 4, 7, 1, 6, 1, 14, 45, 8, 42, 3, 1, 7, 4, 11, 6, 12, 4, 48, 6, 14, 14, 8, 42, 1, 42, 42, 1, 13, 11, 1, 4, 14, 7, 4, 10, 7, 56, 8, 14, 7, 7], [18, 5, 8, 56, 18, 55, 14, 18, 14, 14, 36, 8, 4, 7, 48, 4, 3, 56, 7, 45, 50, 4, 18, 36, 4, 11, 4, 1, 48, 4, 56, 1, 2, 7, 7, 4, 11, 14, 4, 4, 2, 42, 7, 1, 1, 3, 42, 14, 6, 4, 14, 7, 6, 7, 8, 56, 4, 4, 7, 4, 56, 7, 4, 6, 4, 4, 7, 4, 2, 11, 4, 8, 42, 8, 42, 7, 3, 42, 14, 14, 1, 4, 45, 42, 11, 56, 42, 4, 14, 42, 42, 45, 6, 14, 4, 6, 8, 8, 4, 13, 6, 9, 4, 7, 42, 1, 7, 6, 13, 13, 4, 7, 6, 14, 11, 2, 1, 8, 2, 13, 56, 8, 8, 4, 4, 14, 14, 8, 1, 7, 14, 4, 6, 14, 50, 4, 1, 13, 45, 4, 42, 14, 13, 1, 14, 6, 6, 42], [33, 18, 1, 18, 56, 2, 12, 54, 18, 6, 18, 18, 4, 7, 2, 18, 5, 4, 4, 4, 18, 4, 7, 7, 32, 12, 11, 4, 4, 42, 1, 51, 42, 1, 54, 42, 42, 4, 18, 4, 42, 4, 42, 10, 53, 2, 45, 42, 6, 14, 6, 4, 4, 42, 4, 2, 6, 14, 42, 4, 7, 13, 1, 4, 7, 4, 4, 4, 6, 4, 14, 11, 4, 8, 4, 1, 42, 42, 6, 8, 56, 42, 13, 4, 13, 4, 14, 56, 6, 8, 3, 14, 11, 14, 4, 6, 4, 4, 42, 6, 14, 3, 42, 13, 54, 6, 8, 14, 8, 4, 7, 14, 1, 14, 51, 4, 11, 7, 4, 14, 11, 11, 50, 8, 4, 13, 14, 14, 6, 4, 14, 14, 1, 1, 13, 4, 5, 45, 42], [36, 18, 7, 5, 44, 39, 8, 18, 45, 45, 5, 18, 4, 7, 14, 18, 56, 4, 54, 4, 4, 56, 14, 18, 11, 4, 18, 18, 7, 24, 45, 47, 42, 56, 7, 14, 4, 4, 8, 14, 42, 14, 4, 42, 12, 5, 50, 42, 14, 50, 14, 42, 42, 7, 13, 14, 42, 4, 4, 14, 7, 4, 6, 14, 1, 11, 6, 4, 4, 7, 42, 14, 11, 8, 56, 4, 56, 45, 6, 14, 6, 14, 42, 6, 51, 42, 6, 3, 5, 4, 14, 42, 4, 6, 14, 2, 8, 7, 8, 13, 47, 13, 4, 13, 42, 13, 18, 8, 6, 42, 13, 13, 42, 14, 6, 4, 48, 13, 7, 7, 54, 4, 6, 13, 4, 6, 6, 12, 7, 13, 4, 11, 7, 7, 14, 4, 13, 42, 13], [18, 7, 8, 4, 7, 7, 18, 18, 8, 3, 50, 18, 4, 7, 18, 11, 3, 54, 42, 31, 56, 18, 2, 48, 3, 18, 11, 4, 45, 14, 42, 12, 18, 0, 4, 14, 56, 54, 5, 4, 3, 4, 6, 18, 14, 1, 14, 1, 4, 1, 45, 50, 7, 13, 4, 7, 4, 7, 14, 14, 4, 13, 4, 6, 7, 9, 11, 13, 4, 3, 8, 54, 50, 6, 1, 1, 6, 11, 42, 6, 3, 14, 4, 42, 6, 14, 6, 6, 8, 7, 30, 13, 7, 4, 42, 12, 8, 1, 51, 6, 6, 14, 14, 1, 42, 4, 42, 8, 4, 1, 56, 7, 5, 7, 6, 12, 6, 6, 13, 1, 13, 14, 13, 6, 11, 6, 4, 54, 13, 1, 13, 4, 1, 42, 6, 6, 42, 30, 7, 1, 14, 4, 42, 4, 5, 2, 42, 13, 1, 14, 4, 42, 8, 14, 42, 8, 14, 4, 11, 7, 13, 11, 6, 5, 4, 6, 2, 4, 11, 7, 11, 6, 4, 14, 8, 1, 42, 13, 4, 6, 7, 1], [18, 14, 18, 24, 18, 6, 4, 13, 54, 13, 30, 6, 4, 1, 7, 8, 56, 4, 14, 45, 4, 3, 14, 11, 24, 18, 11, 7, 4, 4, 56, 7, 4, 13, 30, 11, 5, 11, 14, 4, 4, 14, 42, 4, 42, 50, 45, 13, 42, 13, 14, 13, 8, 30, 14, 24, 7, 6, 6, 4, 4, 7, 7, 11, 11, 14, 14, 33, 1, 42, 7, 42, 45, 11, 50, 1, 1, 4, 7, 14, 1, 14, 45, 6, 7, 42, 6, 7, 11, 7, 53, 4, 6, 7, 4, 42, 11, 42, 13, 1, 8, 6, 6, 1, 1, 42, 13, 7, 8, 1, 4, 8, 6, 7, 1, 7, 51, 4, 11, 1, 6, 13, 54, 1, 7, 7, 7, 14, 11, 10, 8, 4, 8, 7, 1, 6, 8, 54, 14, 1, 7, 14, 8, 4, 14, 5, 1, 1, 4, 14, 42, 4, 6, 14, 7, 6, 42], [42, 5, 18, 14, 45, 4, 8, 13, 56, 7, 11, 52, 18, 4, 7, 24, 42, 4, 18, 51, 4, 1, 42, 27, 50, 8, 11, 4, 45, 3, 1, 7, 45, 14, 14, 7, 6, 7, 4, 4, 42, 18, 14, 6, 45, 3, 53, 7, 14, 45, 56, 11, 4, 7, 11, 55, 24, 4, 11, 6, 4, 9, 7, 11, 11, 4, 36, 7, 6, 13, 6, 9, 54, 14, 8, 5, 4, 8, 4, 8, 13, 42, 1, 1, 42, 1, 8, 14, 54, 7, 14, 6, 11, 4, 7, 13, 56, 7, 4, 4, 42, 48, 13, 6, 7, 14, 4, 2, 11, 4, 1, 14, 56, 6, 8, 1, 56, 14, 3, 3, 3, 4, 4, 14, 6, 6, 14, 13, 13, 1, 14, 42, 13, 13, 56, 7, 14, 42, 45, 8, 3, 14, 14, 4, 7, 4, 7, 13, 7, 7, 4, 11, 7, 7, 7, 7, 1], [18, 14, 45, 5, 8, 45, 1, 56, 13, 8, 7, 18, 18, 4, 7, 8, 42, 3, 24, 21, 7, 13, 7, 18, 7, 11, 8, 4, 7, 42, 14, 14, 14, 1, 7, 18, 1, 1, 4, 56, 4, 1, 18, 48, 7, 8, 7, 14, 13, 1, 54, 42, 1, 7, 7, 4, 7, 8, 1, 7, 7, 1, 6, 4, 14, 4, 7, 14, 11, 4, 7, 14, 6, 11, 42, 3, 2, 6, 42, 42, 4, 6, 4, 42, 4, 14, 42, 7, 42, 56, 14, 14, 48, 7, 4, 7, 7, 4, 14, 14, 6, 13, 1, 3, 7, 8, 8, 11, 7, 1, 14, 8, 4, 14, 7, 6, 2, 14, 1, 6, 4, 4, 14, 4, 6, 8, 1, 4, 8, 42, 1, 6, 56, 7, 14, 7, 7, 6, 8, 14, 4, 7, 4, 4, 7, 14, 4, 56, 7, 8, 4, 7, 7, 4, 11, 4, 56, 8, 6, 13, 14, 7, 1, 13, 6, 9], [18, 51, 7, 36, 18, 18, 3, 14, 18, 14, 56, 18, 24, 4, 7, 4, 28, 24, 7, 18, 1, 2, 1, 18, 2, 3, 53, 45, 1, 8, 4, 11, 7, 53, 4, 13, 5, 2, 54, 7, 42, 14, 42, 13, 54, 6, 4, 4, 42, 18, 42, 7, 14, 48, 48, 14, 13, 42, 7, 4, 13, 1, 14, 7, 7, 5, 7, 4, 7, 11, 4, 4, 4, 4, 11, 14, 42, 4, 6, 8, 4, 54, 45, 4, 48, 48, 7, 44, 4, 4, 42, 13, 56, 8, 8, 13, 1, 14, 6, 14, 6, 13, 11, 7, 4, 7, 13, 14, 6, 14, 45, 45, 6, 3, 4, 13, 6, 11, 4, 1, 6, 13, 1, 11, 6, 42, 42, 8, 6, 4, 6, 4, 13, 3, 1, 4, 6, 1, 54, 1, 8, 7, 7, 14, 1, 48, 9, 1, 14, 1], [18, 7, 4, 51, 42, 4, 18, 9, 6, 45, 18, 4, 7, 32, 53, 12, 18, 4, 18, 4, 18, 56, 24, 11, 1, 4, 18, 48, 42, 56, 48, 6, 1, 14, 45, 8, 4, 4, 6, 42, 13, 1, 42, 51, 42, 8, 14, 42, 4, 54, 56, 42, 6, 14, 42, 14, 42, 42, 4, 1, 7, 7, 7, 4, 4, 11, 6, 1, 4, 54, 42, 13, 11, 4, 2, 1, 13, 14, 2, 6, 42, 6, 1, 13, 4, 4, 13, 42, 42, 35, 42, 4, 4, 3, 6, 14, 1, 6, 4, 8, 13, 7, 4, 4, 14, 1, 6, 4, 7, 4, 11, 6, 11, 4, 6, 7, 36, 6, 9, 6, 6, 6, 56, 8, 6, 13, 4, 42, 3, 14, 42, 6, 4, 6, 42, 14, 7, 6, 6, 8, 6, 6, 7, 13, 7, 4, 7, 4, 7, 3, 14, 48, 2, 7, 7, 13, 4, 7, 11, 42, 6, 7, 4, 7, 14, 1, 7, 6, 42, 14, 6, 2, 6, 6, 4, 1, 14, 7, 4, 7, 42, 42, 42, 8, 13, 14, 14, 45, 14, 13, 14, 7, 4], [18, 14, 13, 3, 54, 56, 11, 14, 7, 5, 45, 7, 18, 4, 48, 7, 42, 18, 7, 56, 13, 18, 55, 9, 42, 18, 47, 13, 11, 4, 18, 6, 48, 56, 7, 56, 42, 42, 1, 6, 4, 4, 14, 3, 32, 13, 2, 4, 3, 6, 45, 4, 52, 42, 42, 30, 48, 30, 7, 13, 13, 4, 3, 7, 4, 50, 4, 7, 7, 7, 45, 6, 7, 4, 6, 8, 4, 1, 6, 8, 11, 7, 4, 42, 1, 6, 45, 6, 54, 11, 45, 1, 42, 13, 1, 7, 14, 6, 6, 4, 6, 6, 4, 14, 45, 6, 13, 42, 1, 6, 14, 42, 42, 48, 6, 48, 14, 3, 4, 1, 7, 8, 11, 6, 14, 6, 14, 4, 11, 7, 14, 11, 4, 42, 11, 45, 6, 54, 13, 8, 14, 8, 3, 4, 1, 6, 14, 56], [18, 7, 2, 18, 45, 6, 48, 14, 42, 18, 42, 1, 54, 4, 7, 45, 7, 4, 7, 14, 18, 13, 6, 4, 3, 37, 41, 11, 4, 6, 6, 1, 3, 55, 13, 4, 4, 13, 50, 4, 4, 48, 14, 56, 42, 42, 13, 3, 18, 8, 48, 11, 6, 4, 56, 14, 14, 42, 56, 14, 4, 7, 6, 14, 4, 4, 4, 11, 4, 45, 4, 11, 11, 4, 13, 12, 8, 6, 4, 7, 6, 3, 42, 2, 1, 4, 4, 42, 4, 48, 14, 1, 2, 6, 48, 14, 7, 14, 4, 7, 4, 7, 4, 11, 4, 4, 4, 11, 7, 3, 4, 11, 4, 13, 14, 42, 6, 2, 42, 6, 14, 3, 14, 6, 13, 4, 42, 4, 2, 42, 6, 7, 4, 14, 6, 6, 42, 4, 1, 4, 4, 4, 7, 7, 47, 4, 4, 4, 4, 4, 45, 6, 6], [18, 50, 1, 8, 18, 8, 7, 42, 6, 6, 18, 4, 7, 4, 53, 18, 8, 11, 4, 18, 7, 3, 4, 6, 11, 8, 4, 5, 4, 4, 4, 42, 9, 13, 54, 4, 54, 4, 4, 14, 42, 3, 8, 42, 14, 51, 42, 6, 42, 1, 14, 4, 42, 8, 14, 6, 4, 4, 1, 4, 6, 5, 7, 45, 54, 11, 13, 11, 4, 4, 7, 4, 14, 11, 4, 1, 4, 8, 4, 4, 14, 3, 4, 1, 42, 7, 4, 4, 56, 14, 2, 45, 14, 14, 45, 56, 44, 42, 42, 4, 4, 14, 14, 7, 14, 6, 11, 42, 6, 4, 7, 7, 4, 42, 1, 14, 7, 14, 7, 8, 8, 3, 4, 7, 11, 4, 1, 14, 13, 13, 54, 4, 6, 14, 1, 4, 4, 1, 4, 14, 8, 42, 14, 14, 1, 1, 8, 8, 14, 7, 1, 7, 4, 14, 1, 6, 7, 1, 14, 13, 30, 7, 6, 1, 7, 4, 14], [18, 8, 6, 7, 2, 2, 51, 42, 1, 50, 18, 4, 7, 7, 18, 50, 11, 42, 6, 33, 4, 3, 54, 11, 51, 4, 44, 6, 5, 48, 42, 18, 13, 3, 4, 36, 4, 42, 5, 14, 1, 4, 4, 42, 54, 38, 6, 14, 50, 42, 56, 42, 4, 9, 42, 14, 14, 42, 14, 8, 6, 1, 14, 14, 14, 1, 14, 42, 11, 4, 7, 4, 13, 6, 6, 4, 6, 14, 13, 4, 56, 11, 11, 6, 4, 4, 42, 14, 6, 13, 6, 14, 42, 7, 56, 4, 4, 42, 8, 42, 42, 1, 42, 42, 14, 14, 14, 48, 6, 3, 4, 7, 1, 13, 6, 7, 6, 7, 14, 4, 4, 1, 11, 7, 7, 4, 7, 48, 6, 6, 56, 6, 1, 14, 6, 13, 4, 56, 4, 14, 4, 6, 4, 14, 42, 14, 42, 14, 4, 14, 7, 13, 42, 5, 11, 4, 2, 7], [18, 0, 42, 4, 18, 18, 53, 42, 1, 38, 56, 4, 7, 6, 8, 13, 6, 54, 53, 7, 2, 11, 9, 7, 45, 18, 6, 36, 11, 7, 4, 7, 45, 7, 42, 45, 48, 14, 6, 14, 7, 4, 4, 4, 14, 7, 14, 42, 13, 14, 1, 4, 4, 6, 14, 14, 7, 14, 14, 4, 7, 6, 13, 7, 4, 6, 7, 14, 11, 4, 4, 14, 11, 7, 1, 7, 4, 3, 4, 14, 1, 42, 13, 13, 4, 4, 42, 4, 4, 42, 1, 54, 42, 42, 3, 14, 13, 6, 1, 1, 4, 22, 4, 7, 7, 7, 1, 4, 7, 4, 4, 8, 7, 7, 4, 11, 4, 42, 14, 2, 56, 6, 14, 42, 6, 45, 13, 6, 6, 6, 5, 14, 45, 14, 6, 4, 6, 14, 4, 8, 56, 4, 14, 4, 14, 6, 1, 14, 4, 4, 7, 8, 6, 42, 6, 24, 6, 54, 4, 14, 14, 1, 42, 1, 14, 8, 7, 13, 4, 7, 6, 4, 4, 4, 4, 7, 11, 56, 56, 1, 4, 4, 1, 4, 6, 4, 11, 4], [18, 13, 4, 6, 48, 56, 42, 7, 14, 48, 4, 56, 1, 4, 8, 7, 18, 8, 8, 51, 7, 7, 38, 36, 7, 18, 7, 11, 9, 14, 4, 13, 42, 42, 44, 42, 48, 13, 14, 48, 7, 4, 4, 5, 14, 18, 5, 7, 5, 5, 42, 42, 14, 14, 7, 14, 4, 7, 5, 14, 6, 42, 4, 42, 4, 6, 7, 7, 50, 11, 7, 4, 6, 48, 13, 6, 6, 4, 45, 56, 6, 7, 4, 4, 6, 13, 45, 42, 2, 6, 4, 14, 7, 6, 13, 14, 6, 33, 4, 7, 11, 6, 14, 13, 6, 11, 4, 2, 7, 7, 11, 4, 54, 8, 13, 1, 3, 50, 4, 5, 7, 1, 6, 4, 51, 4, 42, 56, 14, 6, 14, 39, 8, 11, 1, 4, 1, 12, 4, 7, 4, 4, 1, 1, 4, 1, 39, 1, 7, 7, 11, 14, 4, 14, 11, 1, 42, 6, 42, 42, 42, 14, 4, 4, 4, 56, 14, 1, 6, 42, 3, 14, 7, 11, 1, 13, 42, 1, 6, 2, 4, 14, 7, 6], [2, 42, 18, 5, 18, 7, 18, 1, 39, 7, 18, 18, 7, 4, 7, 18, 9, 13, 18, 7, 45, 8, 42, 54, 3, 11, 7, 4, 4, 14, 46, 6, 45, 48, 42, 7, 14, 14, 4, 48, 4, 14, 42, 6, 42, 45, 42, 14, 42, 45, 8, 1, 1, 13, 4, 5, 42, 6, 14, 56, 4, 7, 4, 7, 7, 7, 13, 42, 14, 14, 2, 11, 11, 4, 11, 42, 42, 6, 56, 3, 8, 4, 7, 8, 4, 14, 42, 48, 4, 7, 42, 7, 14, 4, 4, 7, 6, 5, 11, 14, 42, 4, 7, 42, 14, 14, 4, 4, 13, 11, 1, 6, 36, 11, 4, 13, 6, 18, 6, 13, 4, 1, 4, 45, 14, 4, 4, 14, 42, 14, 42, 42, 6, 14, 4, 6, 6, 13, 14, 4, 5, 7, 14, 3, 42, 4, 4, 14, 11, 1, 1, 4, 45, 11, 4, 1, 8, 8, 8, 2, 7, 1, 6, 14, 1, 4, 7, 8, 42, 4, 14, 45, 1, 14, 13, 1, 42, 13, 14, 13, 8, 1, 6, 56], [18, 6, 42, 48, 14, 7, 45, 52, 3, 5, 7, 18, 4, 6, 7, 7, 18, 53, 54, 18, 3, 7, 51, 14, 6, 11, 4, 18, 45, 8, 14, 5, 3, 13, 45, 6, 6, 4, 4, 14, 4, 50, 4, 14, 1, 4, 6, 14, 13, 8, 4, 1, 42, 56, 13, 4, 13, 56, 8, 6, 8, 14, 2, 42, 4, 7, 14, 54, 4, 4, 42, 12, 7, 11, 3, 4, 11, 4, 4, 48, 7, 14, 13, 7, 10, 14, 14, 1, 8, 45, 4, 6, 4, 42, 7, 7, 14, 8, 12, 4, 2, 1, 11, 14, 4, 2, 7, 4, 13, 13, 7, 1, 4, 7, 6, 4, 1, 11, 45, 4, 18, 42, 8, 1, 7, 6, 1, 7, 14, 42, 4], [3, 18, 4, 18, 6, 45, 47, 45, 14, 14, 1, 7, 4, 7, 9, 56, 4, 4, 9, 48, 7, 5, 5, 13, 4, 1, 11, 7, 7, 4, 14, 1, 14, 6, 14, 4, 4, 42, 14, 7, 4, 4, 39, 42, 14, 4, 42, 11, 44, 6, 7, 14, 18, 8, 3, 14, 6, 4, 7, 7, 2, 4, 14, 5, 13, 11, 12, 42, 7, 14, 11, 9, 7, 4, 56, 42, 14, 56, 56, 54, 0, 14, 8, 54, 4, 4, 42, 7, 14, 11, 4, 4, 4, 45, 4, 7, 1, 4, 7, 7, 4, 7, 48, 7, 1, 1, 7, 1, 14, 11, 50, 4, 7, 45, 3, 6, 7, 42, 7, 42, 6, 8, 14, 4, 4, 56, 42, 14, 8, 7, 1, 14, 14, 6, 13, 14, 56, 4, 7, 4, 4, 6, 27, 48, 8, 14, 2, 4], [18, 18, 14, 18, 12, 7, 1, 56, 18, 18, 44, 4, 10, 7, 18, 7, 4, 45, 6, 7, 7, 1, 18, 3, 11, 4, 18, 48, 42, 13, 7, 4, 6, 7, 5, 42, 4, 4, 6, 56, 6, 2, 14, 18, 13, 14, 42, 14, 1, 56, 42, 6, 8, 54, 4, 7, 14, 13, 56, 1, 14, 4, 11, 4, 8, 7, 11, 7, 4, 7, 2, 4, 8, 8, 5, 14, 14, 6, 1, 10, 4, 4, 14, 42, 42, 1, 14, 56, 6, 6, 6, 42, 42, 42, 1, 7, 4, 7, 14, 14, 4, 6, 8, 5, 4, 14, 14, 5, 4, 11, 4, 55, 7, 1, 6, 1, 2, 1, 8, 1, 1, 4, 4, 42, 7, 14, 7, 42, 5, 7, 42, 1, 13, 14, 4, 4, 4, 7, 54, 11, 7, 4, 14, 1, 14, 1, 2, 7, 11, 4, 8, 1, 9, 4, 13, 24, 42], [13, 18, 48, 12, 4, 14, 18, 6, 45, 1, 42, 7, 56, 8, 7, 4, 7, 13, 56, 56, 7, 18, 1, 13, 1, 18, 7, 11, 4, 18, 14, 2, 18, 4, 7, 18, 3, 6, 56, 4, 42, 4, 8, 4, 14, 7, 42, 1, 7, 8, 14, 56, 7, 5, 4, 6, 6, 4, 4, 7, 13, 4, 7, 4, 1, 42, 42, 14, 4, 4, 11, 4, 14, 14, 4, 36, 42, 1, 42, 14, 5, 4, 4, 4, 56, 2, 42, 56, 14, 3, 4, 42, 7, 8, 14, 14, 8, 45, 4, 7, 14, 7, 7, 5, 1, 6, 7, 4, 14, 14, 7, 6, 13, 11, 8, 6, 6, 7, 7, 11, 7, 14, 7, 7, 4, 14, 4, 14, 7, 6, 3, 5, 7, 1, 42, 4, 14, 6, 4, 42, 14, 42, 7, 7, 14, 6, 14, 6, 12, 4, 4, 7, 7, 6, 1, 13, 7, 1, 7, 1, 6, 42, 1, 8, 11, 4], [18, 18, 42, 18, 48, 6, 45, 42, 5, 18, 18, 4, 7, 12, 13, 1, 40, 7, 18, 56, 48, 14, 48, 11, 1, 4, 18, 14, 7, 7, 13, 3, 18, 42, 2, 54, 4, 4, 1, 45, 42, 18, 8, 42, 2, 7, 14, 4, 14, 11, 14, 4, 4, 7, 4, 12, 13, 4, 4, 4, 14, 4, 14, 14, 11, 4, 7, 4, 42, 11, 4, 4, 7, 14, 42, 6, 4, 1, 4, 6, 42, 1, 14, 13, 4, 14, 7, 3, 6, 7, 45, 1, 4, 7, 7, 6, 6, 2, 4, 6, 6, 1, 5, 14, 7, 1, 9, 11, 4, 8, 8, 7, 1, 7, 1, 7, 1, 3, 8, 51, 7, 4, 4, 1, 14, 14, 48, 1, 11, 7, 1, 8, 13, 50, 2, 6, 1, 4, 7, 1, 7, 7, 56, 14, 8, 2, 8, 48, 42, 11, 42, 4, 14, 6, 7, 14, 56, 6, 45, 14, 14, 1, 1, 56, 13, 14], [18, 14, 1, 1, 14, 6, 1, 1, 4, 50, 18, 4, 7, 27, 7, 13, 18, 11, 36, 1, 1, 8, 14, 11, 7, 2, 4, 2, 7, 42, 3, 4, 14, 56, 6, 5, 18, 4, 8, 4, 4, 56, 42, 1, 42, 42, 13, 36, 48, 7, 7, 45, 42, 14, 56, 9, 8, 6, 42, 4, 7, 7, 1, 1, 1, 8, 11, 11, 4, 7, 13, 11, 4, 52, 36, 42, 7, 7, 6, 56, 11, 13, 1, 4, 4, 42, 13, 14, 10, 3, 13, 42, 8, 6, 14, 6, 4, 4, 7, 8, 54, 42, 27, 5, 54, 7, 7, 14, 12, 11, 7, 1, 4, 42, 3, 1, 13, 6, 48, 14, 6, 1, 8, 4, 42, 56, 14, 42, 1, 6, 4, 42, 1, 1, 6, 6, 7, 14, 1, 14]], 'testA2C': [[18, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 18, 14, 18, 4, 11, 14, 4, 14, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 7, 4, 4, 14, 7, 11, 7, 4, 14, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 7, 14, 14, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 14, 7, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 14, 4, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4], [18, 14, 14, 14, 14, 4, 4, 7, 14, 4, 14, 4, 7, 4, 14, 4, 4, 4, 11, 14, 4, 4, 4, 11, 4, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 14, 14, 4, 11, 4, 4, 4, 14, 4, 4, 4, 7, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 11, 4, 14, 4, 4, 4, 4, 4, 14, 14, 4, 4, 4, 4, 4, 14, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 7, 4, 4], [18, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 11, 4, 4, 14, 4, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 18, 4, 4, 4, 11, 4, 4, 4, 7, 4, 11, 4, 4, 11, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 14, 4, 18, 14, 18, 18, 11, 4, 14, 4, 4, 7, 4, 7, 14, 4, 4, 4, 7, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 4, 18, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 14, 4, 11, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 4, 4, 18, 4, 4, 4, 4, 14, 14, 4, 14, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 14, 4, 6, 4, 4, 4, 4, 4, 7, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 7, 4, 14, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 14, 18, 4, 11, 18, 18, 4, 4, 7, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 7], [18, 4, 4, 4, 4, 14, 4, 4, 14, 4, 4, 4, 7, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 14, 14, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 11, 4, 4, 4, 6, 14, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 7, 4, 11, 14, 4, 4, 11, 4, 14, 4, 4, 18, 4, 4, 4, 4, 18, 4, 4, 4, 18, 4, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 11, 4, 4, 14, 4, 11, 18, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 7, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 14, 4, 14, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 7, 14], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 14, 4, 4, 4, 14, 4, 4, 4, 14, 7, 4, 4, 4, 4, 14, 14, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 11, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 18, 4, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 14, 4, 4, 4, 14, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 7, 7, 7, 14, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 14, 14, 4, 4, 4, 11, 7, 4, 4, 14, 4, 14, 7, 14, 4, 4, 4, 11, 11, 11, 4, 4, 11, 4, 11, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 14, 18, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 14, 7, 4, 4, 4, 4, 4, 14, 4, 4, 14, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 4, 4, 4, 7, 4, 14, 4, 7, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4], [18, 4, 4, 14, 14, 4, 4, 4, 4, 4, 18, 4, 7, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 11, 4, 4, 7, 4, 4, 4, 4, 11, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 18, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 11, 7, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 4, 4, 4, 14, 4, 4, 4, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4], [18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 14, 14, 4, 14, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9, 14, 4, 14, 7, 4, 4, 4, 4, 18, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 7, 14, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 14, 14, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 14, 14, 7, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 14, 4, 14, 4, 4, 4, 4, 4, 11, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4], [18, 4, 7, 4, 14, 4, 4, 14, 4, 4, 14, 4, 14, 7, 14, 4, 4, 14, 4, 11, 4, 4, 4, 4, 11, 4, 4, 4, 4, 14, 4, 4, 4, 14, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 7, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 7, 4, 14, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 14, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 18, 4, 4, 4, 4, 4, 4, 4, 4, 14], [18, 4, 4, 7, 4, 4, 4, 4, 4, 14, 4, 4, 14, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 7, 7, 18, 4, 4, 7, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 14, 11, 4, 4, 4, 14, 11, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 4, 18, 18, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 11, 4, 4, 11, 14, 11, 14, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 7, 4, 14, 14, 18, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 11, 4, 4, 4, 4], [18, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 14, 7, 4, 18, 4, 4, 4, 4, 4, 4, 4, 7, 11, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 14, 4, 14, 4, 4, 14, 4, 4, 14, 14, 7, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 4, 18, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 18, 14, 4, 4, 4, 4, 4, 14, 4, 7, 4, 11, 4, 14, 4, 4, 14, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 11, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 4, 18, 4, 14, 11, 4, 7, 11, 4, 4, 4, 4, 4, 7, 4, 4, 7], [18, 4, 4, 4, 11, 14, 4, 4, 14, 4, 14, 4, 7, 4, 4, 7, 4, 7, 4, 4, 4, 4, 4, 11, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 14, 7, 18, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 11, 14, 14, 11, 4, 4, 14, 11, 4, 4, 4, 7, 4, 4, 7, 4, 4, 4, 14, 4, 4, 4, 11, 4, 14, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4], [18, 4, 14, 4, 14, 4, 4, 11, 4, 4, 4, 4, 14, 14, 7, 18, 4, 4, 7, 4, 11, 4, 4, 4, 4, 11, 4, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 14, 4, 4, 4, 4, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 18, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 18, 14, 4, 14, 4, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 14, 4, 14, 4, 4, 14, 4, 7, 4, 4, 4, 14, 4, 4, 4, 4, 4, 18, 11, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 14, 4, 4, 7, 4, 4, 7, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 14, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 14, 14, 18, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 11, 4, 11, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 7, 4, 7, 14, 14, 4, 14, 4, 4, 4, 7, 4, 4], [18, 14, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 14, 4, 4, 4, 14, 4, 4, 11, 4, 4, 7, 11, 4, 4, 4, 4, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 7, 11, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4], [18, 4, 14, 4, 7, 4, 4, 7, 14, 4, 4, 4, 7, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 18, 11, 14, 18, 14, 4, 11, 14, 18, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 18, 4, 4, 11, 4, 4, 4, 4, 4, 4, 14, 4, 14, 4, 7, 4, 4, 14, 4, 4, 4, 4, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 18, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4], [18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 14, 7, 18, 4, 7, 11, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 18, 4, 4, 4, 4, 4, 4, 14, 14, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 11, 4, 4, 11, 4, 14, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4], [18, 4, 18, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 14, 18, 14, 4, 4, 4, 4, 4, 14, 14, 14, 4, 4, 7, 4, 7, 4, 11, 4, 4, 11, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 14, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4], [18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 14, 4, 4, 4, 14, 14, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 11, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 14, 4, 4, 4, 4, 4, 14, 4, 11, 4, 7, 4, 4, 4, 11, 4, 4, 14, 7, 4, 4, 11, 4, 18, 4, 4, 18, 4, 4, 4, 14, 4, 4, 4, 14, 4, 18, 14, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 14, 7, 11, 4, 4, 4, 4, 4, 4, 7, 4, 11, 11, 4, 4, 18, 4, 7, 14, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 14, 4, 4, 4, 4, 14, 4, 4, 4, 14, 7, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 14, 4, 14, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 4, 7, 14, 4, 4, 4, 4, 4, 7, 4, 4, 7, 4, 4, 11, 4, 7, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 18, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4], [18, 4, 4, 4, 4, 4, 4, 14, 14, 4, 4, 4, 7, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 14, 18, 4, 4, 14, 4, 14, 4, 4, 4, 4, 4, 4, 7, 7, 4, 4, 4, 11, 4, 4, 11, 14, 4, 11, 4, 4, 4, 4, 14, 4, 4, 4, 11, 4, 4, 14, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 7, 4, 4, 4, 4, 4, 14, 4, 14, 4, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 4, 4, 4, 4, 4, 14, 4, 14, 7, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 14, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 7, 14, 4, 14, 4, 14, 14, 7, 4, 14, 4, 4, 4, 4, 14, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 7, 18, 14, 4, 4, 4, 4, 4, 11, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 18, 4, 4, 4, 14, 4, 4, 4, 14, 7, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 7, 11, 14, 4, 14, 4, 4, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 7, 7, 18, 14, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 18, 18, 14, 4, 14, 4, 14, 4, 4, 4, 4, 14, 7, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 7, 4, 7, 14, 4, 14, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 11, 18, 14, 4, 11, 4, 4, 4, 4, 18, 14, 14, 4, 14, 14, 4, 14, 4, 4, 4, 4, 14, 7, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 7, 14, 4, 4, 4, 14, 18, 4, 4, 4, 4, 14, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 14, 4, 18, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4], [18, 14, 4, 14, 4, 14, 4, 4, 4, 14, 4, 4, 7, 14, 4, 4, 4, 14, 14, 11, 11, 4, 14, 11, 11, 4, 4, 4, 4, 7, 4, 4, 4, 11, 4, 4, 4, 4, 18, 7, 18, 7, 7, 14, 7, 4, 14, 14, 4, 4, 7, 4, 4, 11, 4, 4, 4, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 14, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 11, 4, 4, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 7, 4, 4, 4, 14, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 14, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 14, 4, 7, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 18, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 4, 7, 4, 7, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 7, 7, 11, 4, 4, 4, 4, 4, 14, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 14, 4, 4, 4, 4, 14, 14, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 18, 4, 14, 4, 4, 4, 18, 14], [18, 14, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 7, 4, 14, 11, 4, 7, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 7, 18, 4, 4, 4, 14, 14, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 18, 18, 14, 4, 4, 4, 4, 4, 14, 14, 4, 4, 7, 4, 4, 4, 4, 4], [18, 4, 4, 4, 14, 4, 4, 4, 4, 4, 11, 4, 7, 4, 4, 4, 7, 4, 4, 4, 4, 11, 4, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 14, 4, 2, 4, 14, 4, 4, 4, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 7, 7, 14, 14, 18, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 14, 4, 11, 7, 11, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 14, 14, 4, 4, 4, 14, 4, 4, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11], [18, 4, 4, 4, 7, 4, 4, 4, 7, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 11, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 7, 4, 4, 4, 7, 4, 7, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 11, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 14, 14, 4, 18, 14, 4, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 14, 4, 4, 14, 11, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 11, 4], [18, 4, 7, 4, 4, 4, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 14, 4, 4, 14, 18, 4, 11, 4, 7, 4, 4, 4, 18, 14, 4, 4, 14, 4, 7, 14, 11, 7, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 14, 4, 14, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 14, 4, 4, 4, 11, 4, 11, 11, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 14, 14, 14, 4, 4, 14, 4, 14, 4, 14, 7, 4, 4, 4, 4, 7, 4, 4, 14, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 7, 14, 4, 4, 7, 4, 14, 4, 7, 4, 4, 4, 4, 11, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 14, 4, 4, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 4, 4, 14, 4, 4, 4, 4, 14, 4, 4, 7, 4, 11, 7, 11, 4, 4, 4, 4, 4, 4, 14, 11, 4, 14, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 11, 4, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 18, 18, 7, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 11, 14, 14, 7, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 11, 4, 4, 4], [18, 4, 14, 4, 4, 4, 4, 14, 4, 14, 14, 4, 7, 4, 14, 4, 4, 4, 7, 4, 4, 4, 14, 18, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 14, 4, 4, 14, 4, 7, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 7, 4, 4, 7, 4, 7, 4, 7, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 14, 4, 4, 11, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 11, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 7, 4, 11, 11, 4, 4, 4, 7, 14, 4, 7, 14, 4, 4, 4, 4, 4, 4, 14, 14, 4, 11, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 14, 18, 4, 4, 14, 4, 4, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 11, 7, 14, 11, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 11, 4], [18, 7, 4, 4, 4, 14, 4, 4, 4, 14, 4, 4, 7, 4, 4, 4, 4, 14, 4, 4, 4, 4, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 18, 14, 7, 4, 4, 4, 18, 4, 11, 7, 4, 4, 7, 4, 14, 4, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 4, 4, 4, 4, 4, 7, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 4, 18, 4, 4, 4, 4, 18, 4, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 14, 18, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 11, 4, 4, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 4, 14, 4, 4, 4, 4, 14, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 11, 4, 4, 4, 4, 4, 4], [18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 18, 7, 14, 4, 14, 4, 18, 4, 4, 4, 4, 4, 14, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 4, 4, 4, 4, 4, 4, 14, 4, 7, 18, 4, 7, 14, 4, 4, 4, 14, 4, 4, 4, 4, 14, 7, 14, 4, 4, 4, 4, 4, 4, 14, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 14, 4, 14, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4], [18, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 14, 4, 4, 4, 11, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 14, 4, 18, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 14, 14, 4, 14, 4, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 14, 4, 4, 4, 4, 18, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 14, 7, 4, 4, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4], [18, 4, 14, 4, 4, 4, 4, 18, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 18, 7, 14, 4, 14, 14, 14, 4, 4, 14, 4, 4, 14, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 11, 4, 4, 14, 4, 4, 4, 7, 14, 18, 4, 4, 4, 4, 14, 4, 14, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 18, 4, 18, 18, 4, 18, 14, 14, 4, 7, 4, 4, 4, 4, 4, 7, 11, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 18, 7, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4], [18, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 18, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 14, 14, 4, 4, 4, 4, 4, 14, 7, 7, 4, 4, 4, 4, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 18, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 18, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 18], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 11, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 11, 4, 11, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 14, 4, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 14, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 11, 4, 4, 8, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 14, 4, 4, 4, 14, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 14, 4, 14, 14, 4, 4, 4, 4, 4, 18, 4, 7, 4, 7, 4, 4, 4, 14, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 14, 4, 4, 14, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 7, 4, 11, 4, 4, 4, 4, 14, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 18, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 11], [18, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 7, 14, 4, 4, 4, 7, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 18, 4, 7, 14, 4, 4, 4, 4, 11, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 11, 4, 4, 4, 4, 4], [18, 4, 4, 4, 14, 7, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 7, 4, 4, 4, 4, 4, 11, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 18, 14, 4, 4, 14, 4, 14, 7, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 18, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 11], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 7, 4, 11, 4, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 7, 14, 4, 4, 4, 7, 4], [18, 7, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 14, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 18, 7, 14, 4, 14, 4, 14, 4, 14, 4, 4, 4, 14, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14], [18, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 18, 18, 14, 4, 4, 11, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 14, 4, 14, 4, 4, 4, 19, 18, 4, 7, 14, 4, 4, 4, 14, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 14, 11, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 18, 14, 4, 4, 4, 4, 14, 4, 4, 4, 4], [18, 4, 4, 14, 4, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 11, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 7, 4, 11, 4, 4, 4, 4, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 11, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 14, 4, 4, 7, 14, 4, 4, 4, 4], [18, 4, 4, 4, 7, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 11, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 14, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 14, 4, 4, 4, 18, 4, 4, 14, 4, 4, 4, 14, 7, 11, 4, 4, 4, 14, 14, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 14, 15, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 7, 4, 4, 4, 14, 4, 14, 7, 18, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 14, 11, 4, 4, 4, 11, 4, 4, 4, 7, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 11, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11], [18, 4, 4, 4, 4, 14, 4, 18, 7, 4, 4, 4, 7, 14, 4, 14, 14, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 14, 4, 4, 18, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4], [18, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 7, 7, 1, 4, 4, 4, 11, 4, 18, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 11, 4, 14, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 35, 18, 4, 7, 18, 4, 4, 4, 4, 14, 4, 4, 14, 4, 11, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 7, 4, 4, 14, 18, 4, 7, 7, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 18, 14, 14, 4, 18, 4, 11, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 14, 4, 11, 4, 4, 4, 11, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 11, 4, 4, 4, 18, 4, 4, 4, 4, 4, 14, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 14, 14, 4, 14, 7, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4], [18, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 14, 4, 4, 4, 14, 4, 4, 4, 4, 11, 11, 4, 4, 4, 4, 14, 4, 4, 11, 4, 4, 4, 4, 4, 14, 18, 14, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 18, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 14, 4, 4, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 14, 4, 14, 4, 4, 4, 4, 4, 18, 14, 14, 14, 4, 4, 4, 4, 4, 11, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 7, 7, 4, 7, 14, 4, 4, 7, 4, 4, 7, 11, 11, 4, 4, 4, 14, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 14, 4, 14, 14, 11, 14, 4, 14, 18, 4, 7, 4, 4, 4, 4, 4, 11, 4, 11, 4, 11, 11, 4, 4, 4, 4, 4, 4, 14, 14, 4, 4, 4, 4, 4, 18, 14, 14, 7, 14, 4, 4, 11, 4, 4, 18, 4, 7, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 11, 14, 7, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 4, 4, 4, 4, 11, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 11, 7, 11, 4, 4, 4, 4, 4, 4, 4, 11, 4, 11, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4], [18, 4, 14, 4, 4, 11, 14, 14, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 11, 4, 4, 7, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 14, 4, 4, 14, 4, 4, 7, 4, 11, 4, 4, 4, 4, 14, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 4, 4, 4, 14, 4, 7, 14, 4, 11, 11, 11, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 4, 4, 4, 4, 14, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 11, 4, 7, 4, 4, 4, 4, 14, 4, 14, 14, 7, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 14, 14, 14, 4, 14, 14, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 18, 14, 4, 7, 4, 4, 4, 14, 11, 4, 7, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 14, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 7, 7, 4, 4, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 11], [18, 4, 7, 4, 14, 7, 14, 14, 14, 14, 14, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 11, 4, 14, 14, 4, 14, 4, 7, 4, 7, 4, 11, 4, 11, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 18, 7, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 11, 4, 4, 4, 4, 14, 4, 4, 14, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 21, 14, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 14, 4, 4, 14, 4, 4, 14, 4, 7, 4, 4, 11, 4, 4, 7, 14, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 7, 4, 14, 14, 4, 4, 14, 4, 7, 4, 4, 14, 7, 11, 4, 11, 4, 4, 7, 4, 14, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 11, 7, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 11, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 4, 4, 14, 14, 4, 4, 14, 14, 14, 4, 4, 11, 7, 4, 4, 11, 4, 7, 4, 4, 4, 4, 4, 11, 4, 4, 4, 18, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 14, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 4, 4, 11, 4, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 11, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 7], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 14, 6, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14], [18, 4, 4, 4, 14, 14, 4, 4, 4, 4, 18, 4, 7, 4, 4, 11, 4, 4, 4, 11, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 18, 14, 4, 18, 4, 14, 4, 4, 7, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 14, 7, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 14, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 14, 7, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 18, 4, 14, 4, 4, 4, 7, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 14, 4, 7, 18, 4, 4, 4, 14, 7, 14, 7, 4, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 14, 4, 4, 4, 14, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 14, 14, 4, 4, 4, 14, 4, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 18, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 14, 4, 14, 4, 4, 7, 14, 4, 7, 4, 4, 4, 4, 4, 7, 4, 4, 4, 11, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 14, 14, 4, 4, 14, 4, 4, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 11, 7, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 14, 4, 4, 11, 4, 4, 14, 7, 4, 4, 14, 4, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 18, 14, 4, 18, 18, 4, 4, 4, 14, 4, 7, 4, 4, 4, 11, 4, 4, 4, 4, 4, 11, 11, 4], [18, 14, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 7, 7, 4, 4, 4, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 14, 7, 4, 4, 4, 4, 14, 14, 7, 4, 11, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 4, 7, 14, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 14, 4, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 11, 4, 4, 4, 18, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 11, 4, 4, 4], [18, 14, 14, 4, 4, 4, 4, 7, 14, 14, 14, 4, 7, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 14, 4, 4, 14, 14, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 14, 4, 4, 4, 4, 4, 11, 14, 18, 4, 4, 4, 18, 7, 7, 7, 7, 14, 4, 4, 14, 4, 4, 4, 14, 7, 14, 14, 4, 4, 4, 4, 4, 4, 4, 14, 11], [18, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 4, 14, 14, 7, 4, 4, 7, 4, 4, 4, 14, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 4, 4, 14, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11], [18, 4, 4, 7, 4, 4, 7, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 14, 4, 4, 4, 4, 7, 4, 7, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 7, 14, 4, 4, 4, 4, 14, 4, 14, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 18, 14, 4, 4, 4, 4], [18, 4, 7, 4, 4, 14, 4, 4, 4, 4, 4, 4, 7, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 18, 4, 14, 4, 18, 4, 4, 14, 7, 4, 4, 4, 4, 11, 4, 7, 4, 1, 4, 11, 7, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 18, 4, 18, 14, 4, 4, 4, 14, 4, 14, 4, 14, 4, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 14, 4, 18, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 14, 4, 14, 4, 7, 4, 4, 14, 4, 14, 7, 18, 4, 4, 4, 11, 4, 4, 4, 18, 4, 4, 4, 4, 4, 11, 4, 4, 4, 18, 14, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 14, 7, 14, 4, 4, 4, 4, 4, 4, 4, 11, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 7, 11, 4, 4, 11, 4, 14, 7, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 14, 14, 14, 4, 4, 4, 14, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 11, 4, 4, 4, 4, 14, 14, 4, 4, 4, 14, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 18, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 14, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4], [18, 7, 4, 4, 14, 14, 4, 4, 14, 14, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 7, 14, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 14, 4, 4, 18, 7, 7, 14, 14, 7, 14, 4, 4, 4, 4, 4, 14, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 7, 7, 14, 4, 4, 14, 4, 4, 4, 4, 7, 4, 4, 7, 4, 4, 4, 14, 4, 4, 4, 11, 4, 14, 4, 14, 4, 4, 4, 18, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 14, 4], [18, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 11, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 7, 18, 4, 4, 4, 7, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 11, 7, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 7, 7, 7, 7, 7, 4, 14, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 14, 4, 7, 4, 4, 4, 14, 4, 4, 18, 4, 7, 4, 4, 4, 4, 4, 14, 11, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 18, 14, 4, 18, 4, 14, 4, 7, 4, 4, 4, 4, 7, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 11, 7, 4, 11, 4, 11, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 14, 14, 7, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 11, 7, 4, 4, 14, 4, 4, 11, 4, 4, 4, 14, 11, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 14, 4, 4, 14, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 7, 4, 4, 14, 4, 4, 14, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 7, 4, 18, 14, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4], [18, 4, 4, 4, 4, 7, 4, 4, 14, 4, 14, 4, 14, 7, 4, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 18, 14, 18, 14, 18, 4, 4, 4, 14, 4, 14, 4, 7, 14, 4, 4, 14, 4, 4, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 18, 14, 4, 4, 4, 14, 4, 14, 4, 4, 14, 4, 7, 14, 4, 7, 4, 11, 4, 4, 11], [18, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 7, 18, 4, 4, 4, 4, 4, 4, 18, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 14, 4, 4, 4, 4, 14, 4, 4, 4, 14, 4, 14, 14, 7, 14, 4, 4, 4, 4, 4, 14, 4, 4, 4, 11, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 14, 4, 14, 4, 14, 4, 4, 7, 4, 4, 11, 4, 4, 4, 4, 7, 4, 11, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 14, 4, 4, 4, 4, 4, 7, 4, 14, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 18, 14, 4, 14, 14, 4, 4, 4, 4, 4, 14, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 11], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 14, 7, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4, 11, 4, 7, 4, 4, 4, 4, 4, 4, 4, 18, 7, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 14, 4, 18, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 1, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 11, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 18, 4, 4, 14, 4, 4, 4, 4, 14, 7, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 7, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 4, 14, 4, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 14, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 14, 4, 14, 14, 4, 4, 4, 4, 4, 4, 14, 7, 4, 11, 4, 4, 4, 11, 4, 14, 4, 4, 11, 4, 14, 4, 7, 4, 4, 4, 4, 4, 14, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 11, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 14, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 11, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 14, 4, 4, 4, 4, 4], [18, 4, 4, 4, 11, 4, 4, 4, 4, 4, 14, 4, 14, 14, 14, 7, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 18, 14, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 7, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 14, 14, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 14, 14, 4, 11, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 7, 4, 4, 4], [18, 4, 4, 4, 14, 4, 14, 4, 4, 4, 4, 4, 7, 4, 14, 4, 18, 4, 7, 4, 4, 4, 4, 11, 14, 4, 14, 4, 4, 18, 4, 4, 4, 3, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 14, 4, 14, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 7, 7, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 18, 4, 4, 4, 4, 14, 4, 14, 7, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 14, 4, 4, 4, 14, 4, 4, 11, 4, 14, 7, 4, 4, 4, 4, 4, 7, 4, 4, 14, 4, 11, 4, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 11, 4, 18, 14, 4, 14, 4, 4, 4, 4, 7, 4, 4, 4, 14, 4, 4, 4, 4, 4, 4, 11, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 11, 11, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 14, 14, 14, 4, 4, 4, 4, 18, 7, 7, 7, 7, 7, 7, 7, 14, 4, 4, 4, 7, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 11], [18, 7, 4, 4, 4, 4, 4, 4, 4, 14, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 4, 18, 14, 4, 4, 14, 4, 4, 14, 11, 4, 4, 4, 7, 7, 4, 4, 7, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 7, 4, 4, 4, 4, 14, 4, 4, 4, 4, 4, 11, 4, 4, 41, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 18, 4, 14, 4, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4], [18, 4, 4, 4, 4, 4, 4, 14, 4, 4, 18, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 14, 4, 4, 4, 14, 14, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 4, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 7, 14, 4, 4, 4, 14, 4, 14, 4, 4, 4, 7, 11, 11, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 4, 4, 4, 18, 14, 4, 4, 4, 4, 4, 4, 14, 18, 4, 4, 11, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 18, 4, 7, 7, 14, 4, 4, 4, 4, 14, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11], [18, 4, 14, 4, 4, 7, 4, 4, 14, 14, 4, 14, 4, 7, 4, 14, 4, 7, 4, 4, 4, 4, 11, 4, 14, 11, 4, 4, 14, 4, 4, 4, 4, 14, 4, 4, 18, 4, 4, 18, 14, 7, 4, 4, 14, 4, 11, 11, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 18, 14, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 14, 7, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 14, 4, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 14, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 52, 7, 14, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4]]}\n",
            "Saving best algo to json file...\n",
            "submission.json was saved in /content/drive/My Drive/DinerDashChallenge\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Verifying submission.json...\n",
            "Name of best algo: testA2C\n",
            "Number of episodes(random seeds): 100\n",
            "Number of episodes in submission matches the number of random seeds\n",
            "Verification Complete! Please double check the verification results\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}